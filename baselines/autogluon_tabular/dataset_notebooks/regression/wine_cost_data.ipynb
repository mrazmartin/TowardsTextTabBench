{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0200d09",
   "metadata": {},
   "source": [
    "### Let's start with downloading the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4d0c4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "# to reach the dataloader_functions module\n",
    "module_path = os.path.abspath(os.path.join( \"..\"))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from dataloader_functions.download_data import download_raw_data\n",
    "current_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b8103e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO update this section per dataset\n",
    "dataset_config = {\n",
    "    'dataset_name': 'wine',\n",
    "    'source': 'kaggle',\n",
    "    'remote_path': 'elvinrustam/wine-dataset',\n",
    "    'files': ['WineDataset.csv'],\n",
    "    'rename_files': ['wine.csv'],\n",
    "    'task': 'reg',\n",
    "    'target': 'Price',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4336bfef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36mInfo:\u001b[0m Dataset already downloaded in \u001b[1;35m/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/regression/../../datasets_files/raw/regression/wine\u001b[0m.\n",
      "Downloaded wine dataset to /home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/regression/../../datasets_files/raw/regression/wine\n"
     ]
    }
   ],
   "source": [
    "if dataset_config['task'] == 'clf':\n",
    "    dataset_subfolder = os.path.join('raw', 'classification', dataset_config['dataset_name']) \n",
    "elif dataset_config['task'] == 'reg':\n",
    "    dataset_subfolder = os.path.join('raw', 'regression', dataset_config['dataset_name'])\n",
    "else:\n",
    "    raise ValueError(f\"Unknown task: {dataset_config['task']}\")\n",
    "\n",
    "# this path needs to be modified based on the location of the notebook\n",
    "download_path = os.path.join(current_dir, '..', '..', 'datasets_files', dataset_subfolder)\n",
    "\n",
    "if download_raw_data(\n",
    "    dataset_config=dataset_config,\n",
    "    download_path=download_path,\n",
    "    force_download=False,\n",
    "    remove_unlisted=True,\n",
    ") is not None:\n",
    "    print(f\"Downloaded {dataset_config['dataset_name']} dataset to {download_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d886637",
   "metadata": {},
   "source": [
    "### Now we need to preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48bcaebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader_functions.load_and_pp_raw_data import _drop_empty_columns, _drop_single_value_columns\n",
    "from dataloader_functions.utils.data_2_df import read_any_to_df\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "current_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0861820c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading /home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/regression/../../datasets_files/raw/regression/wine/wine.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Capacity</th>\n",
       "      <th>Grape</th>\n",
       "      <th>Secondary Grape Varieties</th>\n",
       "      <th>Closure</th>\n",
       "      <th>Country</th>\n",
       "      <th>Unit</th>\n",
       "      <th>Characteristics</th>\n",
       "      <th>Per bottle / case / each</th>\n",
       "      <th>Type</th>\n",
       "      <th>ABV</th>\n",
       "      <th>Region</th>\n",
       "      <th>Style</th>\n",
       "      <th>Vintage</th>\n",
       "      <th>Appellation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Guv'nor, Spain</td>\n",
       "      <td>We asked some of our most prized winemakers wo...</td>\n",
       "      <td>£9.99 per bottle</td>\n",
       "      <td>75CL</td>\n",
       "      <td>Tempranillo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Natural Cork</td>\n",
       "      <td>Spain</td>\n",
       "      <td>10.5</td>\n",
       "      <td>Vanilla, Blackberry, Blackcurrant</td>\n",
       "      <td>per bottle</td>\n",
       "      <td>Red</td>\n",
       "      <td>ABV 14.00%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rich &amp; Juicy</td>\n",
       "      <td>NV</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bread &amp; Butter 'Winemaker's Selection' Chardon...</td>\n",
       "      <td>This really does what it says on the tin. It’s...</td>\n",
       "      <td>£15.99 per bottle</td>\n",
       "      <td>75CL</td>\n",
       "      <td>Chardonnay</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Natural Cork</td>\n",
       "      <td>USA</td>\n",
       "      <td>10.1</td>\n",
       "      <td>Vanilla, Almond, Coconut, Green Apple, Peach, ...</td>\n",
       "      <td>per bottle</td>\n",
       "      <td>White</td>\n",
       "      <td>ABV 13.50%</td>\n",
       "      <td>California</td>\n",
       "      <td>Rich &amp; Toasty</td>\n",
       "      <td>2021</td>\n",
       "      <td>Napa Valley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Oyster Bay Sauvignon Blanc 2022, Marlborough</td>\n",
       "      <td>Oyster Bay has been an award-winning gold-stan...</td>\n",
       "      <td>£12.49 per bottle</td>\n",
       "      <td>75CL</td>\n",
       "      <td>Sauvignon Blanc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Screwcap</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>9.8</td>\n",
       "      <td>Tropical Fruit, Gooseberry, Grapefruit, Grass,...</td>\n",
       "      <td>per bottle</td>\n",
       "      <td>White</td>\n",
       "      <td>ABV 13.00%</td>\n",
       "      <td>Marlborough</td>\n",
       "      <td>Crisp &amp; Zesty</td>\n",
       "      <td>2022</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0                                 The Guv'nor, Spain   \n",
       "1  Bread & Butter 'Winemaker's Selection' Chardon...   \n",
       "2       Oyster Bay Sauvignon Blanc 2022, Marlborough   \n",
       "\n",
       "                                         Description              Price  \\\n",
       "0  We asked some of our most prized winemakers wo...   £9.99 per bottle   \n",
       "1  This really does what it says on the tin. It’s...  £15.99 per bottle   \n",
       "2  Oyster Bay has been an award-winning gold-stan...  £12.49 per bottle   \n",
       "\n",
       "  Capacity            Grape Secondary Grape Varieties       Closure  \\\n",
       "0     75CL      Tempranillo                       NaN  Natural Cork   \n",
       "1     75CL       Chardonnay                       NaN  Natural Cork   \n",
       "2     75CL  Sauvignon Blanc                       NaN      Screwcap   \n",
       "\n",
       "       Country  Unit                                    Characteristics  \\\n",
       "0        Spain  10.5                  Vanilla, Blackberry, Blackcurrant   \n",
       "1          USA  10.1  Vanilla, Almond, Coconut, Green Apple, Peach, ...   \n",
       "2  New Zealand   9.8  Tropical Fruit, Gooseberry, Grapefruit, Grass,...   \n",
       "\n",
       "  Per bottle / case / each   Type         ABV       Region          Style  \\\n",
       "0               per bottle    Red  ABV 14.00%          NaN   Rich & Juicy   \n",
       "1               per bottle  White  ABV 13.50%   California  Rich & Toasty   \n",
       "2               per bottle  White  ABV 13.00%  Marlborough  Crisp & Zesty   \n",
       "\n",
       "  Vintage  Appellation  \n",
       "0      NV          NaN  \n",
       "1    2021  Napa Valley  \n",
       "2    2022          NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dataset_files_df = []\n",
    "\n",
    "if dataset_config['rename_files'] is None or len(dataset_config['rename_files']) == 0:\n",
    "    dataset_config['rename_files'] = dataset_config['files']\n",
    "\n",
    "for file in dataset_config['rename_files']:\n",
    "\n",
    "    file_location = os.path.join(download_path, file)\n",
    "\n",
    "    print(f\"Loading {file_location}\")\n",
    "\n",
    "    dataset_files_df.append(read_any_to_df(file_location))\n",
    "\n",
    "# example of the loaded df data:\n",
    "pd.set_option('display.max_columns', None)\n",
    "dataset_files_df[0].head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d099b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped: Index(['Secondary Grape Varieties'], dtype='object')\n",
      "Dataframe shape before/afrer cleaning: (1290, 17) / (1290, 16)\n"
     ]
    }
   ],
   "source": [
    "## Run some basic data cleaning\n",
    "\n",
    "dataset_files_gen_cleaned = []\n",
    "\n",
    "for df_file in dataset_files_df:\n",
    "    df_size = df_file.shape\n",
    "    # 1. Drop columns with more than 50% missing values\n",
    "    df_file = _drop_empty_columns(df_file, threshold=0.6)\n",
    "    # 2. Drop columns with only one unique value\n",
    "    df_file = _drop_single_value_columns(df_file)\n",
    "    # 3. remove duplicates\n",
    "    df_file = df_file.drop_duplicates()\n",
    "    # 4. remove rows with missing target values\n",
    "    df_file = df_file[df_file[dataset_config['target']].notna()]\n",
    "    # 5. drop unnamed columns\n",
    "    df_file = df_file.loc[:, ~df_file.columns.str.contains('^Unnamed')]\n",
    "\n",
    "    dataset_files_gen_cleaned.append(df_file)\n",
    "\n",
    "    print(f\"Dataframe shape before/afrer cleaning: {df_size} / {df_file.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0a2a11a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe shape before/afrer by-hand cleaning: (1290, 16) / (1290, 16)\n"
     ]
    }
   ],
   "source": [
    "## TODO: Now run custom data cleaning -> remove non-essential columns\n",
    "\n",
    "cols_to_drop = []\n",
    "\n",
    "dataset_files_cleaned = []\n",
    "\n",
    "# assuming for multiple files we still want to drop the same columns\n",
    "for df_file in dataset_files_gen_cleaned:\n",
    "    df_size = df_file.shape\n",
    "    for col in cols_to_drop:\n",
    "        if col in df_file.columns:\n",
    "            df_file.drop(col, axis=1, inplace=True)\n",
    "        else:\n",
    "            print(f\"Column {col} not found in dataframe\")\n",
    "\n",
    "    dataset_files_cleaned.append(df_file)    \n",
    "    print(f\"Dataframe shape before/afrer by-hand cleaning: {df_size} / {df_file.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d90a681b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before:  0    £9.99 per bottle\n",
      "Name: Price, dtype: object\n",
      "after:  0    999\n",
      "Name: Price, dtype: int64\n",
      "Dataframe shape before/after cleaning: (1290, 16) / (1290, 16)\n",
      "before:\n",
      " 0    ABV 14.00%\n",
      "Name: ABV, dtype: object\n",
      "after:\n",
      " 0    14.0\n",
      "Name: ABV, dtype: float64\n",
      "Dataframe shape before/after cleaning: (1290, 16) / (1281, 16)\n",
      "before:\n",
      " 0    NV\n",
      "Name: Vintage, dtype: object\n",
      "after:\n",
      " 0   NaN\n",
      "Name: Vintage, dtype: float64\n",
      "Dataframe shape before/after cleaning: (1281, 16) / (1281, 16)\n"
     ]
    }
   ],
   "source": [
    "import copy \n",
    "tmp_df = copy.deepcopy(dataset_files_cleaned)\n",
    "\n",
    "# Make the target column numeric\n",
    "for df_file in dataset_files_cleaned:\n",
    "\n",
    "    df_size = df_file.shape\n",
    "\n",
    "    # print the first 3 rows of the Price column\n",
    "    print(\"before: \", df_file['Price'].head(n=1))\n",
    "    # remove the currency sign prefix\n",
    "    # Step 1: Remove non-digit characters (like '?', ',')\n",
    "    if df_file['Price'].dtype == 'object':\n",
    "        # Check if the column is of type object\n",
    "        # If so, remove non-digit characters\n",
    "        df_file['Price'] = df_file['Price'].str.replace(r'[^\\d]', '', regex=True)\n",
    "\n",
    "    # Step 2: Convert the column to integers\n",
    "    df_file['Price'] = pd.to_numeric(df_file['Price'])\n",
    "    print(\"after: \", df_file['Price'].head(n=1))\n",
    "\n",
    "    # remove rows with missing values in the Price column\n",
    "    df_file.dropna(subset=['Price'], inplace=True)\n",
    "\n",
    "    print(f\"Dataframe shape before/after cleaning: {df_size} / {df_file.shape}\")\n",
    "\n",
    "# TODO: make the ABV column numeric, it is redundantly repeated and the same semantics can be gathered from the column name\n",
    "# the column has strict ABV 13.50% -> make it 13.50\n",
    "for df_file in dataset_files_cleaned:\n",
    "\n",
    "    df_size = df_file.shape\n",
    "\n",
    "    # print the first 3 rows of the Price column\n",
    "    print(\"before:\\n\", df_file['ABV'].head(n=1))\n",
    "    # remove the currency sign prefix\n",
    "    # Step 1: Remove non-digit characters (like '?', ',')\n",
    "    if df_file['ABV'].dtype == 'object':\n",
    "        # Check if the column is of type object\n",
    "        # If so, remove non-digit characters\n",
    "        df_file['ABV'] = df_file['ABV'].str.replace(r'ABV\\s*', '', regex=True).str.replace('%', '', regex=False)\n",
    "        df_file['ABV'] = pd.to_numeric(df_file['ABV'], errors='coerce')\n",
    "\n",
    "\n",
    "    # Step 2: Convert the column to integers\n",
    "    df_file['ABV'] = pd.to_numeric(df_file['ABV'])\n",
    "    print(\"after:\\n\", df_file['ABV'].head(n=1))\n",
    "\n",
    "    # remove rows with missing values in the Price column\n",
    "    df_file.dropna(subset=['ABV'], inplace=True)\n",
    "\n",
    "    print(f\"Dataframe shape before/after cleaning: {df_size} / {df_file.shape}\")\n",
    "\n",
    "# Make the vintage have None when not an integer\n",
    "for df_file in dataset_files_cleaned:\n",
    "\n",
    "    df_size = df_file.shape\n",
    "\n",
    "    # print the first 3 rows of the Price column\n",
    "    print(\"before:\\n\", df_file['Vintage'].head(n=1))\n",
    "    # remove the currency sign prefix\n",
    "    # Step 1: Remove non-digit characters (like '?', ',')\n",
    "    if df_file['Vintage'].dtype == 'object':\n",
    "        # Check if the column is of type object\n",
    "        # If so, remove non-digit characters\n",
    "        df_file['Vintage'] = df_file['Vintage'].str.replace(r'Vintage\\s*', '', regex=True).str.replace('%', '', regex=False)\n",
    "        df_file['Vintage'] = pd.to_numeric(df_file['Vintage'], errors='coerce')\n",
    "\n",
    "\n",
    "    # Step 2: Convert the column to integers\n",
    "    df_file['Vintage'] = pd.to_numeric(df_file['Vintage'])\n",
    "    print(\"after:\\n\", df_file['Vintage'].head(n=1))\n",
    "\n",
    "    print(f\"Dataframe shape before/after cleaning: {df_size} / {df_file.shape}\")\n",
    "\n",
    "# dataset_files_cleaned = tmp_df\n",
    "dataset_files_by_hand_cleaned = dataset_files_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581b17e1",
   "metadata": {},
   "source": [
    "### Now it is time to visualize our changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1500c210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Capacity</th>\n",
       "      <th>Grape</th>\n",
       "      <th>Closure</th>\n",
       "      <th>Country</th>\n",
       "      <th>Unit</th>\n",
       "      <th>Characteristics</th>\n",
       "      <th>Per bottle / case / each</th>\n",
       "      <th>Type</th>\n",
       "      <th>ABV</th>\n",
       "      <th>Region</th>\n",
       "      <th>Style</th>\n",
       "      <th>Vintage</th>\n",
       "      <th>Appellation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Guv'nor, Spain</td>\n",
       "      <td>We asked some of our most prized winemakers wo...</td>\n",
       "      <td>999</td>\n",
       "      <td>75CL</td>\n",
       "      <td>Tempranillo</td>\n",
       "      <td>Natural Cork</td>\n",
       "      <td>Spain</td>\n",
       "      <td>10.5</td>\n",
       "      <td>Vanilla, Blackberry, Blackcurrant</td>\n",
       "      <td>per bottle</td>\n",
       "      <td>Red</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rich &amp; Juicy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bread &amp; Butter 'Winemaker's Selection' Chardon...</td>\n",
       "      <td>This really does what it says on the tin. It’s...</td>\n",
       "      <td>1599</td>\n",
       "      <td>75CL</td>\n",
       "      <td>Chardonnay</td>\n",
       "      <td>Natural Cork</td>\n",
       "      <td>USA</td>\n",
       "      <td>10.1</td>\n",
       "      <td>Vanilla, Almond, Coconut, Green Apple, Peach, ...</td>\n",
       "      <td>per bottle</td>\n",
       "      <td>White</td>\n",
       "      <td>13.5</td>\n",
       "      <td>California</td>\n",
       "      <td>Rich &amp; Toasty</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>Napa Valley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Oyster Bay Sauvignon Blanc 2022, Marlborough</td>\n",
       "      <td>Oyster Bay has been an award-winning gold-stan...</td>\n",
       "      <td>1249</td>\n",
       "      <td>75CL</td>\n",
       "      <td>Sauvignon Blanc</td>\n",
       "      <td>Screwcap</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>9.8</td>\n",
       "      <td>Tropical Fruit, Gooseberry, Grapefruit, Grass,...</td>\n",
       "      <td>per bottle</td>\n",
       "      <td>White</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Marlborough</td>\n",
       "      <td>Crisp &amp; Zesty</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0                                 The Guv'nor, Spain   \n",
       "1  Bread & Butter 'Winemaker's Selection' Chardon...   \n",
       "2       Oyster Bay Sauvignon Blanc 2022, Marlborough   \n",
       "\n",
       "                                         Description  Price Capacity  \\\n",
       "0  We asked some of our most prized winemakers wo...    999     75CL   \n",
       "1  This really does what it says on the tin. It’s...   1599     75CL   \n",
       "2  Oyster Bay has been an award-winning gold-stan...   1249     75CL   \n",
       "\n",
       "             Grape       Closure      Country  Unit  \\\n",
       "0      Tempranillo  Natural Cork        Spain  10.5   \n",
       "1       Chardonnay  Natural Cork          USA  10.1   \n",
       "2  Sauvignon Blanc      Screwcap  New Zealand   9.8   \n",
       "\n",
       "                                     Characteristics Per bottle / case / each  \\\n",
       "0                  Vanilla, Blackberry, Blackcurrant               per bottle   \n",
       "1  Vanilla, Almond, Coconut, Green Apple, Peach, ...               per bottle   \n",
       "2  Tropical Fruit, Gooseberry, Grapefruit, Grass,...               per bottle   \n",
       "\n",
       "    Type   ABV       Region          Style  Vintage  Appellation  \n",
       "0    Red  14.0          NaN   Rich & Juicy      NaN          NaN  \n",
       "1  White  13.5   California  Rich & Toasty   2021.0  Napa Valley  \n",
       "2  White  13.0  Marlborough  Crisp & Zesty   2022.0          NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "dataset_files_by_hand_cleaned[0].head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f71269d",
   "metadata": {},
   "source": [
    "Let's figure out which columns should be viewed as categorical / numerical / textual\n",
    "\n",
    "we can start with a simple heuristic:\n",
    "1. numerical is everything which\n",
    "    - keeps most of its character length after non-numeral strip\n",
    "    - has about the same number of unique values after the strip\n",
    "    + for the purpose of keeping \"semantic information\", hand picked columns can be viewed also as non-numerical, that is not the default benchmark approach though\n",
    "\n",
    "2. categorical is everthing non numerical, which can be then divided into N (where N << Num instances) unique categories\n",
    "\n",
    "3. textual is everything else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "436f9ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Threshold for categorical vs textual: 50\n",
      "Numerical columns (3): ['Price', 'Capacity', 'Unit']\n",
      "Categorical columns (7): ['Closure', 'Country', 'Per bottle / case / each', 'Type', 'ABV', 'Style', 'Vintage']\n",
      "Textual columns (6): ['Title', 'Description', 'Grape', 'Characteristics', 'Region', 'Appellation']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def is_mostly_numeric(series, length_threshold=0.5, unique_threshold=0.8):\n",
    "    \"\"\"Check if column is mostly numeric after stripping non-numeric chars.\"\"\"\n",
    "    stripped = series.astype(str).str.replace(r\"[^\\d\\.\\-]\", \"\", regex=True)\n",
    "    \n",
    "    original_len = series.astype(str).str.len().replace(0, 1)  # avoid div by zero\n",
    "    length_ratio = (stripped.str.len() / original_len).mean()\n",
    "\n",
    "    unique_ratio = stripped.nunique(dropna=False) / max(series.nunique(dropna=False), 1)\n",
    "\n",
    "    return length_ratio > length_threshold and unique_ratio > unique_threshold\n",
    "\n",
    "def classify_columns(df, unique_ratio_threshold=None, explicit_nunique_threshold=None):\n",
    "    \"\"\"\n",
    "    Classify dataframe columns into numerical, categorical, textual.\n",
    "    - Binary categorical (2 unique values) is considered categorical.\n",
    "    \"\"\"\n",
    "    n_rows = len(df)\n",
    "\n",
    "    # Determine threshold for categorical vs textual\n",
    "    if explicit_nunique_threshold is not None:\n",
    "        nunique_threshold = explicit_nunique_threshold\n",
    "    elif unique_ratio_threshold is not None:\n",
    "        nunique_threshold = int(unique_ratio_threshold * n_rows)\n",
    "    else:\n",
    "        nunique_threshold = int(0.05 * n_rows)  # default 5%\n",
    "\n",
    "    nunique_threshold = max(10, nunique_threshold)  # safeguard\n",
    "    print(f\"Threshold for categorical vs textual: {nunique_threshold}\")\n",
    "\n",
    "    numerical_cols = []\n",
    "    categorical_cols = []\n",
    "    textual_cols = []\n",
    "\n",
    "    for col in df.columns:\n",
    "        series = df[col]\n",
    "        nunique = series.nunique(dropna=False)\n",
    "\n",
    "        if pd.api.types.is_numeric_dtype(series):\n",
    "            if nunique <= nunique_threshold:\n",
    "                categorical_cols.append(col)\n",
    "            else:\n",
    "                numerical_cols.append(col)\n",
    "        \n",
    "        elif pd.api.types.is_string_dtype(series) or pd.api.types.is_object_dtype(series):\n",
    "            if is_mostly_numeric(series):\n",
    "                numerical_cols.append(col)\n",
    "            else:\n",
    "                if nunique <= nunique_threshold:\n",
    "                    categorical_cols.append(col)\n",
    "                else:\n",
    "                    textual_cols.append(col)\n",
    "        else:\n",
    "            print(f\"⚠️ Unhandled column type: '{col}' (dtype={series.dtype})\")\n",
    "\n",
    "    print(f\"Numerical columns ({len(numerical_cols)}): {numerical_cols}\")\n",
    "    print(f\"Categorical columns ({len(categorical_cols)}): {categorical_cols}\")\n",
    "    print(f\"Textual columns ({len(textual_cols)}): {textual_cols}\")\n",
    "\n",
    "    return numerical_cols, categorical_cols, textual_cols\n",
    "\n",
    "# Example usage:\n",
    "for df_file in dataset_files_by_hand_cleaned:\n",
    "    # Ratio-based (5% of rows)\n",
    "    # umerical_cols, categorical_cols, textual_cols = classify_columns(df_file, unique_ratio_threshold=0.05)\n",
    "    print(\"\")\n",
    "    # OR explicit value (e.g., anything <= 50 is categorical)\n",
    "    numerical_cols, categorical_cols, textual_cols = classify_columns(df_file, explicit_nunique_threshold=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6499589b",
   "metadata": {},
   "source": [
    "Now let's just try to visualize the kept features, their example values, and their cat/num/text allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "afffbdb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column Name</th>\n",
       "      <th>Example Value</th>\n",
       "      <th>Type</th>\n",
       "      <th># Categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Title</td>\n",
       "      <td>The Guv'nor, Spain</td>\n",
       "      <td>textual</td>\n",
       "      <td>1280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Description</td>\n",
       "      <td>We asked some of our most prized winemakers wo...</td>\n",
       "      <td>textual</td>\n",
       "      <td>1275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Price</td>\n",
       "      <td>999</td>\n",
       "      <td>numerical</td>\n",
       "      <td>~ 120 ~</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Capacity</td>\n",
       "      <td>75CL</td>\n",
       "      <td>numerical</td>\n",
       "      <td>~ 12 ~</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Grape</td>\n",
       "      <td>Tempranillo</td>\n",
       "      <td>textual</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Closure</td>\n",
       "      <td>Natural Cork</td>\n",
       "      <td>categorical</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Country</td>\n",
       "      <td>Spain</td>\n",
       "      <td>categorical</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Unit</td>\n",
       "      <td>10.5</td>\n",
       "      <td>numerical</td>\n",
       "      <td>~ 55 ~</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Characteristics</td>\n",
       "      <td>Vanilla, Blackberry, Blackcurrant</td>\n",
       "      <td>textual</td>\n",
       "      <td>888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Per bottle / case / each</td>\n",
       "      <td>per bottle</td>\n",
       "      <td>categorical</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Type</td>\n",
       "      <td>Red</td>\n",
       "      <td>categorical</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ABV</td>\n",
       "      <td>14.0</td>\n",
       "      <td>categorical</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Region</td>\n",
       "      <td>California</td>\n",
       "      <td>textual</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Style</td>\n",
       "      <td>Rich &amp; Juicy</td>\n",
       "      <td>categorical</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Vintage</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>categorical</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Appellation</td>\n",
       "      <td>Napa Valley</td>\n",
       "      <td>textual</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Column Name  \\\n",
       "0                      Title   \n",
       "1                Description   \n",
       "2                      Price   \n",
       "3                   Capacity   \n",
       "4                      Grape   \n",
       "5                    Closure   \n",
       "6                    Country   \n",
       "7                       Unit   \n",
       "8            Characteristics   \n",
       "9   Per bottle / case / each   \n",
       "10                      Type   \n",
       "11                       ABV   \n",
       "12                    Region   \n",
       "13                     Style   \n",
       "14                   Vintage   \n",
       "15               Appellation   \n",
       "\n",
       "                                        Example Value         Type  \\\n",
       "0                                  The Guv'nor, Spain      textual   \n",
       "1   We asked some of our most prized winemakers wo...      textual   \n",
       "2                                                 999    numerical   \n",
       "3                                                75CL    numerical   \n",
       "4                                         Tempranillo      textual   \n",
       "5                                        Natural Cork  categorical   \n",
       "6                                               Spain  categorical   \n",
       "7                                                10.5    numerical   \n",
       "8                   Vanilla, Blackberry, Blackcurrant      textual   \n",
       "9                                          per bottle  categorical   \n",
       "10                                                Red  categorical   \n",
       "11                                               14.0  categorical   \n",
       "12                                         California      textual   \n",
       "13                                       Rich & Juicy  categorical   \n",
       "14                                             2021.0  categorical   \n",
       "15                                        Napa Valley      textual   \n",
       "\n",
       "   # Categories  \n",
       "0          1280  \n",
       "1          1275  \n",
       "2       ~ 120 ~  \n",
       "3        ~ 12 ~  \n",
       "4           112  \n",
       "5             4  \n",
       "6            25  \n",
       "7        ~ 55 ~  \n",
       "8           888  \n",
       "9             2  \n",
       "10            6  \n",
       "11           33  \n",
       "12           94  \n",
       "13           16  \n",
       "14           21  \n",
       "15          179  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary = []\n",
    "for col in df_file.columns:\n",
    "    if col in categorical_cols:\n",
    "        col_type = \"categorical\"\n",
    "        num_categories = df_file[col].nunique(dropna=True)\n",
    "        num_categories_display = int(num_categories)\n",
    "    elif col in textual_cols:\n",
    "        col_type = \"textual\"\n",
    "        num_categories = df_file[col].nunique(dropna=True)\n",
    "        num_categories_display = int(num_categories)\n",
    "    elif col in numerical_cols:\n",
    "        col_type = \"numerical\"\n",
    "        num_categories = df_file[col].nunique(dropna=True)\n",
    "        num_categories_display = '~ ' + str(num_categories) + ' ~'\n",
    "    else:\n",
    "        col_type = \"unknown\"\n",
    "        num_categories_display = '--'\n",
    "\n",
    "    example = df_file[col].dropna().iloc[0] if df_file[col].dropna().size > 0 else None\n",
    "    summary.append({\n",
    "        'Column Name': col,\n",
    "        'Example Value': str(example),\n",
    "        'Type': col_type,\n",
    "        '# Categories': num_categories_display\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary)\n",
    "\n",
    "# TODO: by hand changes of the type and category count -> e.g. for 'Location':\n",
    "#    # Post-processing: override the type and category count for 'Location'\n",
    "#    # summary_df.loc[summary_df['Column Name'] == 'Location', 'Type'] = 'textual'\n",
    "#    # num_categories = df_file['Location'].nunique(dropna=True)\n",
    "#    # summary_df.loc[summary_df['Column Name'] == 'Location', '# Categories'] = int(num_categories)\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "display(summary_df)  # Or print(summary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b9f5ee9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['75CL', '70CL', '750ML', '1.5LTR', '37.5CL', '2.25L', '500ML',\n",
       "       '50CL', '150CL', '300CL', '5LITRE', '375ML'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print capacitty unique values\n",
    "df_file['Capacity'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25ee8e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need  to transform the capacity to a standardized format -> ML\n",
    "\n",
    "cap_dict = {\n",
    "    'ml': 1,\n",
    "    'cl': 10,\n",
    "    'dl': 100,\n",
    "    'l': 1000,\n",
    "    'litre': 1000,\n",
    "    'ltr': 1000,\n",
    "}\n",
    "\n",
    "def standardize_capacity(value):\n",
    "    # 1. extract the numeric part\n",
    "    numeric_part = re.sub(r'[^0-9.]+', '', value)\n",
    "    # 2. extract the unit part\n",
    "    unit_part = re.sub(r'[0-9.]+', '', value)\n",
    "    # 3. convert to lower case\n",
    "    unit_part = unit_part.lower()\n",
    "    # 4. convert to ml\n",
    "    if unit_part in cap_dict:\n",
    "        return float(numeric_part) * cap_dict[unit_part]\n",
    "    else:\n",
    "        print(f\"Unknown unit: {unit_part}\")\n",
    "        return None\n",
    "    \n",
    "# Apply the function to the Capacity column\n",
    "for df_file in dataset_files_by_hand_cleaned:\n",
    "    if 'Capacity' in df_file.columns:\n",
    "        def safe_standardize(val):\n",
    "            if isinstance(val, str):\n",
    "                return standardize_capacity(val)\n",
    "            else:\n",
    "                return val  # leave numbers, NaN untouched\n",
    "\n",
    "        df_file['Capacity'] = df_file['Capacity'].apply(safe_standardize)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ee4b7d",
   "metadata": {},
   "source": [
    "#### We also need to make sure that numerical columns are actually numerical :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53a6fe00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column Name</th>\n",
       "      <th>Example Value</th>\n",
       "      <th>Type</th>\n",
       "      <th># Categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Title</td>\n",
       "      <td>The Guv'nor, Spain</td>\n",
       "      <td>textual</td>\n",
       "      <td>1280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Description</td>\n",
       "      <td>We asked some of our most prized winemakers wo...</td>\n",
       "      <td>textual</td>\n",
       "      <td>1275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Price</td>\n",
       "      <td>999.0</td>\n",
       "      <td>numerical</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Capacity</td>\n",
       "      <td>750.0</td>\n",
       "      <td>numerical</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Grape</td>\n",
       "      <td>Tempranillo</td>\n",
       "      <td>textual</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Closure</td>\n",
       "      <td>Natural Cork</td>\n",
       "      <td>categorical</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Country</td>\n",
       "      <td>Spain</td>\n",
       "      <td>categorical</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Unit</td>\n",
       "      <td>10.5</td>\n",
       "      <td>numerical</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Characteristics</td>\n",
       "      <td>Vanilla, Blackberry, Blackcurrant</td>\n",
       "      <td>textual</td>\n",
       "      <td>888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Per bottle / case / each</td>\n",
       "      <td>per bottle</td>\n",
       "      <td>categorical</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Type</td>\n",
       "      <td>Red</td>\n",
       "      <td>categorical</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ABV</td>\n",
       "      <td>14.0</td>\n",
       "      <td>categorical</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Region</td>\n",
       "      <td>California</td>\n",
       "      <td>textual</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Style</td>\n",
       "      <td>Rich &amp; Juicy</td>\n",
       "      <td>categorical</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Vintage</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>categorical</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Appellation</td>\n",
       "      <td>Napa Valley</td>\n",
       "      <td>textual</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Column Name  \\\n",
       "0                      Title   \n",
       "1                Description   \n",
       "2                      Price   \n",
       "3                   Capacity   \n",
       "4                      Grape   \n",
       "5                    Closure   \n",
       "6                    Country   \n",
       "7                       Unit   \n",
       "8            Characteristics   \n",
       "9   Per bottle / case / each   \n",
       "10                      Type   \n",
       "11                       ABV   \n",
       "12                    Region   \n",
       "13                     Style   \n",
       "14                   Vintage   \n",
       "15               Appellation   \n",
       "\n",
       "                                        Example Value         Type  \\\n",
       "0                                  The Guv'nor, Spain      textual   \n",
       "1   We asked some of our most prized winemakers wo...      textual   \n",
       "2                                               999.0    numerical   \n",
       "3                                               750.0    numerical   \n",
       "4                                         Tempranillo      textual   \n",
       "5                                        Natural Cork  categorical   \n",
       "6                                               Spain  categorical   \n",
       "7                                                10.5    numerical   \n",
       "8                   Vanilla, Blackberry, Blackcurrant      textual   \n",
       "9                                          per bottle  categorical   \n",
       "10                                                Red  categorical   \n",
       "11                                               14.0  categorical   \n",
       "12                                         California      textual   \n",
       "13                                       Rich & Juicy  categorical   \n",
       "14                                             2021.0  categorical   \n",
       "15                                        Napa Valley      textual   \n",
       "\n",
       "   # Categories  \n",
       "0          1280  \n",
       "1          1275  \n",
       "2           120  \n",
       "3             8  \n",
       "4           112  \n",
       "5             4  \n",
       "6            25  \n",
       "7            55  \n",
       "8           888  \n",
       "9             2  \n",
       "10            6  \n",
       "11           33  \n",
       "12           94  \n",
       "13           16  \n",
       "14           21  \n",
       "15          179  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "from dataloader_functions.load_and_pp_raw_data import clean_numerical_columns\n",
    "\n",
    "summary_df, dataset_files_by_hand_cleaned = clean_numerical_columns(summary_df, dataset_files_by_hand_cleaned)\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "display(summary_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea6209c",
   "metadata": {},
   "source": [
    "### Saving the processed data and loading it back up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a90beb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/regression/../../datasets_files/raw/regression/wine/wine_processed.pkl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Handle rename_files fallback\n",
    "if dataset_config['rename_files'] is None or len(dataset_config['rename_files']) == 0:\n",
    "    dataset_config['rename_files'] = dataset_config['files']\n",
    "\n",
    "for i, df_file in enumerate(dataset_files_by_hand_cleaned):\n",
    "    df_with_meta = df_file.copy()\n",
    "\n",
    "    # Get corresponding file name\n",
    "    file_name = dataset_config['rename_files'][i]\n",
    "    file_base = os.path.splitext(file_name)[0]\n",
    "\n",
    "    # Try assigning multi-index header from summary\n",
    "    try:\n",
    "        df_with_meta.columns = pd.MultiIndex.from_frame(\n",
    "            summary_df[['Column Name', 'Type', '# Categories']]\n",
    "        )\n",
    "        local_summary = summary_df.copy()\n",
    "    except ValueError:\n",
    "        local_summary = summary_df.copy()\n",
    "        if dataset_config['target'] in local_summary['Column Name'].values:\n",
    "            local_summary = local_summary[local_summary['Column Name'] != dataset_config['target']]\n",
    "            df_with_meta.columns = pd.MultiIndex.from_frame(\n",
    "                local_summary[['Column Name', 'Type', '# Categories']]\n",
    "            )\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "    # Construct and save everything together\n",
    "    output_filename = f\"{file_base}_processed.pkl\"\n",
    "    output_path = os.path.join(download_path, output_filename)\n",
    "\n",
    "    save_bundle = {\n",
    "        'data': df_with_meta,\n",
    "        'summary': local_summary,\n",
    "        'config': dataset_config\n",
    "    }\n",
    "\n",
    "    pd.to_pickle(save_bundle, output_path)\n",
    "    print(f\"Saved: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "626bcd8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== WINE ===\n",
      "Loaded config keys: ['dataset_name', 'source', 'remote_path', 'files', 'rename_files', 'task', 'target']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column Name</th>\n",
       "      <th>Type</th>\n",
       "      <th># Categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Title</td>\n",
       "      <td>textual</td>\n",
       "      <td>1280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Description</td>\n",
       "      <td>textual</td>\n",
       "      <td>1275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Price</td>\n",
       "      <td>numerical</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Capacity</td>\n",
       "      <td>numerical</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Grape</td>\n",
       "      <td>textual</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Closure</td>\n",
       "      <td>categorical</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Country</td>\n",
       "      <td>categorical</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Unit</td>\n",
       "      <td>numerical</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Characteristics</td>\n",
       "      <td>textual</td>\n",
       "      <td>888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Per bottle / case / each</td>\n",
       "      <td>categorical</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Type</td>\n",
       "      <td>categorical</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ABV</td>\n",
       "      <td>categorical</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Region</td>\n",
       "      <td>textual</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Style</td>\n",
       "      <td>categorical</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Vintage</td>\n",
       "      <td>categorical</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Appellation</td>\n",
       "      <td>textual</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Column Name         Type  # Categories\n",
       "0                      Title      textual          1280\n",
       "1                Description      textual          1275\n",
       "2                      Price    numerical           120\n",
       "3                   Capacity    numerical             8\n",
       "4                      Grape      textual           112\n",
       "5                    Closure  categorical             4\n",
       "6                    Country  categorical            25\n",
       "7                       Unit    numerical            55\n",
       "8            Characteristics      textual           888\n",
       "9   Per bottle / case / each  categorical             2\n",
       "10                      Type  categorical             6\n",
       "11                       ABV  categorical            33\n",
       "12                    Region      textual            94\n",
       "13                     Style  categorical            16\n",
       "14                   Vintage  categorical            21\n",
       "15               Appellation      textual           179"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Column Name</th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Capacity</th>\n",
       "      <th>Grape</th>\n",
       "      <th>Closure</th>\n",
       "      <th>Country</th>\n",
       "      <th>Unit</th>\n",
       "      <th>Characteristics</th>\n",
       "      <th>Per bottle / case / each</th>\n",
       "      <th>Type</th>\n",
       "      <th>ABV</th>\n",
       "      <th>Region</th>\n",
       "      <th>Style</th>\n",
       "      <th>Vintage</th>\n",
       "      <th>Appellation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Guv'nor, Spain</td>\n",
       "      <td>We asked some of our most prized winemakers wo...</td>\n",
       "      <td>999.0</td>\n",
       "      <td>750.0</td>\n",
       "      <td>Tempranillo</td>\n",
       "      <td>Natural Cork</td>\n",
       "      <td>Spain</td>\n",
       "      <td>10.5</td>\n",
       "      <td>Vanilla, Blackberry, Blackcurrant</td>\n",
       "      <td>per bottle</td>\n",
       "      <td>Red</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rich &amp; Juicy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bread &amp; Butter 'Winemaker's Selection' Chardon...</td>\n",
       "      <td>This really does what it says on the tin. It’s...</td>\n",
       "      <td>1599.0</td>\n",
       "      <td>750.0</td>\n",
       "      <td>Chardonnay</td>\n",
       "      <td>Natural Cork</td>\n",
       "      <td>USA</td>\n",
       "      <td>10.1</td>\n",
       "      <td>Vanilla, Almond, Coconut, Green Apple, Peach, ...</td>\n",
       "      <td>per bottle</td>\n",
       "      <td>White</td>\n",
       "      <td>13.5</td>\n",
       "      <td>California</td>\n",
       "      <td>Rich &amp; Toasty</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>Napa Valley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Oyster Bay Sauvignon Blanc 2022, Marlborough</td>\n",
       "      <td>Oyster Bay has been an award-winning gold-stan...</td>\n",
       "      <td>1249.0</td>\n",
       "      <td>750.0</td>\n",
       "      <td>Sauvignon Blanc</td>\n",
       "      <td>Screwcap</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>9.8</td>\n",
       "      <td>Tropical Fruit, Gooseberry, Grapefruit, Grass,...</td>\n",
       "      <td>per bottle</td>\n",
       "      <td>White</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Marlborough</td>\n",
       "      <td>Crisp &amp; Zesty</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Column Name                                              Title  \\\n",
       "0                                           The Guv'nor, Spain   \n",
       "1            Bread & Butter 'Winemaker's Selection' Chardon...   \n",
       "2                 Oyster Bay Sauvignon Blanc 2022, Marlborough   \n",
       "\n",
       "Column Name                                        Description   Price  \\\n",
       "0            We asked some of our most prized winemakers wo...   999.0   \n",
       "1            This really does what it says on the tin. It’s...  1599.0   \n",
       "2            Oyster Bay has been an award-winning gold-stan...  1249.0   \n",
       "\n",
       "Column Name  Capacity            Grape       Closure      Country  Unit  \\\n",
       "0               750.0      Tempranillo  Natural Cork        Spain  10.5   \n",
       "1               750.0       Chardonnay  Natural Cork          USA  10.1   \n",
       "2               750.0  Sauvignon Blanc      Screwcap  New Zealand   9.8   \n",
       "\n",
       "Column Name                                    Characteristics  \\\n",
       "0                            Vanilla, Blackberry, Blackcurrant   \n",
       "1            Vanilla, Almond, Coconut, Green Apple, Peach, ...   \n",
       "2            Tropical Fruit, Gooseberry, Grapefruit, Grass,...   \n",
       "\n",
       "Column Name Per bottle / case / each   Type   ABV       Region          Style  \\\n",
       "0                         per bottle    Red  14.0          NaN   Rich & Juicy   \n",
       "1                         per bottle  White  13.5   California  Rich & Toasty   \n",
       "2                         per bottle  White  13.0  Marlborough  Crisp & Zesty   \n",
       "\n",
       "Column Name  Vintage  Appellation  \n",
       "0                NaN          NaN  \n",
       "1             2021.0  Napa Valley  \n",
       "2             2022.0          NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Loop through processed files in rename_files\n",
    "for file_name in dataset_config['rename_files']:\n",
    "    # Remove .csv or .tsv extension to get the base name\n",
    "    file_base = os.path.splitext(file_name)[0]\n",
    "    processed_filename = f\"{file_base}_processed.pkl\"\n",
    "    processed_path = os.path.join(download_path, processed_filename)\n",
    "\n",
    "    # Load the bundled dictionary (data + summary + config)\n",
    "    bundle = pd.read_pickle(processed_path)\n",
    "\n",
    "    # Extract components\n",
    "    loaded_df = bundle['data']\n",
    "    summary_df = bundle['summary']\n",
    "    loaded_config = bundle['config']\n",
    "\n",
    "    print(f\"\\n=== {file_base.upper()} ===\")\n",
    "    print(f\"Loaded config keys: {list(loaded_config.keys())}\")\n",
    "\n",
    "    # Show metadata\n",
    "    meta_df = pd.DataFrame(loaded_df.columns.tolist(), columns=['Column Name', 'Type', '# Categories'])\n",
    "    display(meta_df)\n",
    "\n",
    "    # Flatten for modeling\n",
    "    loaded_df.columns = loaded_df.columns.get_level_values(0)\n",
    "    display(loaded_df.head(n=3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821d6af7",
   "metadata": {},
   "source": [
    "### Bonus insights (Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "798d7597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Get target series\n",
    "target_series = loaded_df[dataset_config['target']]\n",
    "\n",
    "# 1️⃣ Histogram with Freedman-Diaconis rule for binning\n",
    "q25, q75 = np.percentile(target_series, [25, 75])\n",
    "iqr = q75 - q25\n",
    "bin_width = 2 * iqr * len(target_series) ** (-1/3)\n",
    "bin_count = int((target_series.max() - target_series.min()) / bin_width)\n",
    "bin_count = max(10, bin_count)  # Ensure reasonable minimum bin count\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(target_series, bins=bin_count, edgecolor='black', alpha=0.7)\n",
    "plt.title(f\"Histogram of '{dataset_config['target']}' (Adaptive Binning)\")\n",
    "plt.xlabel(dataset_config['target'])\n",
    "plt.ylabel('Count')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2️⃣ Cumulative Distribution Function (CDF)\n",
    "target_sorted = target_series.sort_values()\n",
    "cdf = np.arange(len(target_sorted)) / len(target_sorted)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(target_sorted, cdf, color='tab:blue')\n",
    "plt.title(f\"Cumulative Distribution of '{dataset_config['target']}'\")\n",
    "plt.xlabel(dataset_config['target'])\n",
    "plt.ylabel('Cumulative Probability')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c264b5d9-cf50-42ad-bf19-ed217494a2ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250521_160032\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #53~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Jan 15 19:18:46 UTC 2\n",
      "CPU Count:          64\n",
      "Memory Avail:       313.25 GB / 503.54 GB (62.2%)\n",
      "Disk Space Avail:   33796.64 GB / 51214.59 GB (66.0%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[WRAPPER] Running stratified downsampling mode for task: reg\n",
      "\u001b[1;36mInfo:\u001b[0m \n",
      "[INFO] Downsampling dataframe: wine (original rows: 1281)\n",
      "\u001b[1;33mInfo:\u001b[0m Dataset has only 1281 rows. No downsampling needed.\n",
      "Downsampled 1281 rows for wine dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Beginning AutoGluon training ... Time limit = 360s\n",
      "AutoGluon will save models to \"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/regression/AutogluonModels/ag-20250521_160032\"\n",
      "Train Data Rows:    1024\n",
      "Train Data Columns: 15\n",
      "Label Column:       Price\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    320760.23 MB\n",
      "\tTrain Data (Original)  Memory Usage: 1.92 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['Title', 'Description', 'Characteristics']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 713\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])        : 4 | ['Capacity', 'Unit', 'ABV', 'Vintage']\n",
      "\t\t('object', [])       : 8 | ['Grape', 'Closure', 'Country', 'Per bottle / case / each', 'Type', ...]\n",
      "\t\t('object', ['text']) : 3 | ['Title', 'Description', 'Characteristics']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    :   7 | ['Grape', 'Closure', 'Country', 'Type', 'Region', ...]\n",
      "\t\t('category', ['text_as_category'])  :   2 | ['Description', 'Characteristics']\n",
      "\t\t('float', [])                       :   4 | ['Capacity', 'Unit', 'ABV', 'Vintage']\n",
      "\t\t('int', ['binned', 'text_special']) :  42 | ['Title.char_count', 'Title.word_count', 'Title.capital_ratio', 'Title.lower_ratio', 'Title.digit_ratio', ...]\n",
      "\t\t('int', ['bool'])                   :   1 | ['Per bottle / case / each']\n",
      "\t\t('int', ['text_ngram'])             : 693 | ['__nlp__.10', '__nlp__.100', '__nlp__.18', '__nlp__.19', '__nlp__.20', ...]\n",
      "\t10.6s = Fit runtime\n",
      "\t15 features in original data used to generate 749 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.44 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 10.66s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 232.83s of the 349.32s of remaining time.\n",
      "\t0.2\t = Validation score   (r2)\n",
      "\t0.13s\t = Training   runtime\n",
      "\t0.23s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 232.24s of the 348.72s of remaining time.\n",
      "\t0.2025\t = Validation score   (r2)\n",
      "\t0.12s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 231.76s of the 348.24s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.05%)\n",
      "\t0.5286\t = Validation score   (r2)\n",
      "\t120.95s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 88.53s of the 205.01s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.04%)\n",
      "\t0.5515\t = Validation score   (r2)\n",
      "\t89.77s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 349.34s of the 111.59s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBM_BAG_L1': 0.786, 'LightGBMXT_BAG_L1': 0.214}\n",
      "\t0.5533\t = Validation score   (r2)\n",
      "\t0.1s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 106 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 111.44s of the 111.38s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.04%)\n",
      "\t0.5215\t = Validation score   (r2)\n",
      "\t85.67s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 22.63s of the 22.58s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.04%)\n",
      "\t0.4681\t = Validation score   (r2)\n",
      "\t43.19s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 349.34s of the -24.12s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBM_BAG_L1': 0.786, 'LightGBMXT_BAG_L1': 0.214}\n",
      "\t0.5533\t = Validation score   (r2)\n",
      "\t0.1s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 384.32s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 484.6 rows/s (128 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/regression/AutogluonModels/ag-20250521_160032\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250521_160657\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #53~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Jan 15 19:18:46 UTC 2\n",
      "CPU Count:          64\n",
      "Memory Avail:       332.17 GB / 503.54 GB (66.0%)\n",
      "Disk Space Avail:   33796.49 GB / 51214.59 GB (66.0%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ... Time limit = 360s\n",
      "AutoGluon will save models to \"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/regression/AutogluonModels/ag-20250521_160657\"\n",
      "Train Data Rows:    1024\n",
      "Train Data Columns: 9\n",
      "Label Column:       Price\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    340166.50 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.36 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 4 | ['Capacity', 'Unit', 'ABV', 'Vintage']\n",
      "\t\t('object', []) : 5 | ['Closure', 'Country', 'Per bottle / case / each', 'Type', 'Style']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 4 | ['Closure', 'Country', 'Type', 'Style']\n",
      "\t\t('float', [])     : 4 | ['Capacity', 'Unit', 'ABV', 'Vintage']\n",
      "\t\t('int', ['bool']) : 1 | ['Per bottle / case / each']\n",
      "\t0.1s = Fit runtime\n",
      "\t9 features in original data used to generate 9 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.04 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.13s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 239.85s of the 359.84s of remaining time.\n",
      "\t0.2237\t = Validation score   (r2)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 239.76s of the 359.75s of remaining time.\n",
      "\t0.1951\t = Validation score   (r2)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 239.67s of the 359.66s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.5067\t = Validation score   (r2)\n",
      "\t87.4s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 149.62s of the 269.61s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.4833\t = Validation score   (r2)\n",
      "\t57.37s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 89.63s of the 209.63s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.3192\t = Validation score   (r2)\n",
      "\t1.18s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 87.97s of the 207.96s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.12%)\n",
      "\t0.4726\t = Validation score   (r2)\n",
      "\t61.03s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 24.34s of the 144.33s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.3528\t = Validation score   (r2)\n",
      "\t0.99s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 22.90s of the 142.90s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.4553\t = Validation score   (r2)\n",
      "\t83.33s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 359.87s of the 56.49s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.667, 'NeuralNetFastAI_BAG_L1': 0.208, 'LightGBM_BAG_L1': 0.083, 'KNeighborsDist_BAG_L1': 0.042}\n",
      "\t0.5132\t = Validation score   (r2)\n",
      "\t0.17s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 106 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 56.27s of the 56.20s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.5003\t = Validation score   (r2)\n",
      "\t55.32s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 359.87s of the -3.24s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.5, 'LightGBMXT_BAG_L2': 0.4, 'NeuralNetFastAI_BAG_L1': 0.1}\n",
      "\t0.5209\t = Validation score   (r2)\n",
      "\t0.18s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 363.49s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 251.3 rows/s (128 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/regression/AutogluonModels/ag-20250521_160657\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250521_161308\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #53~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Jan 15 19:18:46 UTC 2\n",
      "CPU Count:          64\n",
      "Memory Avail:       311.70 GB / 503.54 GB (61.9%)\n",
      "Disk Space Avail:   33796.24 GB / 51214.59 GB (66.0%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ... Time limit = 360s\n",
      "AutoGluon will save models to \"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/regression/AutogluonModels/ag-20250521_161308\"\n",
      "Train Data Rows:    1025\n",
      "Train Data Columns: 15\n",
      "Label Column:       Price\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    319177.86 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.35 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['Title', 'Description', 'Characteristics']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 713\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])        : 4 | ['Capacity', 'Unit', 'ABV', 'Vintage']\n",
      "\t\t('object', [])       : 8 | ['Grape', 'Closure', 'Country', 'Per bottle / case / each', 'Type', ...]\n",
      "\t\t('object', ['text']) : 3 | ['Title', 'Description', 'Characteristics']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    :   7 | ['Grape', 'Closure', 'Country', 'Type', 'Region', ...]\n",
      "\t\t('category', ['text_as_category'])  :   3 | ['Title', 'Description', 'Characteristics']\n",
      "\t\t('float', [])                       :   4 | ['Capacity', 'Unit', 'ABV', 'Vintage']\n",
      "\t\t('int', ['binned', 'text_special']) :  42 | ['Title.char_count', 'Title.word_count', 'Title.capital_ratio', 'Title.lower_ratio', 'Title.digit_ratio', ...]\n",
      "\t\t('int', ['bool'])                   :   1 | ['Per bottle / case / each']\n",
      "\t\t('int', ['text_ngram'])             : 698 | ['__nlp__.10', '__nlp__.100', '__nlp__.12', '__nlp__.18', '__nlp__.19', ...]\n",
      "\t11.3s = Fit runtime\n",
      "\t15 features in original data used to generate 755 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.45 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 11.42s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 232.33s of the 348.54s of remaining time.\n",
      "\t0.159\t = Validation score   (r2)\n",
      "\t0.12s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 231.78s of the 347.99s of remaining time.\n",
      "\t0.1614\t = Validation score   (r2)\n",
      "\t0.11s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 231.31s of the 347.53s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.05%)\n",
      "\t0.471\t = Validation score   (r2)\n",
      "\t88.27s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 139.02s of the 255.23s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.05%)\n",
      "\t0.4732\t = Validation score   (r2)\n",
      "\t77.11s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 57.80s of the 174.02s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.3805\t = Validation score   (r2)\n",
      "\t9.14s\t = Training   runtime\n",
      "\t0.59s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 47.76s of the 163.97s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.33%)\n",
      "\t0.3504\t = Validation score   (r2)\n",
      "\t55.68s\t = Training   runtime\n",
      "\t0.48s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 348.58s of the 103.85s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBM_BAG_L1': 0.5, 'LightGBMXT_BAG_L1': 0.438, 'RandomForestMSE_BAG_L1': 0.062}\n",
      "\t0.4837\t = Validation score   (r2)\n",
      "\t0.14s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 106 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 103.68s of the 103.63s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.05%)\n",
      "\t0.4779\t = Validation score   (r2)\n",
      "\t67.62s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 31.88s of the 31.82s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.05%)\n",
      "\t0.457\t = Validation score   (r2)\n",
      "\t54.44s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 348.58s of the -27.12s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L2': 0.545, 'LightGBM_BAG_L1': 0.455}\n",
      "\t0.4882\t = Validation score   (r2)\n",
      "\t0.14s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 387.32s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 133.1 rows/s (129 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/regression/AutogluonModels/ag-20250521_161308\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250521_161936\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #53~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Jan 15 19:18:46 UTC 2\n",
      "CPU Count:          64\n",
      "Memory Avail:       314.89 GB / 503.54 GB (62.5%)\n",
      "Disk Space Avail:   33796.07 GB / 51214.59 GB (66.0%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ... Time limit = 360s\n",
      "AutoGluon will save models to \"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/regression/AutogluonModels/ag-20250521_161936\"\n",
      "Train Data Rows:    1025\n",
      "Train Data Columns: 9\n",
      "Label Column:       Price\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    322472.94 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.36 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 4 | ['Capacity', 'Unit', 'ABV', 'Vintage']\n",
      "\t\t('object', []) : 5 | ['Closure', 'Country', 'Per bottle / case / each', 'Type', 'Style']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 4 | ['Closure', 'Country', 'Type', 'Style']\n",
      "\t\t('float', [])     : 4 | ['Capacity', 'Unit', 'ABV', 'Vintage']\n",
      "\t\t('int', ['bool']) : 1 | ['Per bottle / case / each']\n",
      "\t0.1s = Fit runtime\n",
      "\t9 features in original data used to generate 9 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.04 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.13s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 239.85s of the 359.85s of remaining time.\n",
      "\t0.2342\t = Validation score   (r2)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 239.79s of the 359.78s of remaining time.\n",
      "\t0.1837\t = Validation score   (r2)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 239.73s of the 359.72s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.453\t = Validation score   (r2)\n",
      "\t54.65s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 181.63s of the 301.62s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.4458\t = Validation score   (r2)\n",
      "\t72.48s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 105.48s of the 225.48s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.2799\t = Validation score   (r2)\n",
      "\t0.91s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 104.16s of the 224.16s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.12%)\n",
      "\t0.4243\t = Validation score   (r2)\n",
      "\t64.61s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 35.97s of the 155.96s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.3383\t = Validation score   (r2)\n",
      "\t1.01s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 34.53s of the 154.52s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.4201\t = Validation score   (r2)\n",
      "\t88.74s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 359.87s of the 61.72s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.412, 'LightGBM_BAG_L1': 0.294, 'NeuralNetFastAI_BAG_L1': 0.176, 'KNeighborsDist_BAG_L1': 0.118}\n",
      "\t0.472\t = Validation score   (r2)\n",
      "\t0.2s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 106 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 61.49s of the 61.42s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.4606\t = Validation score   (r2)\n",
      "\t51.81s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 5.84s of the 5.77s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.0393\t = Validation score   (r2)\n",
      "\t33.91s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 359.87s of the -31.90s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L2': 0.429, 'LightGBMXT_BAG_L1': 0.381, 'KNeighborsDist_BAG_L1': 0.095, 'NeuralNetFastAI_BAG_L1': 0.095}\n",
      "\t0.4747\t = Validation score   (r2)\n",
      "\t0.17s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 392.11s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 262.6 rows/s (129 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/regression/AutogluonModels/ag-20250521_161936\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250521_162610\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #53~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Jan 15 19:18:46 UTC 2\n",
      "CPU Count:          64\n",
      "Memory Avail:       336.72 GB / 503.54 GB (66.9%)\n",
      "Disk Space Avail:   33803.11 GB / 51214.59 GB (66.0%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ... Time limit = 360s\n",
      "AutoGluon will save models to \"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/regression/AutogluonModels/ag-20250521_162610\"\n",
      "Train Data Rows:    1025\n",
      "Train Data Columns: 15\n",
      "Label Column:       Price\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    344819.93 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.38 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['Title', 'Description', 'Characteristics']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 722\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])        : 4 | ['Capacity', 'Unit', 'ABV', 'Vintage']\n",
      "\t\t('object', [])       : 8 | ['Grape', 'Closure', 'Country', 'Per bottle / case / each', 'Type', ...]\n",
      "\t\t('object', ['text']) : 3 | ['Title', 'Description', 'Characteristics']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    :   7 | ['Grape', 'Closure', 'Country', 'Type', 'Region', ...]\n",
      "\t\t('category', ['text_as_category'])  :   2 | ['Description', 'Characteristics']\n",
      "\t\t('float', [])                       :   4 | ['Capacity', 'Unit', 'ABV', 'Vintage']\n",
      "\t\t('int', ['binned', 'text_special']) :  40 | ['Title.char_count', 'Title.word_count', 'Title.capital_ratio', 'Title.lower_ratio', 'Title.digit_ratio', ...]\n",
      "\t\t('int', ['bool'])                   :   1 | ['Per bottle / case / each']\n",
      "\t\t('int', ['text_ngram'])             : 708 | ['__nlp__.10', '__nlp__.100', '__nlp__.18', '__nlp__.19', '__nlp__.20', ...]\n",
      "\t10.9s = Fit runtime\n",
      "\t15 features in original data used to generate 762 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.47 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 10.97s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 232.63s of the 349.01s of remaining time.\n",
      "\t0.1586\t = Validation score   (r2)\n",
      "\t0.14s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 232.19s of the 348.57s of remaining time.\n",
      "\t0.1613\t = Validation score   (r2)\n",
      "\t0.12s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 231.75s of the 348.13s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.04%)\n",
      "\t0.4808\t = Validation score   (r2)\n",
      "\t96.85s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 130.87s of the 247.25s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.04%)\n",
      "\t0.5291\t = Validation score   (r2)\n",
      "\t77.83s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 48.76s of the 165.14s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.4012\t = Validation score   (r2)\n",
      "\t9.29s\t = Training   runtime\n",
      "\t0.6s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 38.53s of the 154.91s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.31%)\n",
      "\t0.3382\t = Validation score   (r2)\n",
      "\t52.38s\t = Training   runtime\n",
      "\t0.46s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 349.03s of the 97.99s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBM_BAG_L1': 1.0}\n",
      "\t0.5291\t = Validation score   (r2)\n",
      "\t0.14s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 106 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 97.82s of the 97.74s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.04%)\n",
      "\t0.5074\t = Validation score   (r2)\n",
      "\t75.64s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 18.31s of the 18.23s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.04%)\n",
      "\t0.4351\t = Validation score   (r2)\n",
      "\t43.58s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 349.03s of the -29.64s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBM_BAG_L1': 0.714, 'LightGBMXT_BAG_L2': 0.286}\n",
      "\t0.5333\t = Validation score   (r2)\n",
      "\t0.15s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 389.87s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 137.1 rows/s (129 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/regression/AutogluonModels/ag-20250521_162610\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250521_163241\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #53~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Jan 15 19:18:46 UTC 2\n",
      "CPU Count:          64\n",
      "Memory Avail:       332.43 GB / 503.54 GB (66.0%)\n",
      "Disk Space Avail:   33802.96 GB / 51214.59 GB (66.0%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ... Time limit = 360s\n",
      "AutoGluon will save models to \"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/regression/AutogluonModels/ag-20250521_163241\"\n",
      "Train Data Rows:    1025\n",
      "Train Data Columns: 9\n",
      "Label Column:       Price\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    340407.61 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.36 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 4 | ['Capacity', 'Unit', 'ABV', 'Vintage']\n",
      "\t\t('object', []) : 5 | ['Closure', 'Country', 'Per bottle / case / each', 'Type', 'Style']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 4 | ['Closure', 'Country', 'Type', 'Style']\n",
      "\t\t('float', [])     : 4 | ['Capacity', 'Unit', 'ABV', 'Vintage']\n",
      "\t\t('int', ['bool']) : 1 | ['Per bottle / case / each']\n",
      "\t0.1s = Fit runtime\n",
      "\t9 features in original data used to generate 9 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.04 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.13s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 239.85s of the 359.85s of remaining time.\n",
      "\t0.2764\t = Validation score   (r2)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 239.79s of the 359.79s of remaining time.\n",
      "\t0.1782\t = Validation score   (r2)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 239.73s of the 359.72s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.4888\t = Validation score   (r2)\n",
      "\t63.58s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 172.60s of the 292.60s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.4651\t = Validation score   (r2)\n",
      "\t66.72s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 102.09s of the 222.09s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.3073\t = Validation score   (r2)\n",
      "\t0.94s\t = Training   runtime\n",
      "\t0.26s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 100.71s of the 220.71s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.11%)\n",
      "\t0.4746\t = Validation score   (r2)\n",
      "\t70.45s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 26.72s of the 146.72s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.3279\t = Validation score   (r2)\n",
      "\t1.03s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 25.27s of the 145.27s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.4542\t = Validation score   (r2)\n",
      "\t85.89s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 359.87s of the 55.45s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.56, 'CatBoost_BAG_L1': 0.24, 'NeuralNetFastAI_BAG_L1': 0.12, 'KNeighborsDist_BAG_L1': 0.08}\n",
      "\t0.4966\t = Validation score   (r2)\n",
      "\t0.17s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 106 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 55.26s of the 55.19s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.4879\t = Validation score   (r2)\n",
      "\t60.22s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 359.87s of the -9.12s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.44, 'LightGBMXT_BAG_L2': 0.44, 'CatBoost_BAG_L1': 0.08, 'KNeighborsDist_BAG_L1': 0.04}\n",
      "\t0.5091\t = Validation score   (r2)\n",
      "\t0.18s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 369.35s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 249.7 rows/s (129 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/regression/AutogluonModels/ag-20250521_163241\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250521_163852\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #53~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Jan 15 19:18:46 UTC 2\n",
      "CPU Count:          64\n",
      "Memory Avail:       332.82 GB / 503.54 GB (66.1%)\n",
      "Disk Space Avail:   33802.81 GB / 51214.59 GB (66.0%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ... Time limit = 360s\n",
      "AutoGluon will save models to \"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/regression/AutogluonModels/ag-20250521_163852\"\n",
      "Train Data Rows:    1025\n",
      "Train Data Columns: 15\n",
      "Label Column:       Price\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    340807.15 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.46 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['Title', 'Description', 'Characteristics']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 724\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])        : 4 | ['Capacity', 'Unit', 'ABV', 'Vintage']\n",
      "\t\t('object', [])       : 8 | ['Grape', 'Closure', 'Country', 'Per bottle / case / each', 'Type', ...]\n",
      "\t\t('object', ['text']) : 3 | ['Title', 'Description', 'Characteristics']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    :   7 | ['Grape', 'Closure', 'Country', 'Type', 'Region', ...]\n",
      "\t\t('category', ['text_as_category'])  :   3 | ['Title', 'Description', 'Characteristics']\n",
      "\t\t('float', [])                       :   4 | ['Capacity', 'Unit', 'ABV', 'Vintage']\n",
      "\t\t('int', ['binned', 'text_special']) :  42 | ['Title.char_count', 'Title.word_count', 'Title.capital_ratio', 'Title.lower_ratio', 'Title.digit_ratio', ...]\n",
      "\t\t('int', ['bool'])                   :   1 | ['Per bottle / case / each']\n",
      "\t\t('int', ['text_ngram'])             : 707 | ['__nlp__.10', '__nlp__.100', '__nlp__.18', '__nlp__.19', '__nlp__.20', ...]\n",
      "\t10.8s = Fit runtime\n",
      "\t15 features in original data used to generate 764 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.47 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 10.9s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 232.67s of the 349.08s of remaining time.\n",
      "\t0.1258\t = Validation score   (r2)\n",
      "\t0.12s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 232.25s of the 348.65s of remaining time.\n",
      "\t0.1312\t = Validation score   (r2)\n",
      "\t0.12s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 231.88s of the 348.29s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.04%)\n",
      "\t0.4598\t = Validation score   (r2)\n",
      "\t97.19s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 130.68s of the 247.08s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.04%)\n",
      "\t0.4206\t = Validation score   (r2)\n",
      "\t75.32s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 51.10s of the 167.50s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.3059\t = Validation score   (r2)\n",
      "\t9.61s\t = Training   runtime\n",
      "\t0.59s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 40.59s of the 156.99s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.32%)\n",
      "\t0.2882\t = Validation score   (r2)\n",
      "\t53.26s\t = Training   runtime\n",
      "\t0.52s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 349.10s of the 99.46s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.92, 'LightGBM_BAG_L1': 0.08}\n",
      "\t0.4601\t = Validation score   (r2)\n",
      "\t0.13s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 106 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 99.30s of the 99.25s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.04%)\n",
      "\t0.4225\t = Validation score   (r2)\n",
      "\t71.38s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 23.93s of the 23.87s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.04%)\n",
      "\t0.404\t = Validation score   (r2)\n",
      "\t48.0s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 349.10s of the -28.32s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.81, 'LightGBMXT_BAG_L2': 0.19}\n",
      "\t0.462\t = Validation score   (r2)\n",
      "\t0.13s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 388.52s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 129.6 rows/s (129 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/regression/AutogluonModels/ag-20250521_163852\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250521_164522\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #53~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Jan 15 19:18:46 UTC 2\n",
      "CPU Count:          64\n",
      "Memory Avail:       333.40 GB / 503.54 GB (66.2%)\n",
      "Disk Space Avail:   33802.61 GB / 51214.59 GB (66.0%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ... Time limit = 360s\n",
      "AutoGluon will save models to \"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/regression/AutogluonModels/ag-20250521_164522\"\n",
      "Train Data Rows:    1025\n",
      "Train Data Columns: 9\n",
      "Label Column:       Price\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    341403.66 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.36 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 4 | ['Capacity', 'Unit', 'ABV', 'Vintage']\n",
      "\t\t('object', []) : 5 | ['Closure', 'Country', 'Per bottle / case / each', 'Type', 'Style']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 4 | ['Closure', 'Country', 'Type', 'Style']\n",
      "\t\t('float', [])     : 4 | ['Capacity', 'Unit', 'ABV', 'Vintage']\n",
      "\t\t('int', ['bool']) : 1 | ['Per bottle / case / each']\n",
      "\t0.1s = Fit runtime\n",
      "\t9 features in original data used to generate 9 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.04 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.13s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 239.85s of the 359.85s of remaining time.\n",
      "\t0.216\t = Validation score   (r2)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 239.79s of the 359.79s of remaining time.\n",
      "\t0.1512\t = Validation score   (r2)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 239.74s of the 359.73s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.4396\t = Validation score   (r2)\n",
      "\t64.19s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 171.93s of the 291.93s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.3974\t = Validation score   (r2)\n",
      "\t61.94s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 106.31s of the 226.30s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.325\t = Validation score   (r2)\n",
      "\t0.97s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 104.91s of the 224.91s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.11%)\n",
      "\t0.4058\t = Validation score   (r2)\n",
      "\t70.87s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 30.39s of the 150.38s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.3104\t = Validation score   (r2)\n",
      "\t1.02s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 28.93s of the 148.93s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.4159\t = Validation score   (r2)\n",
      "\t88.21s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 359.87s of the 56.67s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.583, 'NeuralNetFastAI_BAG_L1': 0.292, 'RandomForestMSE_BAG_L1': 0.125}\n",
      "\t0.4518\t = Validation score   (r2)\n",
      "\t0.22s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 106 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 56.42s of the 56.36s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.4216\t = Validation score   (r2)\n",
      "\t57.59s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 359.87s of the -5.15s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.5, 'NeuralNetFastAI_BAG_L1': 0.208, 'LightGBMXT_BAG_L2': 0.208, 'RandomForestMSE_BAG_L1': 0.083}\n",
      "\t0.4537\t = Validation score   (r2)\n",
      "\t0.17s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 365.38s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 257.0 rows/s (129 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/regression/AutogluonModels/ag-20250521_164522\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250521_165128\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #53~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Jan 15 19:18:46 UTC 2\n",
      "CPU Count:          64\n",
      "Memory Avail:       332.11 GB / 503.54 GB (66.0%)\n",
      "Disk Space Avail:   33802.38 GB / 51214.59 GB (66.0%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ... Time limit = 360s\n",
      "AutoGluon will save models to \"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/regression/AutogluonModels/ag-20250521_165128\"\n",
      "Train Data Rows:    1025\n",
      "Train Data Columns: 15\n",
      "Label Column:       Price\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    340043.74 MB\n",
      "\tTrain Data (Original)  Memory Usage: 2.46 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['Title', 'Description', 'Characteristics']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 714\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])        : 4 | ['Capacity', 'Unit', 'ABV', 'Vintage']\n",
      "\t\t('object', [])       : 8 | ['Grape', 'Closure', 'Country', 'Per bottle / case / each', 'Type', ...]\n",
      "\t\t('object', ['text']) : 3 | ['Title', 'Description', 'Characteristics']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    :   7 | ['Grape', 'Closure', 'Country', 'Type', 'Region', ...]\n",
      "\t\t('category', ['text_as_category'])  :   3 | ['Title', 'Description', 'Characteristics']\n",
      "\t\t('float', [])                       :   4 | ['Capacity', 'Unit', 'ABV', 'Vintage']\n",
      "\t\t('int', ['binned', 'text_special']) :  42 | ['Title.char_count', 'Title.word_count', 'Title.capital_ratio', 'Title.lower_ratio', 'Title.digit_ratio', ...]\n",
      "\t\t('int', ['bool'])                   :   1 | ['Per bottle / case / each']\n",
      "\t\t('int', ['text_ngram'])             : 702 | ['__nlp__.100', '__nlp__.12', '__nlp__.18', '__nlp__.19', '__nlp__.20', ...]\n",
      "\t10.6s = Fit runtime\n",
      "\t15 features in original data used to generate 759 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.46 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 10.7s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 232.81s of the 349.28s of remaining time.\n",
      "\t0.1927\t = Validation score   (r2)\n",
      "\t0.12s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 232.32s of the 348.79s of remaining time.\n",
      "\t0.1944\t = Validation score   (r2)\n",
      "\t0.11s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 231.87s of the 348.34s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.04%)\n",
      "\t0.4959\t = Validation score   (r2)\n",
      "\t76.9s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 150.87s of the 267.34s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.04%)\n",
      "\t0.5287\t = Validation score   (r2)\n",
      "\t85.6s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 61.23s of the 177.70s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.4997\t = Validation score   (r2)\n",
      "\t9.57s\t = Training   runtime\n",
      "\t0.57s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 50.75s of the 167.22s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.31%)\n",
      "\t0.4188\t = Validation score   (r2)\n",
      "\t55.06s\t = Training   runtime\n",
      "\t0.47s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 349.30s of the 107.71s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBM_BAG_L1': 0.611, 'RandomForestMSE_BAG_L1': 0.389}\n",
      "\t0.5482\t = Validation score   (r2)\n",
      "\t0.15s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 106 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 107.53s of the 107.46s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.04%)\n",
      "\t0.5289\t = Validation score   (r2)\n",
      "\t81.88s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 21.56s of the 21.49s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.04%)\n",
      "\t0.5106\t = Validation score   (r2)\n",
      "\t46.35s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 349.30s of the -29.58s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBM_BAG_L1': 0.412, 'RandomForestMSE_BAG_L1': 0.294, 'LightGBMXT_BAG_L2': 0.294}\n",
      "\t0.552\t = Validation score   (r2)\n",
      "\t0.13s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 389.78s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 137.9 rows/s (129 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/regression/AutogluonModels/ag-20250521_165128\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250521_165759\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #53~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Jan 15 19:18:46 UTC 2\n",
      "CPU Count:          64\n",
      "Memory Avail:       331.77 GB / 503.54 GB (65.9%)\n",
      "Disk Space Avail:   33802.19 GB / 51214.59 GB (66.0%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ... Time limit = 360s\n",
      "AutoGluon will save models to \"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/regression/AutogluonModels/ag-20250521_165759\"\n",
      "Train Data Rows:    1025\n",
      "Train Data Columns: 9\n",
      "Label Column:       Price\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    339732.24 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.36 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 4 | ['Capacity', 'Unit', 'ABV', 'Vintage']\n",
      "\t\t('object', []) : 5 | ['Closure', 'Country', 'Per bottle / case / each', 'Type', 'Style']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 4 | ['Closure', 'Country', 'Type', 'Style']\n",
      "\t\t('float', [])     : 4 | ['Capacity', 'Unit', 'ABV', 'Vintage']\n",
      "\t\t('int', ['bool']) : 1 | ['Per bottle / case / each']\n",
      "\t0.1s = Fit runtime\n",
      "\t9 features in original data used to generate 9 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.04 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.13s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 239.85s of the 359.84s of remaining time.\n",
      "\t0.2672\t = Validation score   (r2)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 239.80s of the 359.79s of remaining time.\n",
      "\t0.2053\t = Validation score   (r2)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 239.75s of the 359.74s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.4832\t = Validation score   (r2)\n",
      "\t80.24s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 155.76s of the 275.75s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.4603\t = Validation score   (r2)\n",
      "\t59.69s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 92.21s of the 212.20s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.3201\t = Validation score   (r2)\n",
      "\t0.98s\t = Training   runtime\n",
      "\t0.26s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 90.79s of the 210.78s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.11%)\n",
      "\t0.4744\t = Validation score   (r2)\n",
      "\t61.79s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 25.11s of the 145.10s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.3074\t = Validation score   (r2)\n",
      "\t0.95s\t = Training   runtime\n",
      "\t0.24s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 23.71s of the 143.70s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.4493\t = Validation score   (r2)\n",
      "\t84.97s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 359.87s of the 54.40s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.429, 'CatBoost_BAG_L1': 0.286, 'NeuralNetFastAI_BAG_L1': 0.238, 'KNeighborsDist_BAG_L1': 0.048}\n",
      "\t0.4996\t = Validation score   (r2)\n",
      "\t0.17s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 106 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 54.21s of the 54.15s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.5135\t = Validation score   (r2)\n",
      "\t58.52s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 359.87s of the -8.31s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L2': 0.64, 'LightGBMXT_BAG_L1': 0.2, 'CatBoost_BAG_L1': 0.12, 'NeuralNetFastAI_BAG_L1': 0.04}\n",
      "\t0.5219\t = Validation score   (r2)\n",
      "\t0.17s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 368.53s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 249.7 rows/s (129 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/regression/AutogluonModels/ag-20250521_165759\")\n"
     ]
    }
   ],
   "source": [
    "from baseline_eval import evaluate_baseline, plot_model_performance_summary\n",
    "results = evaluate_baseline(\n",
    "    df=loaded_df,\n",
    "    model='AGTabular',\n",
    "    df_name=dataset_config['dataset_name'],\n",
    "    label_col= dataset_config['target'],\n",
    "    task_type=dataset_config['task'],\n",
    "    textual_cols=textual_cols,\n",
    "    k_folds=5,\n",
    "    seed=0,\n",
    "    max_samples=3000,\n",
    "    output_path=f\"../../baseline_results/{dataset_config['task']}/{dataset_config['dataset_name']}.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "68aa0e62-a5f4-4734-84c8-8910d43aa436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving plot to ../../baseline_results/plots/reg/score\n",
      "Saving plot to ../../baseline_results/plots/reg/loss\n",
      "Saving plot to ../../baseline_results/plots/reg/roc_auc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score':                                     mean       std\n",
       " model                                             \n",
       " AutoGluon_Tabular_without_text  0.448415  0.054467\n",
       " AutoGluon_Tabular_with_text     0.460022  0.064030,\n",
       " 'loss':                                        mean         std\n",
       " model                                                  \n",
       " AutoGluon_Tabular_with_text     2513.190497  724.707452\n",
       " AutoGluon_Tabular_without_text  2537.759167  712.132207,\n",
       " 'roc_auc':                                 mean  std\n",
       " model                                    \n",
       " AutoGluon_Tabular_with_text      NaN  NaN\n",
       " AutoGluon_Tabular_without_text   NaN  NaN}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs = pd.read_csv(f\"../../baseline_results/{dataset_config['task']}/{dataset_config['dataset_name']}.csv\")\n",
    "plot_model_performance_summary(name=dataset_config['dataset_name'],task=dataset_config['task'], df=rs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
