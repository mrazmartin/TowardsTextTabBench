{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0200d09",
   "metadata": {},
   "source": [
    "### Let's start with downloading the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4d0c4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "# to reach the dataloader_functions module\n",
    "module_path = os.path.abspath(os.path.join( \"..\"))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from dataloader_functions.download_data import download_raw_data\n",
    "current_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b8103e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO update this section per dataset\n",
    "dataset_config = {\n",
    "    'dataset_name': 'beer_rating',\n",
    "    'source': 'kaggle',\n",
    "    'remote_path': 'ruthgn/beer-profile-and-ratings-data-set',\n",
    "    'files': ['beer_profile_and_ratings.csv'],\n",
    "    'rename_files': ['beer_rating.csv'],\n",
    "    'task': 'reg',\n",
    "    'target': 'review_overall',\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4336bfef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36mInfo:\u001b[0m Dataset already downloaded in \u001b[1;35m/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/regression/../../datasets_files/raw/regression/beer_rating\u001b[0m.\n",
      "Downloaded beer_rating dataset to /home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/regression/../../datasets_files/raw/regression/beer_rating\n"
     ]
    }
   ],
   "source": [
    "if dataset_config['task'] == 'clf':\n",
    "    dataset_subfolder = os.path.join('raw', 'classification', dataset_config['dataset_name']) \n",
    "elif dataset_config['task'] == 'reg':\n",
    "    dataset_subfolder = os.path.join('raw', 'regression', dataset_config['dataset_name'])\n",
    "else:\n",
    "    raise ValueError(f\"Unknown task: {dataset_config['task']}\")\n",
    "\n",
    "# this path needs to be modified based on the location of the notebook\n",
    "download_path = os.path.join(current_dir, '..', '..', 'datasets_files', dataset_subfolder)\n",
    "\n",
    "if download_raw_data(\n",
    "    dataset_config=dataset_config,\n",
    "    download_path=download_path,\n",
    "    force_download=False,\n",
    "    remove_unlisted=True,\n",
    ") is not None:\n",
    "    print(f\"Downloaded {dataset_config['dataset_name']} dataset to {download_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d886637",
   "metadata": {},
   "source": [
    "### Now we need to preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48bcaebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader_functions.load_and_pp_raw_data import _drop_empty_columns, _drop_single_value_columns\n",
    "from dataloader_functions.utils.data_2_df import read_any_to_df\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "current_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0861820c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading /home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/regression/../../datasets_files/raw/regression/beer_rating/beer_rating.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Style</th>\n",
       "      <th>Brewery</th>\n",
       "      <th>Beer Name (Full)</th>\n",
       "      <th>Description</th>\n",
       "      <th>ABV</th>\n",
       "      <th>Min IBU</th>\n",
       "      <th>Max IBU</th>\n",
       "      <th>Astringency</th>\n",
       "      <th>Body</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Bitter</th>\n",
       "      <th>Sweet</th>\n",
       "      <th>Sour</th>\n",
       "      <th>Salty</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>Hoppy</th>\n",
       "      <th>Spices</th>\n",
       "      <th>Malty</th>\n",
       "      <th>review_aroma</th>\n",
       "      <th>review_appearance</th>\n",
       "      <th>review_palate</th>\n",
       "      <th>review_taste</th>\n",
       "      <th>review_overall</th>\n",
       "      <th>number_of_reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amber</td>\n",
       "      <td>Altbier</td>\n",
       "      <td>Alaskan Brewing Co.</td>\n",
       "      <td>Alaskan Brewing Co. Alaskan Amber</td>\n",
       "      <td>Notes:Richly malty and long on the palate, wit...</td>\n",
       "      <td>5.3</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>13</td>\n",
       "      <td>32</td>\n",
       "      <td>9</td>\n",
       "      <td>47</td>\n",
       "      <td>74</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>57</td>\n",
       "      <td>8</td>\n",
       "      <td>111</td>\n",
       "      <td>3.498994</td>\n",
       "      <td>3.636821</td>\n",
       "      <td>3.556338</td>\n",
       "      <td>3.643863</td>\n",
       "      <td>3.847082</td>\n",
       "      <td>497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Double Bag</td>\n",
       "      <td>Altbier</td>\n",
       "      <td>Long Trail Brewing Co.</td>\n",
       "      <td>Long Trail Brewing Co. Double Bag</td>\n",
       "      <td>Notes:This malty, full-bodied double alt is al...</td>\n",
       "      <td>7.2</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>12</td>\n",
       "      <td>57</td>\n",
       "      <td>18</td>\n",
       "      <td>33</td>\n",
       "      <td>55</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>35</td>\n",
       "      <td>12</td>\n",
       "      <td>84</td>\n",
       "      <td>3.798337</td>\n",
       "      <td>3.846154</td>\n",
       "      <td>3.904366</td>\n",
       "      <td>4.024948</td>\n",
       "      <td>4.034304</td>\n",
       "      <td>481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Long Trail Ale</td>\n",
       "      <td>Altbier</td>\n",
       "      <td>Long Trail Brewing Co.</td>\n",
       "      <td>Long Trail Brewing Co. Long Trail Ale</td>\n",
       "      <td>Notes:Long Trail Ale is a full-bodied amber al...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>14</td>\n",
       "      <td>37</td>\n",
       "      <td>6</td>\n",
       "      <td>42</td>\n",
       "      <td>43</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>54</td>\n",
       "      <td>4</td>\n",
       "      <td>62</td>\n",
       "      <td>3.409814</td>\n",
       "      <td>3.667109</td>\n",
       "      <td>3.600796</td>\n",
       "      <td>3.631300</td>\n",
       "      <td>3.830239</td>\n",
       "      <td>377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Name    Style                 Brewery  \\\n",
       "0           Amber  Altbier     Alaskan Brewing Co.   \n",
       "1      Double Bag  Altbier  Long Trail Brewing Co.   \n",
       "2  Long Trail Ale  Altbier  Long Trail Brewing Co.   \n",
       "\n",
       "                        Beer Name (Full)  \\\n",
       "0      Alaskan Brewing Co. Alaskan Amber   \n",
       "1      Long Trail Brewing Co. Double Bag   \n",
       "2  Long Trail Brewing Co. Long Trail Ale   \n",
       "\n",
       "                                         Description  ABV  Min IBU  Max IBU  \\\n",
       "0  Notes:Richly malty and long on the palate, wit...  5.3       25       50   \n",
       "1  Notes:This malty, full-bodied double alt is al...  7.2       25       50   \n",
       "2  Notes:Long Trail Ale is a full-bodied amber al...  5.0       25       50   \n",
       "\n",
       "   Astringency  Body  Alcohol  Bitter  Sweet  Sour  Salty  Fruits  Hoppy  \\\n",
       "0           13    32        9      47     74    33      0      33     57   \n",
       "1           12    57       18      33     55    16      0      24     35   \n",
       "2           14    37        6      42     43    11      0      10     54   \n",
       "\n",
       "   Spices  Malty  review_aroma  review_appearance  review_palate  \\\n",
       "0       8    111      3.498994           3.636821       3.556338   \n",
       "1      12     84      3.798337           3.846154       3.904366   \n",
       "2       4     62      3.409814           3.667109       3.600796   \n",
       "\n",
       "   review_taste  review_overall  number_of_reviews  \n",
       "0      3.643863        3.847082                497  \n",
       "1      4.024948        4.034304                481  \n",
       "2      3.631300        3.830239                377  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dataset_files_df = []\n",
    "\n",
    "if dataset_config['rename_files'] is None or len(dataset_config['rename_files']) == 0:\n",
    "    dataset_config['rename_files'] = dataset_config['files']\n",
    "\n",
    "for file in dataset_config['rename_files']:\n",
    "\n",
    "    file_location = os.path.join(download_path, file)\n",
    "\n",
    "    print(f\"Loading {file_location}\")\n",
    "\n",
    "    dataset_files_df.append(read_any_to_df(file_location))\n",
    "\n",
    "# example of the loaded df data:\n",
    "pd.set_option('display.max_columns', None)\n",
    "dataset_files_df[0].head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d099b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped: Index([], dtype='object')\n",
      "Dataframe shape before/afrer cleaning: (3197, 25) / (3197, 25)\n"
     ]
    }
   ],
   "source": [
    "## Run some basic data cleaning\n",
    "\n",
    "dataset_files_gen_cleaned = []\n",
    "\n",
    "for df_file in dataset_files_df:\n",
    "    df_size = df_file.shape\n",
    "    # 1. Drop columns with more than 50% missing values\n",
    "    df_file = _drop_empty_columns(df_file, threshold=0.5)\n",
    "    # 2. Drop columns with only one unique value\n",
    "    df_file = _drop_single_value_columns(df_file)\n",
    "    # 3. remove duplicates\n",
    "    df_file = df_file.drop_duplicates()\n",
    "    # 4. remove rows with missing target values\n",
    "    df_file = df_file[df_file[dataset_config['target']].notna()]\n",
    "    # 5. drop unnamed columns\n",
    "    df_file = df_file.loc[:, ~df_file.columns.str.contains('^Unnamed')]\n",
    "\n",
    "    dataset_files_gen_cleaned.append(df_file)\n",
    "\n",
    "    print(f\"Dataframe shape before/afrer cleaning: {df_size} / {df_file.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0a2a11a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe shape before/afrer by-hand cleaning: (3197, 25) / (3197, 21)\n"
     ]
    }
   ],
   "source": [
    "## TODO: Now run custom data cleaning -> remove non-essential columns\n",
    "\n",
    "cols_to_drop = ['review_aroma', 'review_appearance', 'review_palate', 'review_taste']\n",
    "\n",
    "dataset_files_cleaned = []\n",
    "\n",
    "# assuming for multiple files we still want to drop the same columns\n",
    "for df_file in dataset_files_gen_cleaned:\n",
    "    df_size = df_file.shape\n",
    "    for col in cols_to_drop:\n",
    "        if col in df_file.columns:\n",
    "            df_file.drop(col, axis=1, inplace=True)\n",
    "        else:\n",
    "            print(f\"Column {col} not found in dataframe\")\n",
    "\n",
    "    dataset_files_cleaned.append(df_file)    \n",
    "    print(f\"Dataframe shape before/afrer by-hand cleaning: {df_size} / {df_file.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d90a681b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe shape before removing low number of reviews: (3197, 21)\n",
      "Dataframe shape after removing low number of reviews: (2914, 21)\n"
     ]
    }
   ],
   "source": [
    "# TODO:\n",
    "# let's make sure all reviews scores are credible, so at least XX 'number of reviews'\n",
    "\n",
    "min_number_of_reviews = 5\n",
    "\n",
    "import copy \n",
    "tmp_df = copy.deepcopy(dataset_files_cleaned)\n",
    "\n",
    "for df_file in dataset_files_cleaned:\n",
    "    print(f\"Dataframe shape before removing low number of reviews: {df_file.shape}\")\n",
    "    df_file.drop(df_file[df_file['number_of_reviews'] < min_number_of_reviews].index, inplace=True)\n",
    "    print(f\"Dataframe shape after removing low number of reviews: {df_file.shape}\")\n",
    "\n",
    "# TODO remove once the code is working\n",
    "# dataset_files_cleaned = tmp_df\n",
    "dataset_files_by_hand_cleaned = dataset_files_cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581b17e1",
   "metadata": {},
   "source": [
    "### Now it is time to visualize our changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1500c210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Style</th>\n",
       "      <th>Brewery</th>\n",
       "      <th>Beer Name (Full)</th>\n",
       "      <th>Description</th>\n",
       "      <th>ABV</th>\n",
       "      <th>Min IBU</th>\n",
       "      <th>Max IBU</th>\n",
       "      <th>Astringency</th>\n",
       "      <th>Body</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Bitter</th>\n",
       "      <th>Sweet</th>\n",
       "      <th>Sour</th>\n",
       "      <th>Salty</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>Hoppy</th>\n",
       "      <th>Spices</th>\n",
       "      <th>Malty</th>\n",
       "      <th>review_overall</th>\n",
       "      <th>number_of_reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amber</td>\n",
       "      <td>Altbier</td>\n",
       "      <td>Alaskan Brewing Co.</td>\n",
       "      <td>Alaskan Brewing Co. Alaskan Amber</td>\n",
       "      <td>Notes:Richly malty and long on the palate, wit...</td>\n",
       "      <td>5.3</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>13</td>\n",
       "      <td>32</td>\n",
       "      <td>9</td>\n",
       "      <td>47</td>\n",
       "      <td>74</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>57</td>\n",
       "      <td>8</td>\n",
       "      <td>111</td>\n",
       "      <td>3.847082</td>\n",
       "      <td>497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Double Bag</td>\n",
       "      <td>Altbier</td>\n",
       "      <td>Long Trail Brewing Co.</td>\n",
       "      <td>Long Trail Brewing Co. Double Bag</td>\n",
       "      <td>Notes:This malty, full-bodied double alt is al...</td>\n",
       "      <td>7.2</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>12</td>\n",
       "      <td>57</td>\n",
       "      <td>18</td>\n",
       "      <td>33</td>\n",
       "      <td>55</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>35</td>\n",
       "      <td>12</td>\n",
       "      <td>84</td>\n",
       "      <td>4.034304</td>\n",
       "      <td>481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Long Trail Ale</td>\n",
       "      <td>Altbier</td>\n",
       "      <td>Long Trail Brewing Co.</td>\n",
       "      <td>Long Trail Brewing Co. Long Trail Ale</td>\n",
       "      <td>Notes:Long Trail Ale is a full-bodied amber al...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>14</td>\n",
       "      <td>37</td>\n",
       "      <td>6</td>\n",
       "      <td>42</td>\n",
       "      <td>43</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>54</td>\n",
       "      <td>4</td>\n",
       "      <td>62</td>\n",
       "      <td>3.830239</td>\n",
       "      <td>377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Name    Style                 Brewery  \\\n",
       "0           Amber  Altbier     Alaskan Brewing Co.   \n",
       "1      Double Bag  Altbier  Long Trail Brewing Co.   \n",
       "2  Long Trail Ale  Altbier  Long Trail Brewing Co.   \n",
       "\n",
       "                        Beer Name (Full)  \\\n",
       "0      Alaskan Brewing Co. Alaskan Amber   \n",
       "1      Long Trail Brewing Co. Double Bag   \n",
       "2  Long Trail Brewing Co. Long Trail Ale   \n",
       "\n",
       "                                         Description  ABV  Min IBU  Max IBU  \\\n",
       "0  Notes:Richly malty and long on the palate, wit...  5.3       25       50   \n",
       "1  Notes:This malty, full-bodied double alt is al...  7.2       25       50   \n",
       "2  Notes:Long Trail Ale is a full-bodied amber al...  5.0       25       50   \n",
       "\n",
       "   Astringency  Body  Alcohol  Bitter  Sweet  Sour  Salty  Fruits  Hoppy  \\\n",
       "0           13    32        9      47     74    33      0      33     57   \n",
       "1           12    57       18      33     55    16      0      24     35   \n",
       "2           14    37        6      42     43    11      0      10     54   \n",
       "\n",
       "   Spices  Malty  review_overall  number_of_reviews  \n",
       "0       8    111        3.847082                497  \n",
       "1      12     84        4.034304                481  \n",
       "2       4     62        3.830239                377  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "dataset_files_by_hand_cleaned[0].head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f71269d",
   "metadata": {},
   "source": [
    "Let's figure out which columns should be viewed as categorical / numerical / textual\n",
    "\n",
    "we can start with a simple heuristic:\n",
    "1. numerical is everything which\n",
    "    - keeps most of its character length after non-numeral strip\n",
    "    - has about the same number of unique values after the strip\n",
    "    + for the purpose of keeping \"semantic information\", hand picked columns can be viewed also as non-numerical, that is not the default benchmark approach though\n",
    "\n",
    "2. categorical is everthing non numerical, which can be then divided into N (where N << Num instances) unique categories\n",
    "\n",
    "3. textual is everything else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "436f9ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Threshold for categorical vs textual: 50\n",
      "Numerical columns (13): ['ABV', 'Astringency', 'Body', 'Alcohol', 'Bitter', 'Sweet', 'Sour', 'Fruits', 'Hoppy', 'Spices', 'Malty', 'review_overall', 'number_of_reviews']\n",
      "Categorical columns (3): ['Min IBU', 'Max IBU', 'Salty']\n",
      "Textual columns (5): ['Name', 'Style', 'Brewery', 'Beer Name (Full)', 'Description']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def is_mostly_numeric(series, length_threshold=0.5, unique_threshold=0.8):\n",
    "    \"\"\"Check if column is mostly numeric after stripping non-numeric chars.\"\"\"\n",
    "    stripped = series.astype(str).str.replace(r\"[^\\d\\.\\-]\", \"\", regex=True)\n",
    "    \n",
    "    original_len = series.astype(str).str.len().replace(0, 1)  # avoid div by zero\n",
    "    length_ratio = (stripped.str.len() / original_len).mean()\n",
    "\n",
    "    unique_ratio = stripped.nunique(dropna=False) / max(series.nunique(dropna=False), 1)\n",
    "\n",
    "    return length_ratio > length_threshold and unique_ratio > unique_threshold\n",
    "\n",
    "def classify_columns(df, unique_ratio_threshold=None, explicit_nunique_threshold=None):\n",
    "    \"\"\"\n",
    "    Classify dataframe columns into numerical, categorical, textual.\n",
    "    - Binary categorical (2 unique values) is considered categorical.\n",
    "    \"\"\"\n",
    "    n_rows = len(df)\n",
    "\n",
    "    # Determine threshold for categorical vs textual\n",
    "    if explicit_nunique_threshold is not None:\n",
    "        nunique_threshold = explicit_nunique_threshold\n",
    "    elif unique_ratio_threshold is not None:\n",
    "        nunique_threshold = int(unique_ratio_threshold * n_rows)\n",
    "    else:\n",
    "        nunique_threshold = int(0.05 * n_rows)  # default 5%\n",
    "\n",
    "    nunique_threshold = max(10, nunique_threshold)  # safeguard\n",
    "    print(f\"Threshold for categorical vs textual: {nunique_threshold}\")\n",
    "\n",
    "    numerical_cols = []\n",
    "    categorical_cols = []\n",
    "    textual_cols = []\n",
    "\n",
    "    for col in df.columns:\n",
    "        series = df[col]\n",
    "        nunique = series.nunique(dropna=False)\n",
    "\n",
    "        if pd.api.types.is_numeric_dtype(series):\n",
    "            if nunique <= nunique_threshold:\n",
    "                categorical_cols.append(col)\n",
    "            else:\n",
    "                numerical_cols.append(col)\n",
    "        \n",
    "        elif pd.api.types.is_string_dtype(series) or pd.api.types.is_object_dtype(series):\n",
    "            if is_mostly_numeric(series):\n",
    "                numerical_cols.append(col)\n",
    "            else:\n",
    "                if nunique <= nunique_threshold:\n",
    "                    categorical_cols.append(col)\n",
    "                else:\n",
    "                    textual_cols.append(col)\n",
    "        else:\n",
    "            print(f\"⚠️ Unhandled column type: '{col}' (dtype={series.dtype})\")\n",
    "\n",
    "    print(f\"Numerical columns ({len(numerical_cols)}): {numerical_cols}\")\n",
    "    print(f\"Categorical columns ({len(categorical_cols)}): {categorical_cols}\")\n",
    "    print(f\"Textual columns ({len(textual_cols)}): {textual_cols}\")\n",
    "\n",
    "    return numerical_cols, categorical_cols, textual_cols\n",
    "\n",
    "# Example usage:\n",
    "for df_file in dataset_files_by_hand_cleaned:\n",
    "    # Ratio-based (5% of rows)\n",
    "    # umerical_cols, categorical_cols, textual_cols = classify_columns(df_file, unique_ratio_threshold=0.05)\n",
    "    print(\"\")\n",
    "    # OR explicit value (e.g., anything <= 50 is categorical)\n",
    "    numerical_cols, categorical_cols, textual_cols = classify_columns(df_file, explicit_nunique_threshold=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6499589b",
   "metadata": {},
   "source": [
    "Now let's just try to visualize the kept features, their example values, and their cat/num/text allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "afffbdb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column Name</th>\n",
       "      <th>Example Value</th>\n",
       "      <th>Type</th>\n",
       "      <th># Categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Name</td>\n",
       "      <td>Amber</td>\n",
       "      <td>textual</td>\n",
       "      <td>2795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Style</td>\n",
       "      <td>Altbier</td>\n",
       "      <td>textual</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brewery</td>\n",
       "      <td>Alaskan Brewing Co.</td>\n",
       "      <td>textual</td>\n",
       "      <td>842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Beer Name (Full)</td>\n",
       "      <td>Alaskan Brewing Co. Alaskan Amber</td>\n",
       "      <td>textual</td>\n",
       "      <td>2914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Description</td>\n",
       "      <td>Notes:Richly malty and long on the palate, wit...</td>\n",
       "      <td>textual</td>\n",
       "      <td>1722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ABV</td>\n",
       "      <td>5.3</td>\n",
       "      <td>numerical</td>\n",
       "      <td>~ 188 ~</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Min IBU</td>\n",
       "      <td>25</td>\n",
       "      <td>categorical</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Max IBU</td>\n",
       "      <td>50</td>\n",
       "      <td>categorical</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Astringency</td>\n",
       "      <td>13</td>\n",
       "      <td>numerical</td>\n",
       "      <td>~ 66 ~</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Body</td>\n",
       "      <td>32</td>\n",
       "      <td>numerical</td>\n",
       "      <td>~ 148 ~</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Alcohol</td>\n",
       "      <td>9</td>\n",
       "      <td>numerical</td>\n",
       "      <td>~ 104 ~</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Bitter</td>\n",
       "      <td>47</td>\n",
       "      <td>numerical</td>\n",
       "      <td>~ 132 ~</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Sweet</td>\n",
       "      <td>74</td>\n",
       "      <td>numerical</td>\n",
       "      <td>~ 181 ~</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Sour</td>\n",
       "      <td>33</td>\n",
       "      <td>numerical</td>\n",
       "      <td>~ 191 ~</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Salty</td>\n",
       "      <td>0</td>\n",
       "      <td>categorical</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Fruits</td>\n",
       "      <td>33</td>\n",
       "      <td>numerical</td>\n",
       "      <td>~ 147 ~</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Hoppy</td>\n",
       "      <td>57</td>\n",
       "      <td>numerical</td>\n",
       "      <td>~ 152 ~</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Spices</td>\n",
       "      <td>8</td>\n",
       "      <td>numerical</td>\n",
       "      <td>~ 136 ~</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Malty</td>\n",
       "      <td>111</td>\n",
       "      <td>numerical</td>\n",
       "      <td>~ 194 ~</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>review_overall</td>\n",
       "      <td>3.847082</td>\n",
       "      <td>numerical</td>\n",
       "      <td>~ 2317 ~</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>number_of_reviews</td>\n",
       "      <td>497</td>\n",
       "      <td>numerical</td>\n",
       "      <td>~ 807 ~</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Column Name                                      Example Value  \\\n",
       "0                Name                                              Amber   \n",
       "1               Style                                            Altbier   \n",
       "2             Brewery                                Alaskan Brewing Co.   \n",
       "3    Beer Name (Full)                  Alaskan Brewing Co. Alaskan Amber   \n",
       "4         Description  Notes:Richly malty and long on the palate, wit...   \n",
       "5                 ABV                                                5.3   \n",
       "6             Min IBU                                                 25   \n",
       "7             Max IBU                                                 50   \n",
       "8         Astringency                                                 13   \n",
       "9                Body                                                 32   \n",
       "10            Alcohol                                                  9   \n",
       "11             Bitter                                                 47   \n",
       "12              Sweet                                                 74   \n",
       "13               Sour                                                 33   \n",
       "14              Salty                                                  0   \n",
       "15             Fruits                                                 33   \n",
       "16              Hoppy                                                 57   \n",
       "17             Spices                                                  8   \n",
       "18              Malty                                                111   \n",
       "19     review_overall                                           3.847082   \n",
       "20  number_of_reviews                                                497   \n",
       "\n",
       "           Type # Categories  \n",
       "0       textual         2795  \n",
       "1       textual          111  \n",
       "2       textual          842  \n",
       "3       textual         2914  \n",
       "4       textual         1722  \n",
       "5     numerical      ~ 188 ~  \n",
       "6   categorical           21  \n",
       "7   categorical           25  \n",
       "8     numerical       ~ 66 ~  \n",
       "9     numerical      ~ 148 ~  \n",
       "10    numerical      ~ 104 ~  \n",
       "11    numerical      ~ 132 ~  \n",
       "12    numerical      ~ 181 ~  \n",
       "13    numerical      ~ 191 ~  \n",
       "14  categorical           21  \n",
       "15    numerical      ~ 147 ~  \n",
       "16    numerical      ~ 152 ~  \n",
       "17    numerical      ~ 136 ~  \n",
       "18    numerical      ~ 194 ~  \n",
       "19    numerical     ~ 2317 ~  \n",
       "20    numerical      ~ 807 ~  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary = []\n",
    "for col in df_file.columns:\n",
    "    if col in categorical_cols:\n",
    "        col_type = \"categorical\"\n",
    "        num_categories = df_file[col].nunique(dropna=True)\n",
    "        num_categories_display = int(num_categories)\n",
    "    elif col in textual_cols:\n",
    "        col_type = \"textual\"\n",
    "        num_categories = df_file[col].nunique(dropna=True)\n",
    "        num_categories_display = int(num_categories)\n",
    "    elif col in numerical_cols:\n",
    "        col_type = \"numerical\"\n",
    "        num_categories = df_file[col].nunique(dropna=True)\n",
    "        num_categories_display = '~ ' + str(num_categories) + ' ~'\n",
    "    else:\n",
    "        col_type = \"unknown\"\n",
    "        num_categories_display = '--'\n",
    "\n",
    "    example = df_file[col].dropna().iloc[0] if df_file[col].dropna().size > 0 else None\n",
    "    summary.append({\n",
    "        'Column Name': col,\n",
    "        'Example Value': str(example),\n",
    "        'Type': col_type,\n",
    "        '# Categories': num_categories_display\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary)\n",
    "\n",
    "# TODO: by hand changes of the type and category count -> e.g. for 'Location':\n",
    "#    # Post-processing: override the type and category count for 'Location'\n",
    "#    # summary_df.loc[summary_df['Column Name'] == 'Location', 'Type'] = 'textual'\n",
    "#    # num_categories = df_file['Location'].nunique(dropna=True)\n",
    "#    # summary_df.loc[summary_df['Column Name'] == 'Location', '# Categories'] = int(num_categories)\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "display(summary_df)  # Or print(summary_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479c3f41",
   "metadata": {},
   "source": [
    "#### We also need to make sure that numerical columns are actually numerical :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d89e346e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column Name</th>\n",
       "      <th>Example Value</th>\n",
       "      <th>Type</th>\n",
       "      <th># Categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Name</td>\n",
       "      <td>Amber</td>\n",
       "      <td>textual</td>\n",
       "      <td>2795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Style</td>\n",
       "      <td>Altbier</td>\n",
       "      <td>textual</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brewery</td>\n",
       "      <td>Alaskan Brewing Co.</td>\n",
       "      <td>textual</td>\n",
       "      <td>842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Beer Name (Full)</td>\n",
       "      <td>Alaskan Brewing Co. Alaskan Amber</td>\n",
       "      <td>textual</td>\n",
       "      <td>2914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Description</td>\n",
       "      <td>Notes:Richly malty and long on the palate, wit...</td>\n",
       "      <td>textual</td>\n",
       "      <td>1722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ABV</td>\n",
       "      <td>5.3</td>\n",
       "      <td>numerical</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Min IBU</td>\n",
       "      <td>25</td>\n",
       "      <td>categorical</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Max IBU</td>\n",
       "      <td>50</td>\n",
       "      <td>categorical</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Astringency</td>\n",
       "      <td>13.0</td>\n",
       "      <td>numerical</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Body</td>\n",
       "      <td>32.0</td>\n",
       "      <td>numerical</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Alcohol</td>\n",
       "      <td>9.0</td>\n",
       "      <td>numerical</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Bitter</td>\n",
       "      <td>47.0</td>\n",
       "      <td>numerical</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Sweet</td>\n",
       "      <td>74.0</td>\n",
       "      <td>numerical</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Sour</td>\n",
       "      <td>33.0</td>\n",
       "      <td>numerical</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Salty</td>\n",
       "      <td>0</td>\n",
       "      <td>categorical</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Fruits</td>\n",
       "      <td>33.0</td>\n",
       "      <td>numerical</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Hoppy</td>\n",
       "      <td>57.0</td>\n",
       "      <td>numerical</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Spices</td>\n",
       "      <td>8.0</td>\n",
       "      <td>numerical</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Malty</td>\n",
       "      <td>111.0</td>\n",
       "      <td>numerical</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>review_overall</td>\n",
       "      <td>3.847082</td>\n",
       "      <td>numerical</td>\n",
       "      <td>2317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>number_of_reviews</td>\n",
       "      <td>497.0</td>\n",
       "      <td>numerical</td>\n",
       "      <td>807</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Column Name                                      Example Value  \\\n",
       "0                Name                                              Amber   \n",
       "1               Style                                            Altbier   \n",
       "2             Brewery                                Alaskan Brewing Co.   \n",
       "3    Beer Name (Full)                  Alaskan Brewing Co. Alaskan Amber   \n",
       "4         Description  Notes:Richly malty and long on the palate, wit...   \n",
       "5                 ABV                                                5.3   \n",
       "6             Min IBU                                                 25   \n",
       "7             Max IBU                                                 50   \n",
       "8         Astringency                                               13.0   \n",
       "9                Body                                               32.0   \n",
       "10            Alcohol                                                9.0   \n",
       "11             Bitter                                               47.0   \n",
       "12              Sweet                                               74.0   \n",
       "13               Sour                                               33.0   \n",
       "14              Salty                                                  0   \n",
       "15             Fruits                                               33.0   \n",
       "16              Hoppy                                               57.0   \n",
       "17             Spices                                                8.0   \n",
       "18              Malty                                              111.0   \n",
       "19     review_overall                                           3.847082   \n",
       "20  number_of_reviews                                              497.0   \n",
       "\n",
       "           Type # Categories  \n",
       "0       textual         2795  \n",
       "1       textual          111  \n",
       "2       textual          842  \n",
       "3       textual         2914  \n",
       "4       textual         1722  \n",
       "5     numerical          188  \n",
       "6   categorical           21  \n",
       "7   categorical           25  \n",
       "8     numerical           66  \n",
       "9     numerical          148  \n",
       "10    numerical          104  \n",
       "11    numerical          132  \n",
       "12    numerical          181  \n",
       "13    numerical          191  \n",
       "14  categorical           21  \n",
       "15    numerical          147  \n",
       "16    numerical          152  \n",
       "17    numerical          136  \n",
       "18    numerical          194  \n",
       "19    numerical         2317  \n",
       "20    numerical          807  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "from dataloader_functions.load_and_pp_raw_data import clean_numerical_columns\n",
    "\n",
    "summary_df, dataset_files_by_hand_cleaned = clean_numerical_columns(summary_df, dataset_files_by_hand_cleaned)\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "display(summary_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64dc2fa",
   "metadata": {},
   "source": [
    "### Saving the processed data and loading it back up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae61e038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/regression/../../datasets_files/raw/regression/beer_rating/beer_rating_processed.pkl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Handle rename_files fallback\n",
    "if dataset_config['rename_files'] is None or len(dataset_config['rename_files']) == 0:\n",
    "    dataset_config['rename_files'] = dataset_config['files']\n",
    "\n",
    "for i, df_file in enumerate(dataset_files_by_hand_cleaned):\n",
    "    df_with_meta = df_file.copy()\n",
    "\n",
    "    # Get corresponding file name\n",
    "    file_name = dataset_config['rename_files'][i]\n",
    "    file_base = os.path.splitext(file_name)[0]\n",
    "\n",
    "    # Try assigning multi-index header from summary\n",
    "    try:\n",
    "        df_with_meta.columns = pd.MultiIndex.from_frame(\n",
    "            summary_df[['Column Name', 'Type', '# Categories']]\n",
    "        )\n",
    "        local_summary = summary_df.copy()\n",
    "    except ValueError:\n",
    "        local_summary = summary_df.copy()\n",
    "        if dataset_config['target'] in local_summary['Column Name'].values:\n",
    "            local_summary = local_summary[local_summary['Column Name'] != dataset_config['target']]\n",
    "            df_with_meta.columns = pd.MultiIndex.from_frame(\n",
    "                local_summary[['Column Name', 'Type', '# Categories']]\n",
    "            )\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "    # Construct and save everything together\n",
    "    output_filename = f\"{file_base}_processed.pkl\"\n",
    "    output_path = os.path.join(download_path, output_filename)\n",
    "\n",
    "    save_bundle = {\n",
    "        'data': df_with_meta,\n",
    "        'summary': local_summary,\n",
    "        'config': dataset_config\n",
    "    }\n",
    "\n",
    "    pd.to_pickle(save_bundle, output_path)\n",
    "    print(f\"Saved: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b41e8f5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== BEER_RATING ===\n",
      "Loaded config keys: ['dataset_name', 'source', 'remote_path', 'files', 'rename_files', 'task', 'target']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column Name</th>\n",
       "      <th>Type</th>\n",
       "      <th># Categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Name</td>\n",
       "      <td>textual</td>\n",
       "      <td>2795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Style</td>\n",
       "      <td>textual</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brewery</td>\n",
       "      <td>textual</td>\n",
       "      <td>842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Beer Name (Full)</td>\n",
       "      <td>textual</td>\n",
       "      <td>2914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Description</td>\n",
       "      <td>textual</td>\n",
       "      <td>1722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ABV</td>\n",
       "      <td>numerical</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Min IBU</td>\n",
       "      <td>categorical</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Max IBU</td>\n",
       "      <td>categorical</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Astringency</td>\n",
       "      <td>numerical</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Body</td>\n",
       "      <td>numerical</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Alcohol</td>\n",
       "      <td>numerical</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Bitter</td>\n",
       "      <td>numerical</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Sweet</td>\n",
       "      <td>numerical</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Sour</td>\n",
       "      <td>numerical</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Salty</td>\n",
       "      <td>categorical</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Fruits</td>\n",
       "      <td>numerical</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Hoppy</td>\n",
       "      <td>numerical</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Spices</td>\n",
       "      <td>numerical</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Malty</td>\n",
       "      <td>numerical</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>review_overall</td>\n",
       "      <td>numerical</td>\n",
       "      <td>2317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>number_of_reviews</td>\n",
       "      <td>numerical</td>\n",
       "      <td>807</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Column Name         Type  # Categories\n",
       "0                Name      textual          2795\n",
       "1               Style      textual           111\n",
       "2             Brewery      textual           842\n",
       "3    Beer Name (Full)      textual          2914\n",
       "4         Description      textual          1722\n",
       "5                 ABV    numerical           188\n",
       "6             Min IBU  categorical            21\n",
       "7             Max IBU  categorical            25\n",
       "8         Astringency    numerical            66\n",
       "9                Body    numerical           148\n",
       "10            Alcohol    numerical           104\n",
       "11             Bitter    numerical           132\n",
       "12              Sweet    numerical           181\n",
       "13               Sour    numerical           191\n",
       "14              Salty  categorical            21\n",
       "15             Fruits    numerical           147\n",
       "16              Hoppy    numerical           152\n",
       "17             Spices    numerical           136\n",
       "18              Malty    numerical           194\n",
       "19     review_overall    numerical          2317\n",
       "20  number_of_reviews    numerical           807"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Column Name</th>\n",
       "      <th>Name</th>\n",
       "      <th>Style</th>\n",
       "      <th>Brewery</th>\n",
       "      <th>Beer Name (Full)</th>\n",
       "      <th>Description</th>\n",
       "      <th>ABV</th>\n",
       "      <th>Min IBU</th>\n",
       "      <th>Max IBU</th>\n",
       "      <th>Astringency</th>\n",
       "      <th>Body</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Bitter</th>\n",
       "      <th>Sweet</th>\n",
       "      <th>Sour</th>\n",
       "      <th>Salty</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>Hoppy</th>\n",
       "      <th>Spices</th>\n",
       "      <th>Malty</th>\n",
       "      <th>review_overall</th>\n",
       "      <th>number_of_reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amber</td>\n",
       "      <td>Altbier</td>\n",
       "      <td>Alaskan Brewing Co.</td>\n",
       "      <td>Alaskan Brewing Co. Alaskan Amber</td>\n",
       "      <td>Notes:Richly malty and long on the palate, wit...</td>\n",
       "      <td>5.3</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>13.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>3.847082</td>\n",
       "      <td>497.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Double Bag</td>\n",
       "      <td>Altbier</td>\n",
       "      <td>Long Trail Brewing Co.</td>\n",
       "      <td>Long Trail Brewing Co. Double Bag</td>\n",
       "      <td>Notes:This malty, full-bodied double alt is al...</td>\n",
       "      <td>7.2</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>12.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>4.034304</td>\n",
       "      <td>481.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Long Trail Ale</td>\n",
       "      <td>Altbier</td>\n",
       "      <td>Long Trail Brewing Co.</td>\n",
       "      <td>Long Trail Brewing Co. Long Trail Ale</td>\n",
       "      <td>Notes:Long Trail Ale is a full-bodied amber al...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>25</td>\n",
       "      <td>50</td>\n",
       "      <td>14.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>3.830239</td>\n",
       "      <td>377.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Column Name            Name    Style                 Brewery  \\\n",
       "0                     Amber  Altbier     Alaskan Brewing Co.   \n",
       "1                Double Bag  Altbier  Long Trail Brewing Co.   \n",
       "2            Long Trail Ale  Altbier  Long Trail Brewing Co.   \n",
       "\n",
       "Column Name                       Beer Name (Full)  \\\n",
       "0                Alaskan Brewing Co. Alaskan Amber   \n",
       "1                Long Trail Brewing Co. Double Bag   \n",
       "2            Long Trail Brewing Co. Long Trail Ale   \n",
       "\n",
       "Column Name                                        Description  ABV  Min IBU  \\\n",
       "0            Notes:Richly malty and long on the palate, wit...  5.3       25   \n",
       "1            Notes:This malty, full-bodied double alt is al...  7.2       25   \n",
       "2            Notes:Long Trail Ale is a full-bodied amber al...  5.0       25   \n",
       "\n",
       "Column Name  Max IBU  Astringency  Body  Alcohol  Bitter  Sweet  Sour  Salty  \\\n",
       "0                 50         13.0  32.0      9.0    47.0   74.0  33.0      0   \n",
       "1                 50         12.0  57.0     18.0    33.0   55.0  16.0      0   \n",
       "2                 50         14.0  37.0      6.0    42.0   43.0  11.0      0   \n",
       "\n",
       "Column Name  Fruits  Hoppy  Spices  Malty  review_overall  number_of_reviews  \n",
       "0              33.0   57.0     8.0  111.0        3.847082              497.0  \n",
       "1              24.0   35.0    12.0   84.0        4.034304              481.0  \n",
       "2              10.0   54.0     4.0   62.0        3.830239              377.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Loop through processed files in rename_files\n",
    "for file_name in dataset_config['rename_files']:\n",
    "    # Remove .csv or .tsv extension to get the base name\n",
    "    file_base = os.path.splitext(file_name)[0]\n",
    "    processed_filename = f\"{file_base}_processed.pkl\"\n",
    "    processed_path = os.path.join(download_path, processed_filename)\n",
    "\n",
    "    # Load the bundled dictionary (data + summary + config)\n",
    "    bundle = pd.read_pickle(processed_path)\n",
    "\n",
    "    # Extract components\n",
    "    loaded_df = bundle['data']\n",
    "    summary_df = bundle['summary']\n",
    "    loaded_config = bundle['config']\n",
    "\n",
    "    print(f\"\\n=== {file_base.upper()} ===\")\n",
    "    print(f\"Loaded config keys: {list(loaded_config.keys())}\")\n",
    "\n",
    "    # Show metadata\n",
    "    meta_df = pd.DataFrame(loaded_df.columns.tolist(), columns=['Column Name', 'Type', '# Categories'])\n",
    "    display(meta_df)\n",
    "\n",
    "    # Flatten for modeling\n",
    "    loaded_df.columns = loaded_df.columns.get_level_values(0)\n",
    "    display(loaded_df.head(n=3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6830d5b9",
   "metadata": {},
   "source": [
    "### Bonus insights (Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9221ce38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Get target series\n",
    "target_series = loaded_df[dataset_config['target']]\n",
    "\n",
    "\n",
    "# 1️⃣ Histogram with Freedman-Diaconis rule for binning\n",
    "q25, q75 = np.percentile(target_series, [25, 75])\n",
    "iqr = q75 - q25\n",
    "bin_width = 2 * iqr * len(target_series) ** (-1/3)\n",
    "bin_count = int((target_series.max() - target_series.min()) / bin_width)\n",
    "bin_count = max(10, bin_count)  # Ensure reasonable minimum bin count\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(target_series, bins=bin_count, edgecolor='black', alpha=0.7)\n",
    "plt.title(f\"Histogram of '{dataset_config['target']}' (Adaptive Binning)\")\n",
    "plt.xlabel(dataset_config['target'])\n",
    "plt.ylabel('Count')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2️⃣ Cumulative Distribution Function (CDF)\n",
    "target_sorted = target_series.sort_values()\n",
    "cdf = np.arange(len(target_sorted)) / len(target_sorted)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(target_sorted, cdf, color='tab:blue')\n",
    "plt.title(f\"Cumulative Distribution of '{dataset_config['target']}'\")\n",
    "plt.xlabel(dataset_config['target'])\n",
    "plt.ylabel('Cumulative Probability')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bfcd2f1b-a4c8-4442-9e0e-792d6783191a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250521_155333\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #53~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Jan 15 19:18:46 UTC 2\n",
      "CPU Count:          64\n",
      "Memory Avail:       456.77 GB / 503.54 GB (90.7%)\n",
      "Disk Space Avail:   33796.91 GB / 51214.59 GB (66.0%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[WRAPPER] Running stratified downsampling mode for task: reg\n",
      "\u001b[1;36mInfo:\u001b[0m \n",
      "[INFO] Downsampling dataframe: beer_rating (original rows: 2914)\n",
      "\u001b[1;33mInfo:\u001b[0m Dataset has only 2914 rows. No downsampling needed.\n",
      "Downsampled 2914 rows for beer_rating dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Beginning AutoGluon training ... Time limit = 360s\n",
      "AutoGluon will save models to \"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/regression/AutogluonModels/ag-20250521_155333\"\n",
      "Train Data Rows:    2331\n",
      "Train Data Columns: 20\n",
      "Label Column:       review_overall\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    467938.56 MB\n",
      "\tTrain Data (Original)  Memory Usage: 1.73 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['Style', 'Brewery', 'Beer Name (Full)', 'Description']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 562\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])        : 12 | ['ABV', 'Astringency', 'Body', 'Alcohol', 'Bitter', ...]\n",
      "\t\t('int', [])          :  3 | ['Min IBU', 'Max IBU', 'Salty']\n",
      "\t\t('object', [])       :  1 | ['Name']\n",
      "\t\t('object', ['text']) :  4 | ['Style', 'Brewery', 'Beer Name (Full)', 'Description']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    :   1 | ['Name']\n",
      "\t\t('category', ['text_as_category'])  :   3 | ['Style', 'Brewery', 'Description']\n",
      "\t\t('float', [])                       :  12 | ['ABV', 'Astringency', 'Body', 'Alcohol', 'Bitter', ...]\n",
      "\t\t('int', [])                         :   3 | ['Min IBU', 'Max IBU', 'Salty']\n",
      "\t\t('int', ['binned', 'text_special']) :  66 | ['Style.char_count', 'Style.word_count', 'Style.capital_ratio', 'Style.lower_ratio', 'Style.special_ratio', ...]\n",
      "\t\t('int', ['text_ngram'])             : 549 | ['__nlp__.10', '__nlp__.100', '__nlp__.12', '__nlp__.20', '__nlp__.abbey', ...]\n",
      "\t12.0s = Fit runtime\n",
      "\t20 features in original data used to generate 634 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 2.87 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 12.1s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 231.87s of the 347.87s of remaining time.\n",
      "\t0.3673\t = Validation score   (r2)\n",
      "\t0.11s\t = Training   runtime\n",
      "\t0.28s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 231.25s of the 347.25s of remaining time.\n",
      "\t0.3751\t = Validation score   (r2)\n",
      "\t0.11s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 230.74s of the 346.74s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.03%)\n",
      "\t0.528\t = Validation score   (r2)\n",
      "\t151.48s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 59.06s of the 175.06s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.03%)\n",
      "\t0.1325\t = Validation score   (r2)\n",
      "\t79.04s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 347.90s of the 92.41s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.824, 'KNeighborsDist_BAG_L1': 0.176}\n",
      "\t0.5356\t = Validation score   (r2)\n",
      "\t0.13s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 106 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 92.22s of the 92.15s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.03%)\n",
      "\t0.2346\t = Validation score   (r2)\n",
      "\t102.41s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 347.90s of the -13.75s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.824, 'KNeighborsDist_BAG_L1': 0.176}\n",
      "\t0.5356\t = Validation score   (r2)\n",
      "\t0.13s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 373.99s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1931.8 rows/s (292 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/regression/AutogluonModels/ag-20250521_155333\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250521_155949\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #53~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Jan 15 19:18:46 UTC 2\n",
      "CPU Count:          64\n",
      "Memory Avail:       453.98 GB / 503.54 GB (90.2%)\n",
      "Disk Space Avail:   33796.67 GB / 51214.59 GB (66.0%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ... Time limit = 360s\n",
      "AutoGluon will save models to \"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/regression/AutogluonModels/ag-20250521_155949\"\n",
      "Train Data Rows:    2331\n",
      "Train Data Columns: 15\n",
      "Label Column:       review_overall\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    464905.95 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.27 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['ABV', 'Astringency', 'Body', 'Alcohol', 'Bitter', ...]\n",
      "\t\t('int', [])   :  3 | ['Min IBU', 'Max IBU', 'Salty']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['ABV', 'Astringency', 'Body', 'Alcohol', 'Bitter', ...]\n",
      "\t\t('int', [])   :  3 | ['Min IBU', 'Max IBU', 'Salty']\n",
      "\t0.1s = Fit runtime\n",
      "\t15 features in original data used to generate 15 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.27 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.09s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 239.88s of the 359.88s of remaining time.\n",
      "\t0.3815\t = Validation score   (r2)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 239.70s of the 359.70s of remaining time.\n",
      "\t0.3871\t = Validation score   (r2)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 239.57s of the 359.57s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.4771\t = Validation score   (r2)\n",
      "\t227.39s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 9.35s of the 129.36s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.0441\t = Validation score   (r2)\n",
      "\t63.66s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 359.91s of the 62.11s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.762, 'KNeighborsDist_BAG_L1': 0.238}\n",
      "\t0.4869\t = Validation score   (r2)\n",
      "\t0.12s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 106 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 61.94s of the 61.88s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.3803\t = Validation score   (r2)\n",
      "\t95.71s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 359.91s of the -38.39s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.762, 'KNeighborsDist_BAG_L1': 0.238}\n",
      "\t0.4869\t = Validation score   (r2)\n",
      "\t0.11s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 398.57s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 5065.2 rows/s (292 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/regression/AutogluonModels/ag-20250521_155949\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250521_160627\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #53~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Jan 15 19:18:46 UTC 2\n",
      "CPU Count:          64\n",
      "Memory Avail:       472.50 GB / 503.54 GB (93.8%)\n",
      "Disk Space Avail:   33796.51 GB / 51214.59 GB (66.0%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ... Time limit = 360s\n",
      "AutoGluon will save models to \"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/regression/AutogluonModels/ag-20250521_160627\"\n",
      "Train Data Rows:    2331\n",
      "Train Data Columns: 20\n",
      "Label Column:       review_overall\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    483898.98 MB\n",
      "\tTrain Data (Original)  Memory Usage: 1.92 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['Style', 'Brewery', 'Beer Name (Full)', 'Description']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 564\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])        : 12 | ['ABV', 'Astringency', 'Body', 'Alcohol', 'Bitter', ...]\n",
      "\t\t('int', [])          :  3 | ['Min IBU', 'Max IBU', 'Salty']\n",
      "\t\t('object', [])       :  1 | ['Name']\n",
      "\t\t('object', ['text']) :  4 | ['Style', 'Brewery', 'Beer Name (Full)', 'Description']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    :   1 | ['Name']\n",
      "\t\t('category', ['text_as_category'])  :   3 | ['Style', 'Brewery', 'Description']\n",
      "\t\t('float', [])                       :  12 | ['ABV', 'Astringency', 'Body', 'Alcohol', 'Bitter', ...]\n",
      "\t\t('int', [])                         :   3 | ['Min IBU', 'Max IBU', 'Salty']\n",
      "\t\t('int', ['binned', 'text_special']) :  64 | ['Style.char_count', 'Style.word_count', 'Style.capital_ratio', 'Style.lower_ratio', 'Style.special_ratio', ...]\n",
      "\t\t('int', ['text_ngram'])             : 552 | ['__nlp__.10', '__nlp__.100', '__nlp__.12', '__nlp__.20', '__nlp__.2009', ...]\n",
      "\t13.5s = Fit runtime\n",
      "\t20 features in original data used to generate 635 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 2.88 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 13.74s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 230.78s of the 346.23s of remaining time.\n",
      "\t0.3616\t = Validation score   (r2)\n",
      "\t0.13s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 230.20s of the 345.66s of remaining time.\n",
      "\t0.3717\t = Validation score   (r2)\n",
      "\t0.16s\t = Training   runtime\n",
      "\t0.44s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 229.31s of the 344.76s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.03%)\n",
      "\t0.4841\t = Validation score   (r2)\n",
      "\t228.34s\t = Training   runtime\n",
      "\t0.42s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 346.26s of the 108.24s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.733, 'KNeighborsDist_BAG_L1': 0.267}\n",
      "\t0.5014\t = Validation score   (r2)\n",
      "\t0.09s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 106 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 108.10s of the 108.05s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.03%)\n",
      "\t0.5636\t = Validation score   (r2)\n",
      "\t135.34s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 346.26s of the -31.01s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L2': 0.944, 'LightGBMXT_BAG_L1': 0.056}\n",
      "\t0.5639\t = Validation score   (r2)\n",
      "\t0.1s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 391.22s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 422.5 rows/s (292 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/regression/AutogluonModels/ag-20250521_160627\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250521_161300\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #53~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Jan 15 19:18:46 UTC 2\n",
      "CPU Count:          64\n",
      "Memory Avail:       472.63 GB / 503.54 GB (93.9%)\n",
      "Disk Space Avail:   33796.24 GB / 51214.59 GB (66.0%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ... Time limit = 360s\n",
      "AutoGluon will save models to \"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/regression/AutogluonModels/ag-20250521_161300\"\n",
      "Train Data Rows:    2331\n",
      "Train Data Columns: 15\n",
      "Label Column:       review_overall\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    483967.97 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.27 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['ABV', 'Astringency', 'Body', 'Alcohol', 'Bitter', ...]\n",
      "\t\t('int', [])   :  3 | ['Min IBU', 'Max IBU', 'Salty']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['ABV', 'Astringency', 'Body', 'Alcohol', 'Bitter', ...]\n",
      "\t\t('int', [])   :  3 | ['Min IBU', 'Max IBU', 'Salty']\n",
      "\t0.1s = Fit runtime\n",
      "\t15 features in original data used to generate 15 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.27 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.1s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 239.87s of the 359.88s of remaining time.\n",
      "\t0.3509\t = Validation score   (r2)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 239.74s of the 359.74s of remaining time.\n",
      "\t0.3627\t = Validation score   (r2)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 239.61s of the 359.61s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.5059\t = Validation score   (r2)\n",
      "\t250.92s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 359.90s of the 101.23s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.84, 'KNeighborsDist_BAG_L1': 0.16}\n",
      "\t0.5113\t = Validation score   (r2)\n",
      "\t0.1s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 106 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 101.07s of the 101.01s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.1721\t = Validation score   (r2)\n",
      "\t125.24s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 359.90s of the -28.62s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.84, 'KNeighborsDist_BAG_L1': 0.16}\n",
      "\t0.5113\t = Validation score   (r2)\n",
      "\t0.11s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 388.81s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1694.8 rows/s (292 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/regression/AutogluonModels/ag-20250521_161300\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250521_161929\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #53~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Jan 15 19:18:46 UTC 2\n",
      "CPU Count:          64\n",
      "Memory Avail:       473.72 GB / 503.54 GB (94.1%)\n",
      "Disk Space Avail:   33796.07 GB / 51214.59 GB (66.0%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ... Time limit = 360s\n",
      "AutoGluon will save models to \"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/regression/AutogluonModels/ag-20250521_161929\"\n",
      "Train Data Rows:    2331\n",
      "Train Data Columns: 20\n",
      "Label Column:       review_overall\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    485074.89 MB\n",
      "\tTrain Data (Original)  Memory Usage: 1.95 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['Style', 'Brewery', 'Beer Name (Full)', 'Description']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 548\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])        : 12 | ['ABV', 'Astringency', 'Body', 'Alcohol', 'Bitter', ...]\n",
      "\t\t('int', [])          :  3 | ['Min IBU', 'Max IBU', 'Salty']\n",
      "\t\t('object', [])       :  1 | ['Name']\n",
      "\t\t('object', ['text']) :  4 | ['Style', 'Brewery', 'Beer Name (Full)', 'Description']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    :   1 | ['Name']\n",
      "\t\t('category', ['text_as_category'])  :   3 | ['Style', 'Brewery', 'Description']\n",
      "\t\t('float', [])                       :  12 | ['ABV', 'Astringency', 'Body', 'Alcohol', 'Bitter', ...]\n",
      "\t\t('int', [])                         :   3 | ['Min IBU', 'Max IBU', 'Salty']\n",
      "\t\t('int', ['binned', 'text_special']) :  65 | ['Style.char_count', 'Style.word_count', 'Style.capital_ratio', 'Style.lower_ratio', 'Style.special_ratio', ...]\n",
      "\t\t('int', ['text_ngram'])             : 539 | ['__nlp__.10', '__nlp__.100', '__nlp__.12', '__nlp__.20', '__nlp__.2009', ...]\n",
      "\t11.0s = Fit runtime\n",
      "\t20 features in original data used to generate 623 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 2.82 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 11.12s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 232.53s of the 348.85s of remaining time.\n",
      "\t0.3405\t = Validation score   (r2)\n",
      "\t0.15s\t = Training   runtime\n",
      "\t0.37s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 231.73s of the 348.06s of remaining time.\n",
      "\t0.3514\t = Validation score   (r2)\n",
      "\t0.15s\t = Training   runtime\n",
      "\t0.43s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 230.89s of the 347.21s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.03%)\n",
      "\t0.5282\t = Validation score   (r2)\n",
      "\t232.36s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 348.88s of the 107.18s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.833, 'KNeighborsDist_BAG_L1': 0.167}\n",
      "\t0.5354\t = Validation score   (r2)\n",
      "\t0.07s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 106 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 107.05s of the 107.01s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.03%)\n",
      "\t0.5364\t = Validation score   (r2)\n",
      "\t124.52s\t = Training   runtime\n",
      "\t0.23s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 348.88s of the -22.37s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L2': 0.526, 'LightGBMXT_BAG_L1': 0.421, 'KNeighborsDist_BAG_L1': 0.053}\n",
      "\t0.5499\t = Validation score   (r2)\n",
      "\t0.12s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 382.6s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 539.0 rows/s (292 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/regression/AutogluonModels/ag-20250521_161929\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250521_162552\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #53~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Jan 15 19:18:46 UTC 2\n",
      "CPU Count:          64\n",
      "Memory Avail:       475.14 GB / 503.54 GB (94.4%)\n",
      "Disk Space Avail:   33803.11 GB / 51214.59 GB (66.0%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ... Time limit = 360s\n",
      "AutoGluon will save models to \"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/regression/AutogluonModels/ag-20250521_162552\"\n",
      "Train Data Rows:    2331\n",
      "Train Data Columns: 15\n",
      "Label Column:       review_overall\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    486495.16 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.27 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['ABV', 'Astringency', 'Body', 'Alcohol', 'Bitter', ...]\n",
      "\t\t('int', [])   :  3 | ['Min IBU', 'Max IBU', 'Salty']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['ABV', 'Astringency', 'Body', 'Alcohol', 'Bitter', ...]\n",
      "\t\t('int', [])   :  3 | ['Min IBU', 'Max IBU', 'Salty']\n",
      "\t0.1s = Fit runtime\n",
      "\t15 features in original data used to generate 15 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.27 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.08s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 239.88s of the 359.88s of remaining time.\n",
      "\t0.3609\t = Validation score   (r2)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 239.71s of the 359.71s of remaining time.\n",
      "\t0.371\t = Validation score   (r2)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 239.52s of the 359.53s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.3225\t = Validation score   (r2)\n",
      "\t229.98s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 3.60s of the 123.61s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.0374\t = Validation score   (r2)\n",
      "\t49.87s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 359.92s of the 69.52s of remaining time.\n",
      "\tEnsemble Weights: {'KNeighborsDist_BAG_L1': 0.591, 'LightGBMXT_BAG_L1': 0.409}\n",
      "\t0.4141\t = Validation score   (r2)\n",
      "\t0.11s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 106 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 69.36s of the 69.32s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.3685\t = Validation score   (r2)\n",
      "\t97.45s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 359.92s of the -32.34s of remaining time.\n",
      "\tEnsemble Weights: {'KNeighborsDist_BAG_L1': 0.5, 'LightGBMXT_BAG_L2': 0.312, 'LightGBMXT_BAG_L1': 0.188}\n",
      "\t0.421\t = Validation score   (r2)\n",
      "\t0.1s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 392.53s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 1112.6 rows/s (292 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/regression/AutogluonModels/ag-20250521_162552\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250521_163226\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #53~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Jan 15 19:18:46 UTC 2\n",
      "CPU Count:          64\n",
      "Memory Avail:       474.39 GB / 503.54 GB (94.2%)\n",
      "Disk Space Avail:   33802.97 GB / 51214.59 GB (66.0%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ... Time limit = 360s\n",
      "AutoGluon will save models to \"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/regression/AutogluonModels/ag-20250521_163226\"\n",
      "Train Data Rows:    2331\n",
      "Train Data Columns: 20\n",
      "Label Column:       review_overall\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    485954.36 MB\n",
      "\tTrain Data (Original)  Memory Usage: 1.90 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['Style', 'Brewery', 'Beer Name (Full)', 'Description']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 555\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])        : 12 | ['ABV', 'Astringency', 'Body', 'Alcohol', 'Bitter', ...]\n",
      "\t\t('int', [])          :  3 | ['Min IBU', 'Max IBU', 'Salty']\n",
      "\t\t('object', [])       :  1 | ['Name']\n",
      "\t\t('object', ['text']) :  4 | ['Style', 'Brewery', 'Beer Name (Full)', 'Description']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    :   1 | ['Name']\n",
      "\t\t('category', ['text_as_category'])  :   3 | ['Style', 'Brewery', 'Description']\n",
      "\t\t('float', [])                       :  12 | ['ABV', 'Astringency', 'Body', 'Alcohol', 'Bitter', ...]\n",
      "\t\t('int', [])                         :   3 | ['Min IBU', 'Max IBU', 'Salty']\n",
      "\t\t('int', ['binned', 'text_special']) :  63 | ['Style.char_count', 'Style.word_count', 'Style.capital_ratio', 'Style.lower_ratio', 'Style.special_ratio', ...]\n",
      "\t\t('int', ['text_ngram'])             : 546 | ['__nlp__.10', '__nlp__.100', '__nlp__.12', '__nlp__.15', '__nlp__.20', ...]\n",
      "\t11.5s = Fit runtime\n",
      "\t20 features in original data used to generate 628 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 2.85 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 11.62s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 232.19s of the 348.33s of remaining time.\n",
      "\t0.3999\t = Validation score   (r2)\n",
      "\t0.14s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 231.55s of the 347.70s of remaining time.\n",
      "\t0.4058\t = Validation score   (r2)\n",
      "\t0.12s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 231.02s of the 347.17s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.03%)\n",
      "\t0.3753\t = Validation score   (r2)\n",
      "\t238.52s\t = Training   runtime\n",
      "\t0.28s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 348.38s of the 103.92s of remaining time.\n",
      "\tEnsemble Weights: {'KNeighborsDist_BAG_L1': 0.556, 'LightGBMXT_BAG_L1': 0.444}\n",
      "\t0.4636\t = Validation score   (r2)\n",
      "\t0.11s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 106 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 103.75s of the 103.68s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.03%)\n",
      "\t0.5766\t = Validation score   (r2)\n",
      "\t126.91s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 348.38s of the -27.92s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L2': 0.955, 'KNeighborsDist_BAG_L1': 0.045}\n",
      "\t0.5769\t = Validation score   (r2)\n",
      "\t0.15s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 388.17s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 575.5 rows/s (292 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/regression/AutogluonModels/ag-20250521_163226\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250521_163855\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #53~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Jan 15 19:18:46 UTC 2\n",
      "CPU Count:          64\n",
      "Memory Avail:       475.08 GB / 503.54 GB (94.3%)\n",
      "Disk Space Avail:   33802.81 GB / 51214.59 GB (66.0%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ... Time limit = 360s\n",
      "AutoGluon will save models to \"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/regression/AutogluonModels/ag-20250521_163855\"\n",
      "Train Data Rows:    2331\n",
      "Train Data Columns: 15\n",
      "Label Column:       review_overall\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    486609.87 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.27 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['ABV', 'Astringency', 'Body', 'Alcohol', 'Bitter', ...]\n",
      "\t\t('int', [])   :  3 | ['Min IBU', 'Max IBU', 'Salty']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['ABV', 'Astringency', 'Body', 'Alcohol', 'Bitter', ...]\n",
      "\t\t('int', [])   :  3 | ['Min IBU', 'Max IBU', 'Salty']\n",
      "\t0.1s = Fit runtime\n",
      "\t15 features in original data used to generate 15 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.27 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.09s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 239.88s of the 359.89s of remaining time.\n",
      "\t0.3832\t = Validation score   (r2)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 239.75s of the 359.76s of remaining time.\n",
      "\t0.3912\t = Validation score   (r2)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 239.62s of the 359.63s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.5\t = Validation score   (r2)\n",
      "\t231.56s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 4.11s of the 124.12s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.0399\t = Validation score   (r2)\n",
      "\t54.15s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 359.91s of the 65.79s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.8, 'KNeighborsDist_BAG_L1': 0.2}\n",
      "\t0.5071\t = Validation score   (r2)\n",
      "\t0.1s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 106 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 65.63s of the 65.57s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.3852\t = Validation score   (r2)\n",
      "\t89.74s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 359.91s of the -28.62s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.8, 'KNeighborsDist_BAG_L1': 0.2}\n",
      "\t0.5071\t = Validation score   (r2)\n",
      "\t0.12s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 388.83s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 2957.3 rows/s (292 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/regression/AutogluonModels/ag-20250521_163855\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250521_164524\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #53~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Jan 15 19:18:46 UTC 2\n",
      "CPU Count:          64\n",
      "Memory Avail:       474.62 GB / 503.54 GB (94.3%)\n",
      "Disk Space Avail:   33802.61 GB / 51214.59 GB (66.0%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ... Time limit = 360s\n",
      "AutoGluon will save models to \"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/regression/AutogluonModels/ag-20250521_164524\"\n",
      "Train Data Rows:    2332\n",
      "Train Data Columns: 20\n",
      "Label Column:       review_overall\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    486074.23 MB\n",
      "\tTrain Data (Original)  Memory Usage: 1.89 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['Style', 'Brewery', 'Beer Name (Full)', 'Description']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 551\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])        : 12 | ['ABV', 'Astringency', 'Body', 'Alcohol', 'Bitter', ...]\n",
      "\t\t('int', [])          :  3 | ['Min IBU', 'Max IBU', 'Salty']\n",
      "\t\t('object', [])       :  1 | ['Name']\n",
      "\t\t('object', ['text']) :  4 | ['Style', 'Brewery', 'Beer Name (Full)', 'Description']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    :   1 | ['Name']\n",
      "\t\t('category', ['text_as_category'])  :   3 | ['Style', 'Brewery', 'Description']\n",
      "\t\t('float', [])                       :  12 | ['ABV', 'Astringency', 'Body', 'Alcohol', 'Bitter', ...]\n",
      "\t\t('int', [])                         :   3 | ['Min IBU', 'Max IBU', 'Salty']\n",
      "\t\t('int', ['binned', 'text_special']) :  63 | ['Style.char_count', 'Style.word_count', 'Style.capital_ratio', 'Style.lower_ratio', 'Style.special_ratio', ...]\n",
      "\t\t('int', ['text_ngram'])             : 540 | ['__nlp__.10', '__nlp__.100', '__nlp__.12', '__nlp__.15', '__nlp__.20', ...]\n",
      "\t12.4s = Fit runtime\n",
      "\t20 features in original data used to generate 622 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 2.82 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 12.51s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 231.60s of the 347.46s of remaining time.\n",
      "\t0.3626\t = Validation score   (r2)\n",
      "\t0.11s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 231.00s of the 346.86s of remaining time.\n",
      "\t0.3686\t = Validation score   (r2)\n",
      "\t0.11s\t = Training   runtime\n",
      "\t0.29s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 230.37s of the 346.23s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.03%)\n",
      "\t0.597\t = Validation score   (r2)\n",
      "\t241.07s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 347.49s of the 100.06s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.955, 'KNeighborsDist_BAG_L1': 0.045}\n",
      "\t0.5975\t = Validation score   (r2)\n",
      "\t0.08s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 106 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 99.93s of the 99.88s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.03%)\n",
      "\t0.5031\t = Validation score   (r2)\n",
      "\t119.31s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 347.49s of the -23.97s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.955, 'KNeighborsDist_BAG_L1': 0.045}\n",
      "\t0.5975\t = Validation score   (r2)\n",
      "\t0.1s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 384.18s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1032.4 rows/s (292 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/regression/AutogluonModels/ag-20250521_164524\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250521_165149\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #53~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Jan 15 19:18:46 UTC 2\n",
      "CPU Count:          64\n",
      "Memory Avail:       474.05 GB / 503.54 GB (94.1%)\n",
      "Disk Space Avail:   33802.37 GB / 51214.59 GB (66.0%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ... Time limit = 360s\n",
      "AutoGluon will save models to \"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/regression/AutogluonModels/ag-20250521_165149\"\n",
      "Train Data Rows:    2332\n",
      "Train Data Columns: 15\n",
      "Label Column:       review_overall\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    485450.88 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.27 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['ABV', 'Astringency', 'Body', 'Alcohol', 'Bitter', ...]\n",
      "\t\t('int', [])   :  3 | ['Min IBU', 'Max IBU', 'Salty']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 12 | ['ABV', 'Astringency', 'Body', 'Alcohol', 'Bitter', ...]\n",
      "\t\t('int', [])   :  3 | ['Min IBU', 'Max IBU', 'Salty']\n",
      "\t0.1s = Fit runtime\n",
      "\t15 features in original data used to generate 15 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.27 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.08s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 239.88s of the 359.90s of remaining time.\n",
      "\t0.3756\t = Validation score   (r2)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 239.76s of the 359.77s of remaining time.\n",
      "\t0.3834\t = Validation score   (r2)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 239.64s of the 359.65s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.553\t = Validation score   (r2)\n",
      "\t233.85s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 359.92s of the 118.66s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.938, 'KNeighborsDist_BAG_L1': 0.062}\n",
      "\t0.5538\t = Validation score   (r2)\n",
      "\t0.08s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 106 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 118.52s of the 118.47s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.3876\t = Validation score   (r2)\n",
      "\t138.63s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 359.92s of the -25.77s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.938, 'KNeighborsDist_BAG_L1': 0.062}\n",
      "\t0.5538\t = Validation score   (r2)\n",
      "\t0.1s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 385.96s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1966.6 rows/s (292 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/regression/AutogluonModels/ag-20250521_165149\")\n"
     ]
    }
   ],
   "source": [
    "from baseline_eval import evaluate_baseline, plot_model_performance_summary\n",
    "results = evaluate_baseline(\n",
    "    df=loaded_df,\n",
    "    model='AGTabular',\n",
    "    df_name=dataset_config['dataset_name'],\n",
    "    label_col= dataset_config['target'],\n",
    "    task_type=dataset_config['task'],\n",
    "    textual_cols=textual_cols,\n",
    "    k_folds=5,\n",
    "    seed=0,\n",
    "    max_samples=3000,\n",
    "    output_path=f\"../../baseline_results/{dataset_config['task']}/{dataset_config['dataset_name']}.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f63eb723-37b5-4a13-bda9-8b8f9df49d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving plot to ../../baseline_results/plots/reg/score\n",
      "Saving plot to ../../baseline_results/plots/reg/loss\n",
      "Saving plot to ../../baseline_results/plots/reg/roc_auc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score':                                     mean       std\n",
       " model                                             \n",
       " AutoGluon_Tabular_without_text  0.512240  0.039466\n",
       " AutoGluon_Tabular_with_text     0.586292  0.027218,\n",
       " 'loss':                                     mean       std\n",
       " model                                             \n",
       " AutoGluon_Tabular_with_text     0.275878  0.013236\n",
       " AutoGluon_Tabular_without_text  0.299737  0.020999,\n",
       " 'roc_auc':                                 mean  std\n",
       " model                                    \n",
       " AutoGluon_Tabular_with_text      NaN  NaN\n",
       " AutoGluon_Tabular_without_text   NaN  NaN}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs = pd.read_csv(f\"../../baseline_results/{dataset_config['task']}/{dataset_config['dataset_name']}.csv\")\n",
    "plot_model_performance_summary(name=dataset_config['dataset_name'],task=dataset_config['task'], df=rs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
