{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0200d09",
   "metadata": {},
   "source": [
    "### Let's start with downloading the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4d0c4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "# to reach the dataloader_functions module\n",
    "module_path = os.path.abspath(os.path.join( \"..\"))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from dataloader_functions.download_data import download_raw_data\n",
    "current_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b8103e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO update this section per dataset\n",
    "dataset_config = {\n",
    "    'dataset_name': 'mercari_price',\n",
    "    'source': 'kaggle', # ['kaggle', 'local', 'openml', 'hf']\n",
    "    'remote_path': 'elizabethsam/mercari-price-suggestion-challenge',\n",
    "    'files': ['train.tsv'],\n",
    "    'rename_files': ['mercari_price.csv'],\n",
    "    'task': 'reg', # ['reg', 'cls']\n",
    "    'target': 'price',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4336bfef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36mInfo:\u001b[0m Dataset already downloaded in \u001b[1;35m/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/regression/../../datasets_files/raw/regression/mercari_price\u001b[0m.\n",
      "Downloaded mercari_price dataset to /home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/regression/../../datasets_files/raw/regression/mercari_price\n"
     ]
    }
   ],
   "source": [
    "if dataset_config['task'] == 'clf':\n",
    "    dataset_subfolder = os.path.join('raw', 'classification', dataset_config['dataset_name']) \n",
    "elif dataset_config['task'] == 'reg':\n",
    "    dataset_subfolder = os.path.join('raw', 'regression', dataset_config['dataset_name'])\n",
    "else:\n",
    "    raise ValueError(f\"Unknown task: {dataset_config['task']}\")\n",
    "\n",
    "# this path needs to be modified based on the location of the notebook\n",
    "download_path = os.path.join(current_dir, '..', '..', 'datasets_files', dataset_subfolder)\n",
    "\n",
    "if download_raw_data(\n",
    "    dataset_config=dataset_config,\n",
    "    download_path=download_path,\n",
    "    force_download=False,\n",
    "    remove_unlisted=True,\n",
    ") is not None:\n",
    "    print(f\"Downloaded {dataset_config['dataset_name']} dataset to {download_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d886637",
   "metadata": {},
   "source": [
    "### Now we need to preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48bcaebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader_functions.load_and_pp_raw_data import _drop_empty_columns, _drop_single_value_columns\n",
    "from dataloader_functions.utils.data_2_df import read_any_to_df\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "current_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebac05e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: to get the dataset size to a reasonable size, we will downsample the .csv files\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the path\n",
    "current_dir = os.getcwd()\n",
    "download_path = os.path.join(current_dir, '..', '..', 'datasets_files', dataset_subfolder)\n",
    "\n",
    "# File paths\n",
    "train_path = os.path.join(download_path, dataset_config['rename_files'][0])\n",
    "\n",
    "# Load safely, skipping bad lines\n",
    "train_df = pd.read_csv(train_path, on_bad_lines='skip', engine='python')\n",
    "\n",
    "# Downsample with fallback if not enough rows\n",
    "train_sample_size = min(len(train_df), 12000)\n",
    "\n",
    "train_df = train_df.sample(n=train_sample_size, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Save back (overwrite the originals)\n",
    "train_df.to_csv(train_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0861820c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading /home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/regression/../../datasets_files/raw/regression/mercari_price/mercari_price.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_id</th>\n",
       "      <th>name</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>category_name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>price</th>\n",
       "      <th>shipping</th>\n",
       "      <th>item_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>576884</td>\n",
       "      <td>Kylie_drabczak hooter girl</td>\n",
       "      <td>2</td>\n",
       "      <td>Handmade/Clothing/Costume</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>This listing is only for Kylie_drabczak it inc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>739922</td>\n",
       "      <td>Bundle for Girls Size 2T</td>\n",
       "      <td>3</td>\n",
       "      <td>Kids/Girls 2T-5T/Tops &amp; T-Shirts</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Perfect condition No stains</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1265661</td>\n",
       "      <td>Lularoe XL Amelia NWT</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Dresses/Knee-Length</td>\n",
       "      <td>LuLaRoe</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NWT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_id                        name  item_condition_id  \\\n",
       "0    576884  Kylie_drabczak hooter girl                  2   \n",
       "1    739922    Bundle for Girls Size 2T                  3   \n",
       "2   1265661       Lularoe XL Amelia NWT                  1   \n",
       "\n",
       "                      category_name brand_name  price  shipping  \\\n",
       "0         Handmade/Clothing/Costume        NaN   15.0         1   \n",
       "1  Kids/Girls 2T-5T/Tops & T-Shirts        NaN    7.0         0   \n",
       "2         Women/Dresses/Knee-Length    LuLaRoe   62.0         0   \n",
       "\n",
       "                                    item_description  \n",
       "0  This listing is only for Kylie_drabczak it inc...  \n",
       "1                        Perfect condition No stains  \n",
       "2                                                NWT  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dataset_files_df = []\n",
    "\n",
    "if dataset_config['rename_files'] is None or len(dataset_config['rename_files']) == 0:\n",
    "    dataset_config['rename_files'] = dataset_config['files']\n",
    "\n",
    "for file in dataset_config['rename_files']:\n",
    "\n",
    "    file_location = os.path.join(download_path, file)\n",
    "\n",
    "    print(f\"Loading {file_location}\")\n",
    "\n",
    "    dataset_files_df.append(read_any_to_df(file_location))\n",
    "\n",
    "# example of the loaded df data:\n",
    "pd.set_option('display.max_columns', None)\n",
    "dataset_files_df[0].head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d099b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped: Index([], dtype='object')\n",
      "Dataframe shape before/afrer cleaning: (12000, 8) / (12000, 8)\n"
     ]
    }
   ],
   "source": [
    "## Run some basic data cleaning\n",
    "\n",
    "dataset_files_gen_cleaned = []\n",
    "missing_ratio_threshold = 0.5 # TODO the threshold can be changed\n",
    "\n",
    "for df_file in dataset_files_df:\n",
    "    df_size = df_file.shape\n",
    "    # 1. Drop columns with more than 50% missing values\n",
    "    df_file = _drop_empty_columns(df_file, threshold=missing_ratio_threshold)   \n",
    "    # 2. Drop columns with only one unique value\n",
    "    df_file = _drop_single_value_columns(df_file)\n",
    "    # 3. remove duplicates\n",
    "    df_file = df_file.drop_duplicates()\n",
    "    # 4. remove rows with missing target values\n",
    "    if dataset_config['target'] in df_file.columns:\n",
    "        df_file = df_file[df_file[dataset_config['target']].notna()]\n",
    "    # 5. drop unnamed columns\n",
    "    df_file = df_file.loc[:, ~df_file.columns.str.contains('^Unnamed')]\n",
    "\n",
    "    dataset_files_gen_cleaned.append(df_file)\n",
    "\n",
    "    print(f\"Dataframe shape before/afrer cleaning: {df_size} / {df_file.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0a2a11a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column test_id not found in dataframe\n",
      "Dataframe shape before/afrer by-hand cleaning: (12000, 8) / (12000, 7)\n"
     ]
    }
   ],
   "source": [
    "## TODO: Now run custom data cleaning -> remove non-essential columns\n",
    "\n",
    "cols_to_drop = ['train_id', 'test_id']\n",
    "\n",
    "dataset_files_cleaned = []\n",
    "\n",
    "# assuming for multiple files we still want to drop the same columns\n",
    "for df_file in dataset_files_gen_cleaned:\n",
    "    df_size = df_file.shape\n",
    "    for col in cols_to_drop:\n",
    "        if col in df_file.columns:\n",
    "            df_file.drop(col, axis=1, inplace=True)\n",
    "        else:\n",
    "            print(f\"Column {col} not found in dataframe\")\n",
    "\n",
    "    dataset_files_cleaned.append(df_file)    \n",
    "    print(f\"Dataframe shape before/afrer by-hand cleaning: {df_size} / {df_file.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d90a681b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe shape before custom cleaning: (12000, 7)\n",
      "Dataframe shape after custom clearning: (12000, 7)\n"
     ]
    }
   ],
   "source": [
    "# TODO: some custom data cleaning\n",
    "\n",
    "import copy \n",
    "tmp_df = copy.deepcopy(dataset_files_cleaned)\n",
    "dataset_files_by_hand_cleaned = []\n",
    "\n",
    "for df_file in dataset_files_cleaned:\n",
    "    print(f\"Dataframe shape before custom cleaning: {df_file.shape}\")\n",
    "    # TODO: add custom data cleaning here\n",
    "    # e.g. remove columns with too many unique values\n",
    "    print(f\"Dataframe shape after custom clearning: {df_file.shape}\")\n",
    "\n",
    "    dataset_files_by_hand_cleaned.append(df_file)\n",
    "\n",
    "# reset the dataframe list to the version before custom cleaning -> next cells work wuth dataset_files_by_hand_cleaned\n",
    "dataset_files_cleaned = tmp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581b17e1",
   "metadata": {},
   "source": [
    "### Now it is time to visualize our changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1500c210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>category_name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>price</th>\n",
       "      <th>shipping</th>\n",
       "      <th>item_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kylie_drabczak hooter girl</td>\n",
       "      <td>2</td>\n",
       "      <td>Handmade/Clothing/Costume</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>This listing is only for Kylie_drabczak it inc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bundle for Girls Size 2T</td>\n",
       "      <td>3</td>\n",
       "      <td>Kids/Girls 2T-5T/Tops &amp; T-Shirts</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Perfect condition No stains</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lularoe XL Amelia NWT</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Dresses/Knee-Length</td>\n",
       "      <td>LuLaRoe</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NWT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         name  item_condition_id  \\\n",
       "0  Kylie_drabczak hooter girl                  2   \n",
       "1    Bundle for Girls Size 2T                  3   \n",
       "2       Lularoe XL Amelia NWT                  1   \n",
       "\n",
       "                      category_name brand_name  price  shipping  \\\n",
       "0         Handmade/Clothing/Costume        NaN   15.0         1   \n",
       "1  Kids/Girls 2T-5T/Tops & T-Shirts        NaN    7.0         0   \n",
       "2         Women/Dresses/Knee-Length    LuLaRoe   62.0         0   \n",
       "\n",
       "                                    item_description  \n",
       "0  This listing is only for Kylie_drabczak it inc...  \n",
       "1                        Perfect condition No stains  \n",
       "2                                                NWT  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "dataset_files_by_hand_cleaned[0].head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f71269d",
   "metadata": {},
   "source": [
    "Let's figure out which columns should be viewed as categorical / numerical / textual\n",
    "\n",
    "we can start with a simple heuristic:\n",
    "1. numerical is everything which\n",
    "    - keeps most of its character length after non-numeral strip\n",
    "    - has about the same number of unique values after the strip\n",
    "    + for the purpose of keeping \"semantic information\", hand picked columns can be viewed also as non-numerical, that is not the default benchmark approach though\n",
    "\n",
    "2. categorical is everthing non numerical, which can be then divided into N (where N << Num instances) unique categories\n",
    "\n",
    "3. textual is everything else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "436f9ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Threshold for categorical vs textual: 50\n",
      "Numerical columns (1): ['price']\n",
      "Categorical columns (2): ['item_condition_id', 'shipping']\n",
      "Textual columns (4): ['name', 'category_name', 'brand_name', 'item_description']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def is_mostly_numeric(series, length_threshold=0.5, unique_threshold=0.8):\n",
    "    \"\"\"Check if column is mostly numeric after stripping non-numeric chars.\"\"\"\n",
    "    stripped = series.astype(str).str.replace(r\"[^\\d\\.\\-]\", \"\", regex=True)\n",
    "    \n",
    "    original_len = series.astype(str).str.len().replace(0, 1)  # avoid div by zero\n",
    "    length_ratio = (stripped.str.len() / original_len).mean()\n",
    "\n",
    "    unique_ratio = stripped.nunique(dropna=False) / max(series.nunique(dropna=False), 1)\n",
    "\n",
    "    return length_ratio > length_threshold and unique_ratio > unique_threshold\n",
    "\n",
    "def classify_columns(df, unique_ratio_threshold=None, explicit_nunique_threshold=None):\n",
    "    \"\"\"\n",
    "    Classify dataframe columns into numerical, categorical, textual.\n",
    "    - Binary categorical (2 unique values) is considered categorical.\n",
    "    \"\"\"\n",
    "    n_rows = len(df)\n",
    "\n",
    "    # Determine threshold for categorical vs textual\n",
    "    if explicit_nunique_threshold is not None:\n",
    "        nunique_threshold = explicit_nunique_threshold\n",
    "    elif unique_ratio_threshold is not None:\n",
    "        nunique_threshold = int(unique_ratio_threshold * n_rows)\n",
    "    else:\n",
    "        nunique_threshold = int(0.05 * n_rows)  # default 5%\n",
    "\n",
    "    nunique_threshold = max(10, nunique_threshold)  # safeguard\n",
    "    print(f\"Threshold for categorical vs textual: {nunique_threshold}\")\n",
    "\n",
    "    numerical_cols = []\n",
    "    categorical_cols = []\n",
    "    textual_cols = []\n",
    "\n",
    "    for col in df.columns:\n",
    "        series = df[col]\n",
    "        nunique = series.nunique(dropna=False)\n",
    "\n",
    "        if pd.api.types.is_numeric_dtype(series):\n",
    "            if nunique <= nunique_threshold:\n",
    "                categorical_cols.append(col)\n",
    "            else:\n",
    "                numerical_cols.append(col)\n",
    "        \n",
    "        elif pd.api.types.is_string_dtype(series) or pd.api.types.is_object_dtype(series):\n",
    "            if is_mostly_numeric(series):\n",
    "                numerical_cols.append(col)\n",
    "            else:\n",
    "                if nunique <= nunique_threshold:\n",
    "                    categorical_cols.append(col)\n",
    "                else:\n",
    "                    textual_cols.append(col)\n",
    "        else:\n",
    "            print(f\"⚠️ Unhandled column type: '{col}' (dtype={series.dtype})\")\n",
    "\n",
    "    print(f\"Numerical columns ({len(numerical_cols)}): {numerical_cols}\")\n",
    "    print(f\"Categorical columns ({len(categorical_cols)}): {categorical_cols}\")\n",
    "    print(f\"Textual columns ({len(textual_cols)}): {textual_cols}\")\n",
    "\n",
    "    return numerical_cols, categorical_cols, textual_cols\n",
    "\n",
    "# Example usage:\n",
    "for df_file in dataset_files_by_hand_cleaned:\n",
    "    # Ratio-based (5% of rows)\n",
    "    # umerical_cols, categorical_cols, textual_cols = classify_columns(df_file, unique_ratio_threshold=0.05)\n",
    "    print(\"\")\n",
    "    # OR explicit value (e.g., anything <= 50 is categorical)\n",
    "    numerical_cols, categorical_cols, textual_cols = classify_columns(df_file, explicit_nunique_threshold=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6499589b",
   "metadata": {},
   "source": [
    "Now let's just try to visualize the kept features, their example values, and their cat/num/text allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afffbdb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column Name</th>\n",
       "      <th>Example Value</th>\n",
       "      <th>Type</th>\n",
       "      <th># Categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>name</td>\n",
       "      <td>Kylie_drabczak hooter girl</td>\n",
       "      <td>textual</td>\n",
       "      <td>11763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>item_condition_id</td>\n",
       "      <td>2</td>\n",
       "      <td>categorical</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>category_name</td>\n",
       "      <td>Handmade/Clothing/Costume</td>\n",
       "      <td>textual</td>\n",
       "      <td>637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>brand_name</td>\n",
       "      <td>LuLaRoe</td>\n",
       "      <td>textual</td>\n",
       "      <td>805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>price</td>\n",
       "      <td>15.0</td>\n",
       "      <td>numerical</td>\n",
       "      <td>~ 222 ~</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>shipping</td>\n",
       "      <td>1</td>\n",
       "      <td>categorical</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>item_description</td>\n",
       "      <td>This listing is only for Kylie_drabczak it inc...</td>\n",
       "      <td>textual</td>\n",
       "      <td>10804</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Column Name                                      Example Value  \\\n",
       "0               name                         Kylie_drabczak hooter girl   \n",
       "1  item_condition_id                                                  2   \n",
       "2      category_name                          Handmade/Clothing/Costume   \n",
       "3         brand_name                                            LuLaRoe   \n",
       "4              price                                               15.0   \n",
       "5           shipping                                                  1   \n",
       "6   item_description  This listing is only for Kylie_drabczak it inc...   \n",
       "\n",
       "          Type # Categories  \n",
       "0      textual        11763  \n",
       "1  categorical            5  \n",
       "2      textual          637  \n",
       "3      textual          805  \n",
       "4    numerical      ~ 222 ~  \n",
       "5  categorical            2  \n",
       "6      textual        10804  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary = []\n",
    "for col in df_file.columns:\n",
    "    if col in categorical_cols:\n",
    "        col_type = \"categorical\"\n",
    "        num_categories = df_file[col].nunique(dropna=True)\n",
    "        num_categories_display = int(num_categories)\n",
    "    elif col in textual_cols:\n",
    "        col_type = \"textual\"\n",
    "        num_categories = df_file[col].nunique(dropna=True)\n",
    "        num_categories_display = int(num_categories)\n",
    "    elif col in numerical_cols:\n",
    "        col_type = \"numerical\"\n",
    "        num_categories = df_file[col].nunique(dropna=True)\n",
    "        num_categories_display = '~ ' + str(num_categories) + ' ~'\n",
    "    else:\n",
    "        col_type = \"unknown\"\n",
    "        num_categories_display = '--'\n",
    "\n",
    "    example = df_file[col].dropna().iloc[0] if df_file[col].dropna().size > 0 else None\n",
    "    summary.append({\n",
    "        'Column Name': col,\n",
    "        'Example Value': str(example),\n",
    "        'Type': col_type,\n",
    "        '# Categories': num_categories_display\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary)\n",
    "\n",
    "# TODO: by hand changes of the type and category count -> e.g. for 'Location':\n",
    "#    # Post-processing: override the type and category count for 'Location'\n",
    "#    # summary_df.loc[summary_df['Column Name'] == 'Location', 'Type'] = 'textual'\n",
    "#    # num_categories = df_file['Location'].nunique(dropna=True)\n",
    "#    # summary_df.loc[summary_df['Column Name'] == 'Location', '# Categories'] = int(num_categories)\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "display(summary_df)  # Or print(summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448756bb",
   "metadata": {},
   "source": [
    "#### We also need to make sure that numerical columns are actually numerical :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73734b74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column Name</th>\n",
       "      <th>Example Value</th>\n",
       "      <th>Type</th>\n",
       "      <th># Categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>name</td>\n",
       "      <td>Kylie_drabczak hooter girl</td>\n",
       "      <td>textual</td>\n",
       "      <td>11763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>item_condition_id</td>\n",
       "      <td>2</td>\n",
       "      <td>categorical</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>category_name</td>\n",
       "      <td>Handmade/Clothing/Costume</td>\n",
       "      <td>textual</td>\n",
       "      <td>637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>brand_name</td>\n",
       "      <td>LuLaRoe</td>\n",
       "      <td>textual</td>\n",
       "      <td>805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>price</td>\n",
       "      <td>15.0</td>\n",
       "      <td>numerical</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>shipping</td>\n",
       "      <td>1</td>\n",
       "      <td>categorical</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>item_description</td>\n",
       "      <td>This listing is only for Kylie_drabczak it inc...</td>\n",
       "      <td>textual</td>\n",
       "      <td>10804</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Column Name                                      Example Value  \\\n",
       "0               name                         Kylie_drabczak hooter girl   \n",
       "1  item_condition_id                                                  2   \n",
       "2      category_name                          Handmade/Clothing/Costume   \n",
       "3         brand_name                                            LuLaRoe   \n",
       "4              price                                               15.0   \n",
       "5           shipping                                                  1   \n",
       "6   item_description  This listing is only for Kylie_drabczak it inc...   \n",
       "\n",
       "          Type # Categories  \n",
       "0      textual        11763  \n",
       "1  categorical            5  \n",
       "2      textual          637  \n",
       "3      textual          805  \n",
       "4    numerical          222  \n",
       "5  categorical            2  \n",
       "6      textual        10804  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import copy\n",
    "\n",
    "from dataloader_functions.load_and_pp_raw_data import clean_numerical_columns\n",
    "\n",
    "summary_df, dataset_files_by_hand_cleaned = clean_numerical_columns(summary_df, dataset_files_by_hand_cleaned)\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "display(summary_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ef8954",
   "metadata": {},
   "source": [
    "### Saving the processed data and loading it back up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2fe5eab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/regression/../../datasets_files/raw/regression/mercari_price/mercari_price_processed.pkl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Handle rename_files fallback\n",
    "if dataset_config['rename_files'] is None or len(dataset_config['rename_files']) == 0:\n",
    "    dataset_config['rename_files'] = dataset_config['files']\n",
    "\n",
    "for i, df_file in enumerate(dataset_files_by_hand_cleaned):\n",
    "    df_with_meta = df_file.copy()\n",
    "\n",
    "    # Get corresponding file name\n",
    "    file_name = dataset_config['rename_files'][i]\n",
    "    file_base = os.path.splitext(file_name)[0]\n",
    "\n",
    "    # Try assigning multi-index header from summary\n",
    "    try:\n",
    "        df_with_meta.columns = pd.MultiIndex.from_frame(\n",
    "            summary_df[['Column Name', 'Type', '# Categories']]\n",
    "        )\n",
    "        local_summary = summary_df.copy()\n",
    "    except ValueError:\n",
    "        local_summary = summary_df.copy()\n",
    "        if dataset_config['target'] in local_summary['Column Name'].values:\n",
    "            local_summary = local_summary[local_summary['Column Name'] != dataset_config['target']]\n",
    "            df_with_meta.columns = pd.MultiIndex.from_frame(\n",
    "                local_summary[['Column Name', 'Type', '# Categories']]\n",
    "            )\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "    # Construct and save everything together\n",
    "    output_filename = f\"{file_base}_processed.pkl\"\n",
    "    output_path = os.path.join(download_path, output_filename)\n",
    "\n",
    "    save_bundle = {\n",
    "        'data': df_with_meta,\n",
    "        'summary': local_summary,\n",
    "        'config': dataset_config\n",
    "    }\n",
    "\n",
    "    pd.to_pickle(save_bundle, output_path)\n",
    "    print(f\"Saved: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c7bcd87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== MERCARI_PRICE ===\n",
      "Loaded config keys: ['dataset_name', 'source', 'remote_path', 'files', 'rename_files', 'task', 'target']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column Name</th>\n",
       "      <th>Type</th>\n",
       "      <th># Categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>name</td>\n",
       "      <td>textual</td>\n",
       "      <td>11763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>item_condition_id</td>\n",
       "      <td>categorical</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>category_name</td>\n",
       "      <td>textual</td>\n",
       "      <td>637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>brand_name</td>\n",
       "      <td>textual</td>\n",
       "      <td>805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>price</td>\n",
       "      <td>numerical</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>shipping</td>\n",
       "      <td>categorical</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>item_description</td>\n",
       "      <td>textual</td>\n",
       "      <td>10804</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Column Name         Type  # Categories\n",
       "0               name      textual         11763\n",
       "1  item_condition_id  categorical             5\n",
       "2      category_name      textual           637\n",
       "3         brand_name      textual           805\n",
       "4              price    numerical           222\n",
       "5           shipping  categorical             2\n",
       "6   item_description      textual         10804"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Column Name</th>\n",
       "      <th>name</th>\n",
       "      <th>item_condition_id</th>\n",
       "      <th>category_name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>price</th>\n",
       "      <th>shipping</th>\n",
       "      <th>item_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kylie_drabczak hooter girl</td>\n",
       "      <td>2</td>\n",
       "      <td>Handmade/Clothing/Costume</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1</td>\n",
       "      <td>This listing is only for Kylie_drabczak it inc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bundle for Girls Size 2T</td>\n",
       "      <td>3</td>\n",
       "      <td>Kids/Girls 2T-5T/Tops &amp; T-Shirts</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Perfect condition No stains</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lularoe XL Amelia NWT</td>\n",
       "      <td>1</td>\n",
       "      <td>Women/Dresses/Knee-Length</td>\n",
       "      <td>LuLaRoe</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NWT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Column Name                        name  item_condition_id  \\\n",
       "0            Kylie_drabczak hooter girl                  2   \n",
       "1              Bundle for Girls Size 2T                  3   \n",
       "2                 Lularoe XL Amelia NWT                  1   \n",
       "\n",
       "Column Name                     category_name brand_name  price  shipping  \\\n",
       "0                   Handmade/Clothing/Costume        NaN   15.0         1   \n",
       "1            Kids/Girls 2T-5T/Tops & T-Shirts        NaN    7.0         0   \n",
       "2                   Women/Dresses/Knee-Length    LuLaRoe   62.0         0   \n",
       "\n",
       "Column Name                                   item_description  \n",
       "0            This listing is only for Kylie_drabczak it inc...  \n",
       "1                                  Perfect condition No stains  \n",
       "2                                                          NWT  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Loop through processed files in rename_files\n",
    "for file_name in dataset_config['rename_files']:\n",
    "    # Remove .csv or .tsv extension to get the base name\n",
    "    file_base = os.path.splitext(file_name)[0]\n",
    "    processed_filename = f\"{file_base}_processed.pkl\"\n",
    "    processed_path = os.path.join(download_path, processed_filename)\n",
    "\n",
    "    # Load the bundled dictionary (data + summary + config)\n",
    "    bundle = pd.read_pickle(processed_path)\n",
    "\n",
    "    # Extract components\n",
    "    loaded_df = bundle['data']\n",
    "    summary_df = bundle['summary']\n",
    "    loaded_config = bundle['config']\n",
    "\n",
    "    print(f\"\\n=== {file_base.upper()} ===\")\n",
    "    print(f\"Loaded config keys: {list(loaded_config.keys())}\")\n",
    "\n",
    "    # Show metadata\n",
    "    meta_df = pd.DataFrame(loaded_df.columns.tolist(), columns=['Column Name', 'Type', '# Categories'])\n",
    "    display(meta_df)\n",
    "\n",
    "    # Flatten for modeling\n",
    "    loaded_df.columns = loaded_df.columns.get_level_values(0)\n",
    "    display(loaded_df.head(n=3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4aa3f42",
   "metadata": {},
   "source": [
    "### Bonus insights (Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "054c2426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Get target series\n",
    "target_series = loaded_df[dataset_config['target']]\n",
    "\n",
    "# 1️⃣ Histogram with Freedman-Diaconis rule for binning\n",
    "q25, q75 = np.percentile(target_series, [25, 75])\n",
    "iqr = q75 - q25\n",
    "bin_width = 2 * iqr * len(target_series) ** (-1/3)\n",
    "bin_count = int((target_series.max() - target_series.min()) / bin_width)\n",
    "bin_count = max(10, bin_count)  # Ensure reasonable minimum bin count\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(target_series, bins=bin_count, edgecolor='black', alpha=0.7)\n",
    "plt.title(f\"Histogram of '{dataset_config['target']}' (Adaptive Binning)\")\n",
    "plt.xlabel(dataset_config['target'])\n",
    "plt.ylabel('Count')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2️⃣ Cumulative Distribution Function (CDF)\n",
    "target_sorted = target_series.sort_values()\n",
    "cdf = np.arange(len(target_sorted)) / len(target_sorted)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(target_sorted, cdf, color='tab:blue')\n",
    "plt.title(f\"Cumulative Distribution of '{dataset_config['target']}'\")\n",
    "plt.xlabel(dataset_config['target'])\n",
    "plt.ylabel('Cumulative Probability')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc633b46-a16e-4bef-a167-b24087bba846",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250522_221437\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #53~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Jan 15 19:18:46 UTC 2\n",
      "CPU Count:          64\n",
      "Memory Avail:       369.73 GB / 503.54 GB (73.4%)\n",
      "Disk Space Avail:   33770.86 GB / 51214.59 GB (65.9%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[WRAPPER] Running stratified downsampling mode for task: reg\n",
      "\u001b[1;36mInfo:\u001b[0m \n",
      "[INFO] Downsampling dataframe: mercari_price (original rows: 12000)\n",
      "Downsampled 3000 rows for mercari_price dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Beginning AutoGluon training ... Time limit = 360s\n",
      "AutoGluon will save models to \"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/regression/AutogluonModels/ag-20250522_221437\"\n",
      "Train Data Rows:    2400\n",
      "Train Data Columns: 6\n",
      "Label Column:       price\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    378536.06 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.97 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['name', 'item_description']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 288\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])          : 2 | ['item_condition_id', 'shipping']\n",
      "\t\t('object', [])       : 2 | ['category_name', 'brand_name']\n",
      "\t\t('object', ['text']) : 2 | ['name', 'item_description']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    :   2 | ['category_name', 'brand_name']\n",
      "\t\t('category', ['text_as_category'])  :   2 | ['name', 'item_description']\n",
      "\t\t('int', [])                         :   1 | ['item_condition_id']\n",
      "\t\t('int', ['binned', 'text_special']) :  41 | ['name.char_count', 'name.word_count', 'name.capital_ratio', 'name.lower_ratio', 'name.digit_ratio', ...]\n",
      "\t\t('int', ['bool'])                   :   1 | ['shipping']\n",
      "\t\t('int', ['text_ngram'])             : 285 | ['__nlp__.10', '__nlp__.100', '__nlp__.100 authentic', '__nlp__.11', '__nlp__.12', ...]\n",
      "\t6.1s = Fit runtime\n",
      "\t6 features in original data used to generate 332 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.44 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 6.16s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 235.84s of the 353.82s of remaining time.\n",
      "\t-0.2019\t = Validation score   (r2)\n",
      "\t0.06s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 235.46s of the 353.45s of remaining time.\n",
      "\t-0.2052\t = Validation score   (r2)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 235.18s of the 353.16s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.02%)\n",
      "\t0.1249\t = Validation score   (r2)\n",
      "\t77.52s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 129.15s of the 247.14s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.02%)\n",
      "\t0.1221\t = Validation score   (r2)\n",
      "\t70.08s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 56.17s of the 174.16s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.0476\t = Validation score   (r2)\n",
      "\t13.49s\t = Training   runtime\n",
      "\t0.56s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 41.61s of the 159.60s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.18%)\n",
      "\t0.1089\t = Validation score   (r2)\n",
      "\t46.12s\t = Training   runtime\n",
      "\t0.27s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 353.84s of the 110.18s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBM_BAG_L1': 0.36, 'LightGBMXT_BAG_L1': 0.32, 'CatBoost_BAG_L1': 0.2, 'RandomForestMSE_BAG_L1': 0.12}\n",
      "\t0.1428\t = Validation score   (r2)\n",
      "\t0.16s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 106 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 109.97s of the 109.91s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.02%)\n",
      "\t0.1331\t = Validation score   (r2)\n",
      "\t67.54s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 39.47s of the 39.41s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.02%)\n",
      "\t0.1371\t = Validation score   (r2)\n",
      "\t54.33s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 353.84s of the -18.03s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBM_BAG_L2': 0.435, 'LightGBMXT_BAG_L2': 0.348, 'RandomForestMSE_BAG_L1': 0.13, 'CatBoost_BAG_L1': 0.087}\n",
      "\t0.1487\t = Validation score   (r2)\n",
      "\t0.15s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 378.28s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 417.2 rows/s (300 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/regression/AutogluonModels/ag-20250522_221437\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250522_222057\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #53~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Jan 15 19:18:46 UTC 2\n",
      "CPU Count:          64\n",
      "Memory Avail:       365.92 GB / 503.54 GB (72.7%)\n",
      "Disk Space Avail:   33770.75 GB / 51214.59 GB (65.9%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ... Time limit = 360s\n",
      "AutoGluon will save models to \"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/regression/AutogluonModels/ag-20250522_222057\"\n",
      "Train Data Rows:    2400\n",
      "Train Data Columns: 2\n",
      "Label Column:       price\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    374695.19 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.04 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', []) : 2 | ['item_condition_id', 'shipping']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('int', [])       : 1 | ['item_condition_id']\n",
      "\t\t('int', ['bool']) : 1 | ['shipping']\n",
      "\t0.0s = Fit runtime\n",
      "\t2 features in original data used to generate 2 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.02 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.07s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 239.89s of the 359.90s of remaining time.\n",
      "\t-0.236\t = Validation score   (r2)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 239.77s of the 359.78s of remaining time.\n",
      "\t-0.236\t = Validation score   (r2)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 239.65s of the 359.66s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.0084\t = Validation score   (r2)\n",
      "\t70.5s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 166.51s of the 286.52s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.0078\t = Validation score   (r2)\n",
      "\t52.34s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 111.60s of the 231.61s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.004\t = Validation score   (r2)\n",
      "\t0.89s\t = Training   runtime\n",
      "\t0.26s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 110.38s of the 230.39s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.10%)\n",
      "\t0.0079\t = Validation score   (r2)\n",
      "\t50.44s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 57.47s of the 177.48s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.004\t = Validation score   (r2)\n",
      "\t0.9s\t = Training   runtime\n",
      "\t0.26s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 56.25s of the 176.26s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.0112\t = Validation score   (r2)\n",
      "\t107.0s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 359.93s of the 65.25s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetFastAI_BAG_L1': 0.727, 'LightGBMXT_BAG_L1': 0.273}\n",
      "\t0.0116\t = Validation score   (r2)\n",
      "\t0.17s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 106 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 65.02s of the 64.96s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.2637\t = Validation score   (r2)\n",
      "\t73.89s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 359.93s of the -12.83s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L2': 1.0}\n",
      "\t0.2637\t = Validation score   (r2)\n",
      "\t0.18s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 373.08s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 694.6 rows/s (300 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/regression/AutogluonModels/ag-20250522_222057\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250522_222716\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #53~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Jan 15 19:18:46 UTC 2\n",
      "CPU Count:          64\n",
      "Memory Avail:       365.78 GB / 503.54 GB (72.6%)\n",
      "Disk Space Avail:   33770.70 GB / 51214.59 GB (65.9%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ... Time limit = 360s\n",
      "AutoGluon will save models to \"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/regression/AutogluonModels/ag-20250522_222716\"\n",
      "Train Data Rows:    2400\n",
      "Train Data Columns: 6\n",
      "Label Column:       price\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    374560.88 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.97 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['name', 'item_description']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 296\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])          : 2 | ['item_condition_id', 'shipping']\n",
      "\t\t('object', [])       : 2 | ['category_name', 'brand_name']\n",
      "\t\t('object', ['text']) : 2 | ['name', 'item_description']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    :   2 | ['category_name', 'brand_name']\n",
      "\t\t('category', ['text_as_category'])  :   2 | ['name', 'item_description']\n",
      "\t\t('int', [])                         :   1 | ['item_condition_id']\n",
      "\t\t('int', ['binned', 'text_special']) :  41 | ['name.char_count', 'name.word_count', 'name.capital_ratio', 'name.lower_ratio', 'name.digit_ratio', ...]\n",
      "\t\t('int', ['bool'])                   :   1 | ['shipping']\n",
      "\t\t('int', ['text_ngram'])             : 293 | ['__nlp__.10', '__nlp__.100', '__nlp__.100 authentic', '__nlp__.11', '__nlp__.12', ...]\n",
      "\t6.0s = Fit runtime\n",
      "\t6 features in original data used to generate 340 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.47 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 6.1s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 235.87s of the 353.88s of remaining time.\n",
      "\t-0.1769\t = Validation score   (r2)\n",
      "\t0.06s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 235.60s of the 353.60s of remaining time.\n",
      "\t-0.1805\t = Validation score   (r2)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 235.34s of the 353.35s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.02%)\n",
      "\t0.1048\t = Validation score   (r2)\n",
      "\t65.26s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 166.20s of the 284.20s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.02%)\n",
      "\t0.094\t = Validation score   (r2)\n",
      "\t56.96s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 105.66s of the 223.66s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.0212\t = Validation score   (r2)\n",
      "\t12.65s\t = Training   runtime\n",
      "\t0.5s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 92.07s of the 210.08s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.18%)\n",
      "\t0.1157\t = Validation score   (r2)\n",
      "\t74.14s\t = Training   runtime\n",
      "\t0.27s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 14.24s of the 132.24s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.0173\t = Validation score   (r2)\n",
      "\t9.42s\t = Training   runtime\n",
      "\t0.52s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 3.84s of the 121.85s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\tTime limit exceeded... Skipping NeuralNetFastAI_BAG_L1.\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 353.90s of the 112.34s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.52, 'LightGBMXT_BAG_L1': 0.4, 'LightGBM_BAG_L1': 0.04, 'RandomForestMSE_BAG_L1': 0.04}\n",
      "\t0.1281\t = Validation score   (r2)\n",
      "\t0.16s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 106 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 112.15s of the 112.09s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.02%)\n",
      "\t0.1012\t = Validation score   (r2)\n",
      "\t56.41s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 53.05s of the 52.99s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.02%)\n",
      "\t0.1115\t = Validation score   (r2)\n",
      "\t56.09s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 353.90s of the -6.96s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.391, 'LightGBMXT_BAG_L1': 0.348, 'LightGBM_BAG_L2': 0.217, 'RandomForestMSE_BAG_L1': 0.043}\n",
      "\t0.1295\t = Validation score   (r2)\n",
      "\t0.16s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 367.17s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 438.3 rows/s (300 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/regression/AutogluonModels/ag-20250522_222716\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250522_223325\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #53~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Jan 15 19:18:46 UTC 2\n",
      "CPU Count:          64\n",
      "Memory Avail:       367.06 GB / 503.54 GB (72.9%)\n",
      "Disk Space Avail:   33770.55 GB / 51214.59 GB (65.9%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ... Time limit = 360s\n",
      "AutoGluon will save models to \"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/regression/AutogluonModels/ag-20250522_223325\"\n",
      "Train Data Rows:    2400\n",
      "Train Data Columns: 2\n",
      "Label Column:       price\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    375885.70 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.04 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', []) : 2 | ['item_condition_id', 'shipping']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('int', [])       : 1 | ['item_condition_id']\n",
      "\t\t('int', ['bool']) : 1 | ['shipping']\n",
      "\t0.0s = Fit runtime\n",
      "\t2 features in original data used to generate 2 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.02 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.06s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 239.90s of the 359.91s of remaining time.\n",
      "\t-0.0218\t = Validation score   (r2)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 239.81s of the 359.82s of remaining time.\n",
      "\t-0.0228\t = Validation score   (r2)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 239.71s of the 359.73s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.0061\t = Validation score   (r2)\n",
      "\t46.65s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 189.45s of the 309.47s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.0052\t = Validation score   (r2)\n",
      "\t42.58s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 143.50s of the 263.51s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t-0.0005\t = Validation score   (r2)\n",
      "\t0.86s\t = Training   runtime\n",
      "\t0.27s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 142.33s of the 262.34s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.10%)\n",
      "\t0.0058\t = Validation score   (r2)\n",
      "\t49.54s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 89.36s of the 209.38s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t-0.0005\t = Validation score   (r2)\n",
      "\t0.86s\t = Training   runtime\n",
      "\t0.28s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 88.19s of the 208.20s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.0125\t = Validation score   (r2)\n",
      "\t92.47s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 359.94s of the 111.71s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetFastAI_BAG_L1': 0.9, 'CatBoost_BAG_L1': 0.1}\n",
      "\t0.0126\t = Validation score   (r2)\n",
      "\t0.18s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 106 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 111.50s of the 111.44s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.1818\t = Validation score   (r2)\n",
      "\t81.79s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 26.00s of the 25.93s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.1787\t = Validation score   (r2)\n",
      "\t49.37s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 359.94s of the -27.32s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L2': 0.538, 'LightGBM_BAG_L2': 0.462}\n",
      "\t0.1906\t = Validation score   (r2)\n",
      "\t0.2s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 387.57s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 834.2 rows/s (300 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/regression/AutogluonModels/ag-20250522_223325\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250522_223954\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #53~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Jan 15 19:18:46 UTC 2\n",
      "CPU Count:          64\n",
      "Memory Avail:       364.74 GB / 503.54 GB (72.4%)\n",
      "Disk Space Avail:   33770.48 GB / 51214.59 GB (65.9%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ... Time limit = 360s\n",
      "AutoGluon will save models to \"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/regression/AutogluonModels/ag-20250522_223954\"\n",
      "Train Data Rows:    2400\n",
      "Train Data Columns: 6\n",
      "Label Column:       price\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    373484.01 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.99 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['name', 'item_description']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 277\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])          : 2 | ['item_condition_id', 'shipping']\n",
      "\t\t('object', [])       : 2 | ['category_name', 'brand_name']\n",
      "\t\t('object', ['text']) : 2 | ['name', 'item_description']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    :   2 | ['category_name', 'brand_name']\n",
      "\t\t('category', ['text_as_category'])  :   2 | ['name', 'item_description']\n",
      "\t\t('int', [])                         :   1 | ['item_condition_id']\n",
      "\t\t('int', ['binned', 'text_special']) :  43 | ['name.char_count', 'name.word_count', 'name.capital_ratio', 'name.lower_ratio', 'name.digit_ratio', ...]\n",
      "\t\t('int', ['bool'])                   :   1 | ['shipping']\n",
      "\t\t('int', ['text_ngram'])             : 275 | ['__nlp__.10', '__nlp__.100', '__nlp__.11', '__nlp__.12', '__nlp__.24', ...]\n",
      "\t5.8s = Fit runtime\n",
      "\t6 features in original data used to generate 324 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.39 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.85s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 236.04s of the 354.12s of remaining time.\n",
      "\t-0.1921\t = Validation score   (r2)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 235.75s of the 353.83s of remaining time.\n",
      "\t-0.1895\t = Validation score   (r2)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 235.49s of the 353.57s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.02%)\n",
      "\t0.0984\t = Validation score   (r2)\n",
      "\t59.17s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 172.64s of the 290.73s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.02%)\n",
      "\t0.0846\t = Validation score   (r2)\n",
      "\t57.87s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 111.16s of the 229.24s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t-0.0225\t = Validation score   (r2)\n",
      "\t12.06s\t = Training   runtime\n",
      "\t0.51s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 98.21s of the 216.29s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.18%)\n",
      "\t0.0948\t = Validation score   (r2)\n",
      "\t75.63s\t = Training   runtime\n",
      "\t0.24s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 18.87s of the 136.95s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t-0.0093\t = Validation score   (r2)\n",
      "\t9.02s\t = Training   runtime\n",
      "\t0.51s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 8.92s of the 127.01s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t-0.035\t = Validation score   (r2)\n",
      "\t74.56s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 354.15s of the 48.46s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.391, 'CatBoost_BAG_L1': 0.391, 'LightGBM_BAG_L1': 0.217}\n",
      "\t0.1105\t = Validation score   (r2)\n",
      "\t0.18s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 106 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 48.25s of the 48.19s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.02%)\n",
      "\t0.1088\t = Validation score   (r2)\n",
      "\t59.56s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 354.15s of the -15.64s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L2': 0.5, 'LightGBMXT_BAG_L1': 0.286, 'CatBoost_BAG_L1': 0.214}\n",
      "\t0.1173\t = Validation score   (r2)\n",
      "\t0.18s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 375.94s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 343.7 rows/s (300 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/regression/AutogluonModels/ag-20250522_223954\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250522_224612\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #53~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Jan 15 19:18:46 UTC 2\n",
      "CPU Count:          64\n",
      "Memory Avail:       364.85 GB / 503.54 GB (72.5%)\n",
      "Disk Space Avail:   33770.33 GB / 51214.59 GB (65.9%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ... Time limit = 360s\n",
      "AutoGluon will save models to \"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/regression/AutogluonModels/ag-20250522_224612\"\n",
      "Train Data Rows:    2400\n",
      "Train Data Columns: 2\n",
      "Label Column:       price\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    373619.17 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.04 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', []) : 2 | ['item_condition_id', 'shipping']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('int', [])       : 1 | ['item_condition_id']\n",
      "\t\t('int', ['bool']) : 1 | ['shipping']\n",
      "\t0.0s = Fit runtime\n",
      "\t2 features in original data used to generate 2 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.02 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.05s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 239.90s of the 359.92s of remaining time.\n",
      "\t-0.0373\t = Validation score   (r2)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 239.81s of the 359.83s of remaining time.\n",
      "\t-0.0416\t = Validation score   (r2)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 239.72s of the 359.73s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.0059\t = Validation score   (r2)\n",
      "\t43.2s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 192.89s of the 312.91s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.0054\t = Validation score   (r2)\n",
      "\t45.52s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 143.82s of the 263.83s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t-0.0\t = Validation score   (r2)\n",
      "\t0.84s\t = Training   runtime\n",
      "\t0.26s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 142.68s of the 262.69s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.10%)\n",
      "\t0.0053\t = Validation score   (r2)\n",
      "\t50.86s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 88.39s of the 208.40s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t-0.0\t = Validation score   (r2)\n",
      "\t0.93s\t = Training   runtime\n",
      "\t0.26s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 87.15s of the 207.16s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.01\t = Validation score   (r2)\n",
      "\t93.49s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 359.95s of the 109.96s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetFastAI_BAG_L1': 0.864, 'LightGBMXT_BAG_L1': 0.091, 'KNeighborsUnif_BAG_L1': 0.045}\n",
      "\t0.0102\t = Validation score   (r2)\n",
      "\t0.23s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 106 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 109.71s of the 109.63s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.2794\t = Validation score   (r2)\n",
      "\t65.43s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 40.84s of the 40.76s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.3024\t = Validation score   (r2)\n",
      "\t53.12s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 359.95s of the -16.39s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBM_BAG_L2': 0.7, 'LightGBMXT_BAG_L2': 0.3}\n",
      "\t0.3076\t = Validation score   (r2)\n",
      "\t0.19s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 376.63s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 783.6 rows/s (300 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/regression/AutogluonModels/ag-20250522_224612\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250522_225230\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #53~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Jan 15 19:18:46 UTC 2\n",
      "CPU Count:          64\n",
      "Memory Avail:       363.21 GB / 503.54 GB (72.1%)\n",
      "Disk Space Avail:   33770.28 GB / 51214.59 GB (65.9%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ... Time limit = 360s\n",
      "AutoGluon will save models to \"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/regression/AutogluonModels/ag-20250522_225230\"\n",
      "Train Data Rows:    2400\n",
      "Train Data Columns: 6\n",
      "Label Column:       price\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    371967.88 MB\n",
      "\tTrain Data (Original)  Memory Usage: 1.02 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['name', 'item_description']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 295\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])          : 2 | ['item_condition_id', 'shipping']\n",
      "\t\t('object', [])       : 2 | ['category_name', 'brand_name']\n",
      "\t\t('object', ['text']) : 2 | ['name', 'item_description']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    :   2 | ['category_name', 'brand_name']\n",
      "\t\t('category', ['text_as_category'])  :   2 | ['name', 'item_description']\n",
      "\t\t('int', [])                         :   1 | ['item_condition_id']\n",
      "\t\t('int', ['binned', 'text_special']) :  43 | ['name.char_count', 'name.word_count', 'name.capital_ratio', 'name.lower_ratio', 'name.digit_ratio', ...]\n",
      "\t\t('int', ['bool'])                   :   1 | ['shipping']\n",
      "\t\t('int', ['text_ngram'])             : 292 | ['__nlp__.10', '__nlp__.100', '__nlp__.11', '__nlp__.12', '__nlp__.24', ...]\n",
      "\t6.1s = Fit runtime\n",
      "\t6 features in original data used to generate 341 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.47 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 6.11s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 235.87s of the 353.87s of remaining time.\n",
      "\t-0.1675\t = Validation score   (r2)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 235.61s of the 353.61s of remaining time.\n",
      "\t-0.1667\t = Validation score   (r2)\n",
      "\t0.06s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 235.35s of the 353.35s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.02%)\n",
      "\t0.1134\t = Validation score   (r2)\n",
      "\t61.66s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 169.83s of the 287.83s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.02%)\n",
      "\t0.1317\t = Validation score   (r2)\n",
      "\t61.63s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 104.40s of the 222.41s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.0211\t = Validation score   (r2)\n",
      "\t12.75s\t = Training   runtime\n",
      "\t0.52s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 90.75s of the 208.75s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.19%)\n",
      "\t0.1282\t = Validation score   (r2)\n",
      "\t72.5s\t = Training   runtime\n",
      "\t0.27s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 14.33s of the 132.33s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.0076\t = Validation score   (r2)\n",
      "\t9.73s\t = Training   runtime\n",
      "\t0.52s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 3.63s of the 121.63s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\tTime limit exceeded... Skipping NeuralNetFastAI_BAG_L1.\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 353.89s of the 112.28s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBM_BAG_L1': 0.524, 'CatBoost_BAG_L1': 0.476}\n",
      "\t0.1501\t = Validation score   (r2)\n",
      "\t0.15s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 106 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 112.10s of the 112.04s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.02%)\n",
      "\t0.1299\t = Validation score   (r2)\n",
      "\t61.36s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 48.03s of the 47.97s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.02%)\n",
      "\t0.1266\t = Validation score   (r2)\n",
      "\t62.2s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 353.89s of the -18.36s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBM_BAG_L1': 0.467, 'CatBoost_BAG_L1': 0.4, 'LightGBMXT_BAG_L2': 0.133}\n",
      "\t0.1506\t = Validation score   (r2)\n",
      "\t0.17s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 378.6s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 443.5 rows/s (300 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/regression/AutogluonModels/ag-20250522_225230\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250522_225850\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #53~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Jan 15 19:18:46 UTC 2\n",
      "CPU Count:          64\n",
      "Memory Avail:       363.36 GB / 503.54 GB (72.2%)\n",
      "Disk Space Avail:   33770.14 GB / 51214.59 GB (65.9%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ... Time limit = 360s\n",
      "AutoGluon will save models to \"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/regression/AutogluonModels/ag-20250522_225850\"\n",
      "Train Data Rows:    2400\n",
      "Train Data Columns: 2\n",
      "Label Column:       price\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    372083.99 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.04 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', []) : 2 | ['item_condition_id', 'shipping']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('int', [])       : 1 | ['item_condition_id']\n",
      "\t\t('int', ['bool']) : 1 | ['shipping']\n",
      "\t0.0s = Fit runtime\n",
      "\t2 features in original data used to generate 2 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.02 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.06s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 239.90s of the 359.92s of remaining time.\n",
      "\t-0.0451\t = Validation score   (r2)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 239.80s of the 359.82s of remaining time.\n",
      "\t-0.0464\t = Validation score   (r2)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 239.71s of the 359.73s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.011\t = Validation score   (r2)\n",
      "\t50.05s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 186.24s of the 306.25s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.0098\t = Validation score   (r2)\n",
      "\t45.21s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 137.56s of the 257.57s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.0046\t = Validation score   (r2)\n",
      "\t0.84s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 136.42s of the 256.44s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.10%)\n",
      "\t0.0101\t = Validation score   (r2)\n",
      "\t50.63s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 82.36s of the 202.38s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.0047\t = Validation score   (r2)\n",
      "\t0.87s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 81.19s of the 201.21s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.0174\t = Validation score   (r2)\n",
      "\t95.47s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 359.94s of the 101.74s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetFastAI_BAG_L1': 1.0}\n",
      "\t0.0174\t = Validation score   (r2)\n",
      "\t0.17s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 106 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 101.54s of the 101.48s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.3635\t = Validation score   (r2)\n",
      "\t99.33s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 359.94s of the -1.87s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L2': 1.0}\n",
      "\t0.3635\t = Validation score   (r2)\n",
      "\t0.2s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 362.11s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 727.7 rows/s (300 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/regression/AutogluonModels/ag-20250522_225850\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250522_230453\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #53~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Jan 15 19:18:46 UTC 2\n",
      "CPU Count:          64\n",
      "Memory Avail:       400.45 GB / 503.54 GB (79.5%)\n",
      "Disk Space Avail:   33770.09 GB / 51214.59 GB (65.9%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ... Time limit = 360s\n",
      "AutoGluon will save models to \"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/regression/AutogluonModels/ag-20250522_230453\"\n",
      "Train Data Rows:    2400\n",
      "Train Data Columns: 6\n",
      "Label Column:       price\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    410082.89 MB\n",
      "\tTrain Data (Original)  Memory Usage: 1.01 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['name', 'item_description']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 300\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])          : 2 | ['item_condition_id', 'shipping']\n",
      "\t\t('object', [])       : 2 | ['category_name', 'brand_name']\n",
      "\t\t('object', ['text']) : 2 | ['name', 'item_description']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    :   2 | ['category_name', 'brand_name']\n",
      "\t\t('category', ['text_as_category'])  :   2 | ['name', 'item_description']\n",
      "\t\t('int', [])                         :   1 | ['item_condition_id']\n",
      "\t\t('int', ['binned', 'text_special']) :  43 | ['name.char_count', 'name.word_count', 'name.capital_ratio', 'name.lower_ratio', 'name.digit_ratio', ...]\n",
      "\t\t('int', ['bool'])                   :   1 | ['shipping']\n",
      "\t\t('int', ['text_ngram'])             : 296 | ['__nlp__.10', '__nlp__.100', '__nlp__.11', '__nlp__.12', '__nlp__.24', ...]\n",
      "\t7.3s = Fit runtime\n",
      "\t6 features in original data used to generate 345 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.49 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 7.37s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 235.03s of the 352.61s of remaining time.\n",
      "\t-0.1714\t = Validation score   (r2)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 234.72s of the 352.30s of remaining time.\n",
      "\t-0.175\t = Validation score   (r2)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 234.44s of the 352.02s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.02%)\n",
      "\t0.1079\t = Validation score   (r2)\n",
      "\t60.25s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 170.45s of the 288.03s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.02%)\n",
      "\t0.1022\t = Validation score   (r2)\n",
      "\t59.39s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 107.34s of the 224.92s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t-0.016\t = Validation score   (r2)\n",
      "\t12.9s\t = Training   runtime\n",
      "\t0.53s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 93.52s of the 211.10s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.18%)\n",
      "\t0.1011\t = Validation score   (r2)\n",
      "\t71.54s\t = Training   runtime\n",
      "\t0.27s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 18.35s of the 135.93s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.0167\t = Validation score   (r2)\n",
      "\t9.63s\t = Training   runtime\n",
      "\t0.55s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 7.75s of the 125.33s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\tTime limit exceeded... Skipping NeuralNetFastAI_BAG_L1.\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 352.63s of the 115.37s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBM_BAG_L1': 0.35, 'LightGBMXT_BAG_L1': 0.3, 'CatBoost_BAG_L1': 0.3, 'RandomForestMSE_BAG_L1': 0.05}\n",
      "\t0.1224\t = Validation score   (r2)\n",
      "\t0.16s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 106 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 115.18s of the 115.12s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.02%)\n",
      "\t0.1359\t = Validation score   (r2)\n",
      "\t76.12s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 36.32s of the 36.25s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.02%)\n",
      "\t0.1178\t = Validation score   (r2)\n",
      "\t56.94s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 352.63s of the -24.60s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L2': 0.652, 'LightGBM_BAG_L2': 0.261, 'RandomForestMSE_BAG_L1': 0.043, 'CatBoost_BAG_L1': 0.043}\n",
      "\t0.1414\t = Validation score   (r2)\n",
      "\t0.16s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 384.82s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 374.5 rows/s (300 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/regression/AutogluonModels/ag-20250522_230453\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250522_231120\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #53~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Jan 15 19:18:46 UTC 2\n",
      "CPU Count:          64\n",
      "Memory Avail:       366.44 GB / 503.54 GB (72.8%)\n",
      "Disk Space Avail:   33769.92 GB / 51214.59 GB (65.9%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ... Time limit = 360s\n",
      "AutoGluon will save models to \"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/regression/AutogluonModels/ag-20250522_231120\"\n",
      "Train Data Rows:    2400\n",
      "Train Data Columns: 2\n",
      "Label Column:       price\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    375210.36 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.04 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', []) : 2 | ['item_condition_id', 'shipping']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('int', [])       : 1 | ['item_condition_id']\n",
      "\t\t('int', ['bool']) : 1 | ['shipping']\n",
      "\t0.0s = Fit runtime\n",
      "\t2 features in original data used to generate 2 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.02 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.06s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'r2'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 108 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 239.90s of the 359.91s of remaining time.\n",
      "\t-0.1411\t = Validation score   (r2)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 239.80s of the 359.81s of remaining time.\n",
      "\t-0.1422\t = Validation score   (r2)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 239.71s of the 359.72s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.0068\t = Validation score   (r2)\n",
      "\t55.05s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 181.22s of the 301.23s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.006\t = Validation score   (r2)\n",
      "\t45.29s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE_BAG_L1 ... Training model for up to 132.46s of the 252.47s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.0009\t = Validation score   (r2)\n",
      "\t0.87s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 131.29s of the 251.31s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.10%)\n",
      "\t0.0049\t = Validation score   (r2)\n",
      "\t45.97s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ... Training model for up to 81.61s of the 201.62s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.001\t = Validation score   (r2)\n",
      "\t0.85s\t = Training   runtime\n",
      "\t0.26s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 80.46s of the 200.47s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.0128\t = Validation score   (r2)\n",
      "\t95.77s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 359.94s of the 100.89s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetFastAI_BAG_L1': 0.842, 'LightGBMXT_BAG_L1': 0.105, 'LightGBM_BAG_L1': 0.053}\n",
      "\t0.013\t = Validation score   (r2)\n",
      "\t0.17s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 106 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 100.69s of the 100.63s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.3282\t = Validation score   (r2)\n",
      "\t93.79s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 359.94s of the 2.62s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L2': 1.0}\n",
      "\t0.3282\t = Validation score   (r2)\n",
      "\t0.18s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 357.6s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 717.1 rows/s (300 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/regression/AutogluonModels/ag-20250522_231120\")\n"
     ]
    }
   ],
   "source": [
    "from baseline_eval import evaluate_baseline, plot_model_performance_summary\n",
    "results = evaluate_baseline(\n",
    "    df=loaded_df,\n",
    "    model='AGTabular',\n",
    "    df_name=dataset_config['dataset_name'],\n",
    "    label_col= dataset_config['target'],\n",
    "    task_type=dataset_config['task'],\n",
    "    textual_cols=textual_cols,\n",
    "    k_folds=5,\n",
    "    seed=0,\n",
    "    max_samples=3000,\n",
    "    output_path=f\"../../baseline_results/{dataset_config['task']}/{dataset_config['dataset_name']}.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "038c2cec-891f-4773-abc7-e8c0a4fdd4d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving plot to ../../baseline_results/plots/reg/score\n",
      "Saving plot to ../../baseline_results/plots/reg/loss\n",
      "Saving plot to ../../baseline_results/plots/reg/roc_auc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score':                                     mean       std\n",
       " model                                             \n",
       " AutoGluon_Tabular_without_text -0.086784  0.095004\n",
       " AutoGluon_Tabular_with_text     0.133704  0.037342,\n",
       " 'loss':                                      mean       std\n",
       " model                                              \n",
       " AutoGluon_Tabular_with_text     31.406266  6.703562\n",
       " AutoGluon_Tabular_without_text  35.079118  6.984875,\n",
       " 'roc_auc':                                 mean  std\n",
       " model                                    \n",
       " AutoGluon_Tabular_with_text      NaN  NaN\n",
       " AutoGluon_Tabular_without_text   NaN  NaN}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs = pd.read_csv(f\"../../baseline_results/{dataset_config['task']}/{dataset_config['dataset_name']}.csv\")\n",
    "plot_model_performance_summary(name=dataset_config['dataset_name'],task=dataset_config['task'], df=rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19748cd-da3b-4307-a2b0-c44279a4a1a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
