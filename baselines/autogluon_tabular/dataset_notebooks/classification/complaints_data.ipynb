{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0200d09",
   "metadata": {},
   "source": [
    "### Let's start with downloading the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4d0c4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "# to reach the dataloader_functions module\n",
    "module_path = os.path.abspath(os.path.join( \"..\"))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from dataloader_functions.download_data import download_raw_data\n",
    "current_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b8103e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO update this section per dataset\n",
    "dataset_config = {\n",
    "    'dataset_name': 'consumer_complaints',\n",
    "    'source': 'kaggle', # ['kaggle', 'local', 'openml', 'hf']\n",
    "    'remote_path': 'selener/consumer-complaint-database',\n",
    "    'files': ['rows.csv'],\n",
    "    'rename_files': ['complaints_data.csv'],\n",
    "    'task': 'clf', # ['reg', 'clf']\n",
    "    'target': 'Company response to consumer',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4336bfef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36mInfo:\u001b[0m Dataset already downloaded in \u001b[1;35m/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/../../datasets_files/raw/classification/consumer_complaints\u001b[0m.\n",
      "Downloaded consumer_complaints dataset to /home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/../../datasets_files/raw/classification/consumer_complaints\n"
     ]
    }
   ],
   "source": [
    "if dataset_config['task'] == 'clf':\n",
    "    dataset_subfolder = os.path.join('raw', 'classification', dataset_config['dataset_name']) \n",
    "elif dataset_config['task'] == 'reg':\n",
    "    dataset_subfolder = os.path.join('raw', 'regression', dataset_config['dataset_name'])\n",
    "else:\n",
    "    raise ValueError(f\"Unknown task: {dataset_config['task']}\")\n",
    "\n",
    "# this path needs to be modified based on the location of the notebook\n",
    "download_path = os.path.join(current_dir, '..', '..', 'datasets_files', dataset_subfolder)\n",
    "\n",
    "if download_raw_data(\n",
    "    dataset_config=dataset_config,\n",
    "    download_path=download_path,\n",
    "    force_download=False,\n",
    "    remove_unlisted=True,\n",
    ") is not None:\n",
    "    print(f\"Downloaded {dataset_config['dataset_name']} dataset to {download_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d886637",
   "metadata": {},
   "source": [
    "### Now we need to preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48bcaebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader_functions.load_and_pp_raw_data import _drop_empty_columns, _drop_single_value_columns\n",
    "from dataloader_functions.utils.data_2_df import read_any_to_df\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "current_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f204a3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: we will downsample the dataset to ~24k samples\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the path\n",
    "current_dir = os.getcwd()\n",
    "download_path = os.path.join(current_dir, '..', '..', 'datasets_files', dataset_subfolder)\n",
    "                                                                                                                    \n",
    "# File paths\n",
    "train_path = os.path.join(download_path, dataset_config['rename_files'][0])\n",
    "\n",
    "# Load safely, skipping bad lines\n",
    "train_df = pd.read_csv(train_path, on_bad_lines='skip', engine='python')\n",
    "\n",
    "# Downsample with fallback if not enough rows\n",
    "train_sample_size = min(len(train_df), 24000)\n",
    "\n",
    "train_df = train_df.sample(n=train_sample_size, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Save back (overwrite the originals)\n",
    "train_df.to_csv(train_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0861820c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading /home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/../../datasets_files/raw/classification/consumer_complaints/complaints_data.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date received</th>\n",
       "      <th>Product</th>\n",
       "      <th>Sub-product</th>\n",
       "      <th>Issue</th>\n",
       "      <th>Sub-issue</th>\n",
       "      <th>Consumer complaint narrative</th>\n",
       "      <th>Company public response</th>\n",
       "      <th>Company</th>\n",
       "      <th>State</th>\n",
       "      <th>ZIP code</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Consumer consent provided?</th>\n",
       "      <th>Submitted via</th>\n",
       "      <th>Date sent to company</th>\n",
       "      <th>Company response to consumer</th>\n",
       "      <th>Timely response?</th>\n",
       "      <th>Consumer disputed?</th>\n",
       "      <th>Complaint ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/31/2019</td>\n",
       "      <td>Debt collection</td>\n",
       "      <td>I do not know</td>\n",
       "      <td>Attempts to collect debt not owed</td>\n",
       "      <td>Debt is not yours</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Company has responded to the consumer and the ...</td>\n",
       "      <td>WAKEFIELD &amp; ASSOCIATES, INC.</td>\n",
       "      <td>GA</td>\n",
       "      <td>30014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Consent not provided</td>\n",
       "      <td>Web</td>\n",
       "      <td>01/31/2019</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3139423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>08/04/2014</td>\n",
       "      <td>Mortgage</td>\n",
       "      <td>Other mortgage</td>\n",
       "      <td>Loan modification,collection,foreclosure</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Specialized Loan Servicing LLC</td>\n",
       "      <td>VA</td>\n",
       "      <td>22042</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Referral</td>\n",
       "      <td>08/06/2014</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>967089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>09/09/2014</td>\n",
       "      <td>Mortgage</td>\n",
       "      <td>Other mortgage</td>\n",
       "      <td>Loan servicing, payments, escrow account</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NATIONSTAR MORTGAGE</td>\n",
       "      <td>DC</td>\n",
       "      <td>20003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Postal mail</td>\n",
       "      <td>09/12/2014</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>1020500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Date received          Product     Sub-product  \\\n",
       "0    01/31/2019  Debt collection   I do not know   \n",
       "1    08/04/2014         Mortgage  Other mortgage   \n",
       "2    09/09/2014         Mortgage  Other mortgage   \n",
       "\n",
       "                                      Issue          Sub-issue  \\\n",
       "0         Attempts to collect debt not owed  Debt is not yours   \n",
       "1  Loan modification,collection,foreclosure                NaN   \n",
       "2  Loan servicing, payments, escrow account                NaN   \n",
       "\n",
       "  Consumer complaint narrative  \\\n",
       "0                          NaN   \n",
       "1                          NaN   \n",
       "2                          NaN   \n",
       "\n",
       "                             Company public response  \\\n",
       "0  Company has responded to the consumer and the ...   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "\n",
       "                          Company State ZIP code Tags  \\\n",
       "0    WAKEFIELD & ASSOCIATES, INC.    GA    30014  NaN   \n",
       "1  Specialized Loan Servicing LLC    VA    22042  NaN   \n",
       "2             NATIONSTAR MORTGAGE    DC    20003  NaN   \n",
       "\n",
       "  Consumer consent provided? Submitted via Date sent to company  \\\n",
       "0       Consent not provided           Web           01/31/2019   \n",
       "1                        NaN      Referral           08/06/2014   \n",
       "2                        NaN   Postal mail           09/12/2014   \n",
       "\n",
       "  Company response to consumer Timely response? Consumer disputed?  \\\n",
       "0      Closed with explanation              Yes                NaN   \n",
       "1      Closed with explanation              Yes                Yes   \n",
       "2      Closed with explanation              Yes                 No   \n",
       "\n",
       "   Complaint ID  \n",
       "0       3139423  \n",
       "1        967089  \n",
       "2       1020500  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dataset_files_df = []\n",
    "\n",
    "if dataset_config['rename_files'] is None or len(dataset_config['rename_files']) == 0:\n",
    "    dataset_config['rename_files'] = dataset_config['files']\n",
    "\n",
    "for file in dataset_config['rename_files']:\n",
    "\n",
    "    file_location = os.path.join(download_path, file)\n",
    "\n",
    "    print(f\"Loading {file_location}\")\n",
    "\n",
    "    dataset_files_df.append(read_any_to_df(file_location))\n",
    "\n",
    "# example of the loaded df data:\n",
    "pd.set_option('display.max_columns', None)\n",
    "dataset_files_df[0].head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d099b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped: Index(['Consumer complaint narrative', 'Company public response', 'Tags'], dtype='object')\n",
      "Dataframe shape before/afrer cleaning: (24000, 18) / (24000, 15)\n"
     ]
    }
   ],
   "source": [
    "## Run some basic data cleaning\n",
    "\n",
    "dataset_files_gen_cleaned = []\n",
    "missing_ratio_threshold = 0.5 # TODO the threshold can be changed\n",
    "\n",
    "for df_file in dataset_files_df:\n",
    "    df_size = df_file.shape\n",
    "    # 1. Drop columns with more than 50% missing values\n",
    "    df_file = _drop_empty_columns(df_file, threshold=missing_ratio_threshold)   \n",
    "    # 2. Drop columns with only one unique value\n",
    "    df_file = _drop_single_value_columns(df_file)\n",
    "    # 3. remove duplicates\n",
    "    df_file = df_file.drop_duplicates()\n",
    "    # 4. remove rows with missing target values\n",
    "    df_file = df_file[df_file[dataset_config['target']].notna()]\n",
    "    # 5. drop unnamed columns\n",
    "    df_file = df_file.loc[:, ~df_file.columns.str.contains('^Unnamed')]\n",
    "\n",
    "    dataset_files_gen_cleaned.append(df_file)\n",
    "\n",
    "    print(f\"Dataframe shape before/afrer cleaning: {df_size} / {df_file.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0a2a11a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe shape before/afrer by-hand cleaning: (24000, 15) / (24000, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date received</th>\n",
       "      <th>Product</th>\n",
       "      <th>Sub-product</th>\n",
       "      <th>Issue</th>\n",
       "      <th>Sub-issue</th>\n",
       "      <th>Company</th>\n",
       "      <th>State</th>\n",
       "      <th>ZIP code</th>\n",
       "      <th>Consumer consent provided?</th>\n",
       "      <th>Submitted via</th>\n",
       "      <th>Company response to consumer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01/31/2019</td>\n",
       "      <td>Debt collection</td>\n",
       "      <td>I do not know</td>\n",
       "      <td>Attempts to collect debt not owed</td>\n",
       "      <td>Debt is not yours</td>\n",
       "      <td>WAKEFIELD &amp; ASSOCIATES, INC.</td>\n",
       "      <td>GA</td>\n",
       "      <td>30014</td>\n",
       "      <td>Consent not provided</td>\n",
       "      <td>Web</td>\n",
       "      <td>Closed with explanation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>08/04/2014</td>\n",
       "      <td>Mortgage</td>\n",
       "      <td>Other mortgage</td>\n",
       "      <td>Loan modification,collection,foreclosure</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Specialized Loan Servicing LLC</td>\n",
       "      <td>VA</td>\n",
       "      <td>22042</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Referral</td>\n",
       "      <td>Closed with explanation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>09/09/2014</td>\n",
       "      <td>Mortgage</td>\n",
       "      <td>Other mortgage</td>\n",
       "      <td>Loan servicing, payments, escrow account</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NATIONSTAR MORTGAGE</td>\n",
       "      <td>DC</td>\n",
       "      <td>20003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Postal mail</td>\n",
       "      <td>Closed with explanation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Date received          Product     Sub-product  \\\n",
       "0    01/31/2019  Debt collection   I do not know   \n",
       "1    08/04/2014         Mortgage  Other mortgage   \n",
       "2    09/09/2014         Mortgage  Other mortgage   \n",
       "\n",
       "                                      Issue          Sub-issue  \\\n",
       "0         Attempts to collect debt not owed  Debt is not yours   \n",
       "1  Loan modification,collection,foreclosure                NaN   \n",
       "2  Loan servicing, payments, escrow account                NaN   \n",
       "\n",
       "                          Company State ZIP code Consumer consent provided?  \\\n",
       "0    WAKEFIELD & ASSOCIATES, INC.    GA    30014       Consent not provided   \n",
       "1  Specialized Loan Servicing LLC    VA    22042                        NaN   \n",
       "2             NATIONSTAR MORTGAGE    DC    20003                        NaN   \n",
       "\n",
       "  Submitted via Company response to consumer  \n",
       "0           Web      Closed with explanation  \n",
       "1      Referral      Closed with explanation  \n",
       "2   Postal mail      Closed with explanation  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## TODO: Now run custom data cleaning -> remove non-essential columns\n",
    "\n",
    "cols_to_drop = ['Complaint ID','Date sent to company','Timely response?','Consumer disputed?']\n",
    "\n",
    "dataset_files_cleaned = []\n",
    "\n",
    "# assuming for multiple files we still want to drop the same columns\n",
    "for df_file in dataset_files_gen_cleaned:\n",
    "    df_size = df_file.shape\n",
    "    for col in cols_to_drop:\n",
    "        if col in df_file.columns:\n",
    "            df_file.drop(col, axis=1, inplace=True)\n",
    "        else:\n",
    "            print(f\"Column {col} not found in dataframe\")\n",
    "\n",
    "    dataset_files_cleaned.append(df_file)    \n",
    "    print(f\"Dataframe shape before/afrer by-hand cleaning: {df_size} / {df_file.shape}\")\n",
    "\n",
    "dataset_files_cleaned[0].head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d90a681b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe shape before custom cleaning: (24000, 11)\n",
      "Dataframe shape after custom cleaning: (23273, 11)\n"
     ]
    }
   ],
   "source": [
    "# TODO: some custom data cleaning\n",
    "import copy \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from  dataloader_functions.load_and_pp_raw_data import clean_zip_code\n",
    "\n",
    "tmp_df = copy.deepcopy(dataset_files_cleaned)\n",
    "dataset_files_by_hand_cleaned = []\n",
    "\n",
    "for df_file in dataset_files_cleaned:\n",
    "    print(f\"Dataframe shape before custom cleaning: {df_file.shape}\")\n",
    "    \n",
    "    # 1. Drop non-essential target categories & make safe copy\n",
    "    to_drop = ['Closed', 'In progress', 'Untimely response', 'Closed with relief']\n",
    "    df_file = df_file[~df_file[dataset_config['target']].isin(to_drop)].copy()\n",
    "\n",
    "    # 2. Convert 'Date received' to timestamp (handle NaT safely)\n",
    "    df_file['Date received'] = pd.to_datetime(df_file['Date received'], format='%m/%d/%Y', errors='coerce')\n",
    "    df_file['Date received'] = df_file['Date received'].apply(lambda x: x.timestamp() if pd.notnull(x) else float('nan'))\n",
    "\n",
    "    # 3. Clean 'ZIP code' column to remove non-numerical characters\n",
    "    if 'ZIP code' in df_file.columns:\n",
    "        df_file['ZIP code'] = clean_zip_code(df_file['ZIP code'])\n",
    "\n",
    "    print(f\"Dataframe shape after custom cleaning: {df_file.shape}\")\n",
    "\n",
    "    dataset_files_by_hand_cleaned.append(df_file)\n",
    "\n",
    "# reset the dataframe list to the version before custom cleaning\n",
    "dataset_files_cleaned = tmp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581b17e1",
   "metadata": {},
   "source": [
    "### Now it is time to visualize our changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1500c210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date received</th>\n",
       "      <th>Product</th>\n",
       "      <th>Sub-product</th>\n",
       "      <th>Issue</th>\n",
       "      <th>Sub-issue</th>\n",
       "      <th>Company</th>\n",
       "      <th>State</th>\n",
       "      <th>ZIP code</th>\n",
       "      <th>Consumer consent provided?</th>\n",
       "      <th>Submitted via</th>\n",
       "      <th>Company response to consumer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.548893e+09</td>\n",
       "      <td>Debt collection</td>\n",
       "      <td>I do not know</td>\n",
       "      <td>Attempts to collect debt not owed</td>\n",
       "      <td>Debt is not yours</td>\n",
       "      <td>WAKEFIELD &amp; ASSOCIATES, INC.</td>\n",
       "      <td>GA</td>\n",
       "      <td>300</td>\n",
       "      <td>Consent not provided</td>\n",
       "      <td>Web</td>\n",
       "      <td>Closed with explanation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.407110e+09</td>\n",
       "      <td>Mortgage</td>\n",
       "      <td>Other mortgage</td>\n",
       "      <td>Loan modification,collection,foreclosure</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Specialized Loan Servicing LLC</td>\n",
       "      <td>VA</td>\n",
       "      <td>220</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Referral</td>\n",
       "      <td>Closed with explanation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.410221e+09</td>\n",
       "      <td>Mortgage</td>\n",
       "      <td>Other mortgage</td>\n",
       "      <td>Loan servicing, payments, escrow account</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NATIONSTAR MORTGAGE</td>\n",
       "      <td>DC</td>\n",
       "      <td>200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Postal mail</td>\n",
       "      <td>Closed with explanation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Date received          Product     Sub-product  \\\n",
       "0   1.548893e+09  Debt collection   I do not know   \n",
       "1   1.407110e+09         Mortgage  Other mortgage   \n",
       "2   1.410221e+09         Mortgage  Other mortgage   \n",
       "\n",
       "                                      Issue          Sub-issue  \\\n",
       "0         Attempts to collect debt not owed  Debt is not yours   \n",
       "1  Loan modification,collection,foreclosure                NaN   \n",
       "2  Loan servicing, payments, escrow account                NaN   \n",
       "\n",
       "                          Company State  ZIP code Consumer consent provided?  \\\n",
       "0    WAKEFIELD & ASSOCIATES, INC.    GA       300       Consent not provided   \n",
       "1  Specialized Loan Servicing LLC    VA       220                        NaN   \n",
       "2             NATIONSTAR MORTGAGE    DC       200                        NaN   \n",
       "\n",
       "  Submitted via Company response to consumer  \n",
       "0           Web      Closed with explanation  \n",
       "1      Referral      Closed with explanation  \n",
       "2   Postal mail      Closed with explanation  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "dataset_files_by_hand_cleaned[0].head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f71269d",
   "metadata": {},
   "source": [
    "Let's figure out which columns should be viewed as categorical / numerical / textual\n",
    "\n",
    "we can start with a simple heuristic:\n",
    "1. numerical is everything which\n",
    "    - keeps most of its character length after non-numeral strip\n",
    "    - has about the same number of unique values after the strip\n",
    "    + for the purpose of keeping \"semantic information\", hand picked columns can be viewed also as non-numerical, that is not the default benchmark approach though\n",
    "\n",
    "2. categorical is everthing non numerical, which can be then divided into N (where N << Num instances) unique categories\n",
    "\n",
    "3. textual is everything else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "436f9ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Threshold for categorical vs textual: 50\n",
      "Numerical columns (2): ['Date received', 'ZIP code']\n",
      "Categorical columns (4): ['Product', 'Consumer consent provided?', 'Submitted via', 'Company response to consumer']\n",
      "Textual columns (5): ['Sub-product', 'Issue', 'Sub-issue', 'Company', 'State']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def is_mostly_numeric(series, length_threshold=0.5, unique_threshold=0.8):\n",
    "    \"\"\"Check if column is mostly numeric after stripping non-numeric chars.\"\"\"\n",
    "    stripped = series.astype(str).str.replace(r\"[^\\d\\.\\-]\", \"\", regex=True)\n",
    "    \n",
    "    original_len = series.astype(str).str.len().replace(0, 1)  # avoid div by zero\n",
    "    length_ratio = (stripped.str.len() / original_len).mean()\n",
    "\n",
    "    unique_ratio = stripped.nunique(dropna=False) / max(series.nunique(dropna=False), 1)\n",
    "\n",
    "    return length_ratio > length_threshold and unique_ratio > unique_threshold\n",
    "\n",
    "def classify_columns(df, unique_ratio_threshold=None, explicit_nunique_threshold=None):\n",
    "    \"\"\"\n",
    "    Classify dataframe columns into numerical, categorical, textual.\n",
    "    - Binary categorical (2 unique values) is considered categorical.\n",
    "    \"\"\"\n",
    "    n_rows = len(df)\n",
    "\n",
    "    # Determine threshold for categorical vs textual\n",
    "    if explicit_nunique_threshold is not None:\n",
    "        nunique_threshold = explicit_nunique_threshold\n",
    "    elif unique_ratio_threshold is not None:\n",
    "        nunique_threshold = int(unique_ratio_threshold * n_rows)\n",
    "    else:\n",
    "        nunique_threshold = int(0.05 * n_rows)  # default 5%\n",
    "\n",
    "    nunique_threshold = max(10, nunique_threshold)  # safeguard\n",
    "    print(f\"Threshold for categorical vs textual: {nunique_threshold}\")\n",
    "\n",
    "    numerical_cols = []\n",
    "    categorical_cols = []\n",
    "    textual_cols = []\n",
    "\n",
    "    for col in df.columns:\n",
    "        series = df[col]\n",
    "        nunique = series.nunique(dropna=False)\n",
    "\n",
    "        if pd.api.types.is_numeric_dtype(series):\n",
    "            if nunique <= nunique_threshold:\n",
    "                categorical_cols.append(col)\n",
    "            else:\n",
    "                numerical_cols.append(col)\n",
    "        \n",
    "        elif pd.api.types.is_string_dtype(series) or pd.api.types.is_object_dtype(series):\n",
    "            if is_mostly_numeric(series):\n",
    "                numerical_cols.append(col)\n",
    "            else:\n",
    "                if nunique <= nunique_threshold:\n",
    "                    categorical_cols.append(col)\n",
    "                else:\n",
    "                    textual_cols.append(col)\n",
    "        else:\n",
    "            print(f\"⚠️ Unhandled column type: '{col}' (dtype={series.dtype})\")\n",
    "\n",
    "    print(f\"Numerical columns ({len(numerical_cols)}): {numerical_cols}\")\n",
    "    print(f\"Categorical columns ({len(categorical_cols)}): {categorical_cols}\")\n",
    "    print(f\"Textual columns ({len(textual_cols)}): {textual_cols}\")\n",
    "\n",
    "    return numerical_cols, categorical_cols, textual_cols\n",
    "\n",
    "# Example usage:\n",
    "for df_file in dataset_files_by_hand_cleaned:\n",
    "    # Ratio-based (5% of rows)\n",
    "    # umerical_cols, categorical_cols, textual_cols = classify_columns(df_file, unique_ratio_threshold=0.05)\n",
    "    print(\"\")\n",
    "    # OR explicit value (e.g., anything <= 50 is categorical)\n",
    "    numerical_cols, categorical_cols, textual_cols = classify_columns(df_file, explicit_nunique_threshold=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6499589b",
   "metadata": {},
   "source": [
    "Now let's just try to visualize the kept features, their example values, and their cat/num/text allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afffbdb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column Name</th>\n",
       "      <th>Example Value</th>\n",
       "      <th>Type</th>\n",
       "      <th># Categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Date received</td>\n",
       "      <td>1548892800.0</td>\n",
       "      <td>numerical</td>\n",
       "      <td>~ 2589 ~</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Product</td>\n",
       "      <td>Debt collection</td>\n",
       "      <td>categorical</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sub-product</td>\n",
       "      <td>I do not know</td>\n",
       "      <td>textual</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Issue</td>\n",
       "      <td>Attempts to collect debt not owed</td>\n",
       "      <td>textual</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sub-issue</td>\n",
       "      <td>Debt is not yours</td>\n",
       "      <td>textual</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Company</td>\n",
       "      <td>WAKEFIELD &amp; ASSOCIATES, INC.</td>\n",
       "      <td>textual</td>\n",
       "      <td>1318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>State</td>\n",
       "      <td>GA</td>\n",
       "      <td>textual</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ZIP code</td>\n",
       "      <td>300</td>\n",
       "      <td>numerical</td>\n",
       "      <td>~ 841 ~</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Consumer consent provided?</td>\n",
       "      <td>Consent not provided</td>\n",
       "      <td>categorical</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Submitted via</td>\n",
       "      <td>Web</td>\n",
       "      <td>categorical</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Company response to consumer</td>\n",
       "      <td>Closed with explanation</td>\n",
       "      <td>categorical</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Column Name                      Example Value  \\\n",
       "0                  Date received                       1548892800.0   \n",
       "1                        Product                    Debt collection   \n",
       "2                    Sub-product                      I do not know   \n",
       "3                          Issue  Attempts to collect debt not owed   \n",
       "4                      Sub-issue                  Debt is not yours   \n",
       "5                        Company       WAKEFIELD & ASSOCIATES, INC.   \n",
       "6                          State                                 GA   \n",
       "7                       ZIP code                                300   \n",
       "8     Consumer consent provided?               Consent not provided   \n",
       "9                  Submitted via                                Web   \n",
       "10  Company response to consumer            Closed with explanation   \n",
       "\n",
       "           Type # Categories  \n",
       "0     numerical     ~ 2589 ~  \n",
       "1   categorical           18  \n",
       "2       textual           71  \n",
       "3       textual          154  \n",
       "4       textual          201  \n",
       "5       textual         1318  \n",
       "6       textual           60  \n",
       "7     numerical      ~ 841 ~  \n",
       "8   categorical            4  \n",
       "9   categorical            6  \n",
       "10  categorical            4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary = []\n",
    "for col in df_file.columns:\n",
    "    if col in categorical_cols:\n",
    "        col_type = \"categorical\"\n",
    "        num_categories = df_file[col].nunique(dropna=True)\n",
    "        num_categories_display = int(num_categories)\n",
    "    elif col in textual_cols:\n",
    "        col_type = \"textual\"\n",
    "        num_categories = df_file[col].nunique(dropna=True)\n",
    "        num_categories_display = int(num_categories)\n",
    "    elif col in numerical_cols:\n",
    "        col_type = \"numerical\"\n",
    "        num_categories = df_file[col].nunique(dropna=True)\n",
    "        num_categories_display = '~ ' + str(num_categories) + ' ~'\n",
    "    else:\n",
    "        col_type = \"unknown\"\n",
    "        num_categories_display = '--'\n",
    "\n",
    "    example = df_file[col].dropna().iloc[0] if df_file[col].dropna().size > 0 else None\n",
    "    summary.append({\n",
    "        'Column Name': col,\n",
    "        'Example Value': str(example),\n",
    "        'Type': col_type,\n",
    "        '# Categories': num_categories_display\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary)\n",
    "\n",
    "# TODO: by hand changes of the type and category count -> e.g. for 'Location':\n",
    "#    # Post-processing: override the type and category count for 'Location'\n",
    "#    # summary_df.loc[summary_df['Column Name'] == 'Location', 'Type'] = 'textual'\n",
    "#    # num_categories = df_file['Location'].nunique(dropna=True)\n",
    "#    # summary_df.loc[summary_df['Column Name'] == 'Location', '# Categories'] = int(num_categories)\n",
    "\n",
    "display(summary_df)  # Or print(summary_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ef8954",
   "metadata": {},
   "source": [
    "### Saving the processed data and loading it back up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2fe5eab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/../../datasets_files/raw/classification/consumer_complaints/complaints_data_processed.pkl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Handle rename_files fallback\n",
    "if dataset_config['rename_files'] is None or len(dataset_config['rename_files']) == 0:\n",
    "    dataset_config['rename_files'] = dataset_config['files']\n",
    "\n",
    "for i, df_file in enumerate(dataset_files_by_hand_cleaned):\n",
    "    df_with_meta = df_file.copy()\n",
    "\n",
    "    # Get corresponding file name\n",
    "    file_name = dataset_config['rename_files'][i]\n",
    "    file_base = os.path.splitext(file_name)[0]\n",
    "\n",
    "    # Try assigning multi-index header from summary\n",
    "    try:\n",
    "        df_with_meta.columns = pd.MultiIndex.from_frame(\n",
    "            summary_df[['Column Name', 'Type', '# Categories']]\n",
    "        )\n",
    "        local_summary = summary_df.copy()\n",
    "    except ValueError:\n",
    "        local_summary = summary_df.copy()\n",
    "        if dataset_config['target'] in local_summary['Column Name'].values:\n",
    "            local_summary = local_summary[local_summary['Column Name'] != dataset_config['target']]\n",
    "            df_with_meta.columns = pd.MultiIndex.from_frame(\n",
    "                local_summary[['Column Name', 'Type', '# Categories']]\n",
    "            )\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "    # Construct and save everything together\n",
    "    output_filename = f\"{file_base}_processed.pkl\"\n",
    "    output_path = os.path.join(download_path, output_filename)\n",
    "\n",
    "    save_bundle = {\n",
    "        'data': df_with_meta,\n",
    "        'summary': local_summary,\n",
    "        'config': dataset_config\n",
    "    }\n",
    "\n",
    "    pd.to_pickle(save_bundle, output_path)\n",
    "    print(f\"Saved: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c7bcd87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== COMPLAINTS_DATA ===\n",
      "Loaded config keys: ['dataset_name', 'source', 'remote_path', 'files', 'rename_files', 'task', 'target']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column Name</th>\n",
       "      <th>Type</th>\n",
       "      <th># Categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Date received</td>\n",
       "      <td>numerical</td>\n",
       "      <td>~ 2589 ~</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Product</td>\n",
       "      <td>categorical</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sub-product</td>\n",
       "      <td>textual</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Issue</td>\n",
       "      <td>textual</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sub-issue</td>\n",
       "      <td>textual</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Company</td>\n",
       "      <td>textual</td>\n",
       "      <td>1318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>State</td>\n",
       "      <td>textual</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ZIP code</td>\n",
       "      <td>numerical</td>\n",
       "      <td>~ 841 ~</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Consumer consent provided?</td>\n",
       "      <td>categorical</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Submitted via</td>\n",
       "      <td>categorical</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Company response to consumer</td>\n",
       "      <td>categorical</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Column Name         Type # Categories\n",
       "0                  Date received    numerical     ~ 2589 ~\n",
       "1                        Product  categorical           18\n",
       "2                    Sub-product      textual           71\n",
       "3                          Issue      textual          154\n",
       "4                      Sub-issue      textual          201\n",
       "5                        Company      textual         1318\n",
       "6                          State      textual           60\n",
       "7                       ZIP code    numerical      ~ 841 ~\n",
       "8     Consumer consent provided?  categorical            4\n",
       "9                  Submitted via  categorical            6\n",
       "10  Company response to consumer  categorical            4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Column Name</th>\n",
       "      <th>Date received</th>\n",
       "      <th>Product</th>\n",
       "      <th>Sub-product</th>\n",
       "      <th>Issue</th>\n",
       "      <th>Sub-issue</th>\n",
       "      <th>Company</th>\n",
       "      <th>State</th>\n",
       "      <th>ZIP code</th>\n",
       "      <th>Consumer consent provided?</th>\n",
       "      <th>Submitted via</th>\n",
       "      <th>Company response to consumer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.548893e+09</td>\n",
       "      <td>Debt collection</td>\n",
       "      <td>I do not know</td>\n",
       "      <td>Attempts to collect debt not owed</td>\n",
       "      <td>Debt is not yours</td>\n",
       "      <td>WAKEFIELD &amp; ASSOCIATES, INC.</td>\n",
       "      <td>GA</td>\n",
       "      <td>300</td>\n",
       "      <td>Consent not provided</td>\n",
       "      <td>Web</td>\n",
       "      <td>Closed with explanation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.407110e+09</td>\n",
       "      <td>Mortgage</td>\n",
       "      <td>Other mortgage</td>\n",
       "      <td>Loan modification,collection,foreclosure</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Specialized Loan Servicing LLC</td>\n",
       "      <td>VA</td>\n",
       "      <td>220</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Referral</td>\n",
       "      <td>Closed with explanation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.410221e+09</td>\n",
       "      <td>Mortgage</td>\n",
       "      <td>Other mortgage</td>\n",
       "      <td>Loan servicing, payments, escrow account</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NATIONSTAR MORTGAGE</td>\n",
       "      <td>DC</td>\n",
       "      <td>200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Postal mail</td>\n",
       "      <td>Closed with explanation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Column Name  Date received          Product     Sub-product  \\\n",
       "0             1.548893e+09  Debt collection   I do not know   \n",
       "1             1.407110e+09         Mortgage  Other mortgage   \n",
       "2             1.410221e+09         Mortgage  Other mortgage   \n",
       "\n",
       "Column Name                                     Issue          Sub-issue  \\\n",
       "0                   Attempts to collect debt not owed  Debt is not yours   \n",
       "1            Loan modification,collection,foreclosure                NaN   \n",
       "2            Loan servicing, payments, escrow account                NaN   \n",
       "\n",
       "Column Name                         Company State  ZIP code  \\\n",
       "0              WAKEFIELD & ASSOCIATES, INC.    GA       300   \n",
       "1            Specialized Loan Servicing LLC    VA       220   \n",
       "2                       NATIONSTAR MORTGAGE    DC       200   \n",
       "\n",
       "Column Name Consumer consent provided? Submitted via  \\\n",
       "0                 Consent not provided           Web   \n",
       "1                                  NaN      Referral   \n",
       "2                                  NaN   Postal mail   \n",
       "\n",
       "Column Name Company response to consumer  \n",
       "0                Closed with explanation  \n",
       "1                Closed with explanation  \n",
       "2                Closed with explanation  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Loop through processed files in rename_files\n",
    "for file_name in dataset_config['rename_files']:\n",
    "    # Remove .csv or .tsv extension to get the base name\n",
    "    file_base = os.path.splitext(file_name)[0]\n",
    "    processed_filename = f\"{file_base}_processed.pkl\"\n",
    "    processed_path = os.path.join(download_path, processed_filename)\n",
    "\n",
    "    # Load the bundled dictionary (data + summary + config)\n",
    "    bundle = pd.read_pickle(processed_path)\n",
    "\n",
    "    # Extract components\n",
    "    loaded_df = bundle['data']\n",
    "    summary_df = bundle['summary']\n",
    "    loaded_config = bundle['config']\n",
    "\n",
    "    print(f\"\\n=== {file_base.upper()} ===\")\n",
    "    print(f\"Loaded config keys: {list(loaded_config.keys())}\")\n",
    "\n",
    "    # Show metadata\n",
    "    meta_df = pd.DataFrame(loaded_df.columns.tolist(), columns=['Column Name', 'Type', '# Categories'])\n",
    "    display(meta_df)\n",
    "\n",
    "    # Flatten for modeling\n",
    "    loaded_df.columns = loaded_df.columns.get_level_values(0)\n",
    "    display(loaded_df.head(n=3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e76bb54",
   "metadata": {},
   "source": [
    "### Bonus insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd886839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique classes in 'Company response to consumer': ['Closed with explanation', 'Closed with non-monetary relief', 'Closed with monetary relief', 'Closed without relief']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, \"Distribution of 'Company response to consumer' target\")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show data imbalance:\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the distribution of player_class with counts\n",
    "value_counts = loaded_df[dataset_config['target']].value_counts()\n",
    "\n",
    "# print the unique classes\n",
    "print(f\"Unique classes in '{dataset_config['target']}': {value_counts.index.tolist()}\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "value_counts.plot(kind='bar')\n",
    "\n",
    "# Add counts as text labels on top of bars\n",
    "for i, count in enumerate(value_counts):\n",
    "    plt.text(i, count, str(count), ha='center', va='bottom')\n",
    "\n",
    "plt.title(f\"Distribution of '{dataset_config['target']}' target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "161be88f-08be-4ee9-80e2-6dc9780afc0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250521_170609\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #53~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Jan 15 19:18:46 UTC 2\n",
      "CPU Count:          64\n",
      "Memory Avail:       333.40 GB / 503.54 GB (66.2%)\n",
      "Disk Space Avail:   33801.88 GB / 51214.59 GB (66.0%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[WRAPPER] Running stratified downsampling mode for task: clf\n",
      "\u001b[1;36mInfo:\u001b[0m \n",
      "[INFO] Downsampling dataframe: consumer_complaints (original rows: 23273)\n",
      "\u001b[1;33mInfo:\u001b[0m Trying to sample ~750 rows per class (total=3000)\n",
      "\u001b[1;32mInfo:\u001b[0m [INFO] Class Closed without relief has only 346 instances. Keeping all.\n",
      "\u001b[1;36mInfo:\u001b[0m Final downsampled dataset has 3000 rows. Per class counts: [Closed with explanation: 1097, Closed with non-monetary relief: 796, Closed with monetary relief: 761, Closed without relief: 346]\n",
      "\n",
      "Downsampled 3000 rows for consumer_complaints dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Beginning AutoGluon training ... Time limit = 360s\n",
      "AutoGluon will save models to \"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250521_170609\"\n",
      "Train Data Rows:    2400\n",
      "Train Data Columns: 10\n",
      "Label Column:       Company response to consumer\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 4\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "Warning: dtype Int64 is not recognized as a valid dtype by numpy! AutoGluon may incorrectly handle this feature...\n",
      "Cannot interpret 'Int64Dtype()' as a data type\n",
      "\tAvailable Memory:                    341395.14 MB\n",
      "\tTrain Data (Original)  Memory Usage: 1.32 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "Warning: dtype Int64 is not recognized as a valid dtype by numpy! AutoGluon may incorrectly handle this feature...\n",
      "Cannot interpret 'Int64Dtype()' as a data type\n",
      "Warning: dtype Int64 is not recognized as a valid dtype by numpy! AutoGluon may incorrectly handle this feature...\n",
      "Cannot interpret 'Int64Dtype()' as a data type\n",
      "Warning: dtype Int64 is not recognized as a valid dtype by numpy! AutoGluon may incorrectly handle this feature...\n",
      "Cannot interpret 'Int64Dtype()' as a data type\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "Warning: dtype Int64 is not recognized as a valid dtype by numpy! AutoGluon may incorrectly handle this feature...\n",
      "Cannot interpret 'Int64Dtype()' as a data type\n",
      "Warning: dtype Int64 is not recognized as a valid dtype by numpy! AutoGluon may incorrectly handle this feature...\n",
      "Cannot interpret 'Int64Dtype()' as a data type\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "Warning: dtype Int64 is not recognized as a valid dtype by numpy! AutoGluon may incorrectly handle this feature...\n",
      "Cannot interpret 'Int64Dtype()' as a data type\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['Sub-product', 'Issue', 'Sub-issue', 'Company']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 324\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['ZIP code']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('Int64', []) : 1 | ['ZIP code']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])        : 1 | ['Date received']\n",
      "\t\t('object', [])       : 4 | ['Product', 'State', 'Consumer consent provided?', 'Submitted via']\n",
      "\t\t('object', ['text']) : 4 | ['Sub-product', 'Issue', 'Sub-issue', 'Company']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    :   4 | ['Product', 'State', 'Consumer consent provided?', 'Submitted via']\n",
      "\t\t('category', ['text_as_category'])  :   4 | ['Sub-product', 'Issue', 'Sub-issue', 'Company']\n",
      "\t\t('float', [])                       :   1 | ['Date received']\n",
      "\t\t('int', ['binned', 'text_special']) :  38 | ['Sub-product.char_count', 'Sub-product.word_count', 'Sub-product.capital_ratio', 'Sub-product.lower_ratio', 'Sub-product.special_ratio', ...]\n",
      "\t\t('int', ['text_ngram'])             : 187 | ['__nlp__.about', '__nlp__.account', '__nlp__.account managing', '__nlp__.account opening', '__nlp__.account opening closing', ...]\n",
      "\t43.9s = Fit runtime\n",
      "\t9 features in original data used to generate 234 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.98 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 43.94s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 110 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 210.65s of the 316.03s of remaining time.\n",
      "\t0.4675\t = Validation score   (accuracy)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t0.31s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 210.19s of the 315.57s of remaining time.\n",
      "\t0.4338\t = Validation score   (accuracy)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 209.96s of the 315.35s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.6396\t = Validation score   (accuracy)\n",
      "\t113.21s\t = Training   runtime\n",
      "\t0.31s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 75.80s of the 181.18s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.02%)\n",
      "\t0.6558\t = Validation score   (accuracy)\n",
      "\t88.22s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 316.06s of the 89.35s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.562, 'NeuralNetFastAI_BAG_L1': 0.25, 'KNeighborsUnif_BAG_L1': 0.188}\n",
      "\t0.6858\t = Validation score   (accuracy)\n",
      "\t0.14s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 108 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 89.16s of the 89.11s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.68\t = Validation score   (accuracy)\n",
      "\t103.46s\t = Training   runtime\n",
      "\t0.33s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 316.06s of the -17.62s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.5, 'NeuralNetFastAI_BAG_L2': 0.375, 'KNeighborsUnif_BAG_L1': 0.062, 'NeuralNetFastAI_BAG_L1': 0.062}\n",
      "\t0.6946\t = Validation score   (accuracy)\n",
      "\t0.16s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 377.86s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 370.8 rows/s (300 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250521_170609\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250521_171236\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #53~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Jan 15 19:18:46 UTC 2\n",
      "CPU Count:          64\n",
      "Memory Avail:       332.09 GB / 503.54 GB (66.0%)\n",
      "Disk Space Avail:   33801.79 GB / 51214.59 GB (66.0%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ... Time limit = 360s\n",
      "AutoGluon will save models to \"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250521_171236\"\n",
      "Train Data Rows:    2400\n",
      "Train Data Columns: 5\n",
      "Label Column:       Company response to consumer\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 4\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "Warning: dtype Int64 is not recognized as a valid dtype by numpy! AutoGluon may incorrectly handle this feature...\n",
      "Cannot interpret 'Int64Dtype()' as a data type\n",
      "\tAvailable Memory:                    340059.01 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.49 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "Warning: dtype Int64 is not recognized as a valid dtype by numpy! AutoGluon may incorrectly handle this feature...\n",
      "Cannot interpret 'Int64Dtype()' as a data type\n",
      "Warning: dtype Int64 is not recognized as a valid dtype by numpy! AutoGluon may incorrectly handle this feature...\n",
      "Cannot interpret 'Int64Dtype()' as a data type\n",
      "Warning: dtype Int64 is not recognized as a valid dtype by numpy! AutoGluon may incorrectly handle this feature...\n",
      "Cannot interpret 'Int64Dtype()' as a data type\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "Warning: dtype Int64 is not recognized as a valid dtype by numpy! AutoGluon may incorrectly handle this feature...\n",
      "Cannot interpret 'Int64Dtype()' as a data type\n",
      "Warning: dtype Int64 is not recognized as a valid dtype by numpy! AutoGluon may incorrectly handle this feature...\n",
      "Cannot interpret 'Int64Dtype()' as a data type\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "Warning: dtype Int64 is not recognized as a valid dtype by numpy! AutoGluon may incorrectly handle this feature...\n",
      "Cannot interpret 'Int64Dtype()' as a data type\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['ZIP code']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('Int64', []) : 1 | ['ZIP code']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 1 | ['Date received']\n",
      "\t\t('object', []) : 3 | ['Product', 'Consumer consent provided?', 'Submitted via']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) : 3 | ['Product', 'Consumer consent provided?', 'Submitted via']\n",
      "\t\t('float', [])    : 1 | ['Date received']\n",
      "\t0.1s = Fit runtime\n",
      "\t4 features in original data used to generate 4 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.16s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 110 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 239.83s of the 359.81s of remaining time.\n",
      "\t0.4679\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 239.76s of the 359.74s of remaining time.\n",
      "\t0.4375\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 239.70s of the 359.68s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.6475\t = Validation score   (accuracy)\n",
      "\t110.45s\t = Training   runtime\n",
      "\t0.29s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 126.39s of the 246.37s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.6488\t = Validation score   (accuracy)\n",
      "\t76.99s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 46.34s of the 166.33s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.6438\t = Validation score   (accuracy)\n",
      "\t61.87s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 359.84s of the 101.16s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\n",
      "\t0.6488\t = Validation score   (accuracy)\n",
      "\t0.16s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 108 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 100.98s of the 100.93s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.6512\t = Validation score   (accuracy)\n",
      "\t104.78s\t = Training   runtime\n",
      "\t0.32s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 359.84s of the -7.13s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetFastAI_BAG_L2': 0.667, 'LightGBMXT_BAG_L1': 0.2, 'NeuralNetFastAI_BAG_L1': 0.067, 'LightGBM_BAG_L1': 0.067}\n",
      "\t0.6625\t = Validation score   (accuracy)\n",
      "\t0.19s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 367.36s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 361.5 rows/s (300 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250521_171236\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250521_171847\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #53~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Jan 15 19:18:46 UTC 2\n",
      "CPU Count:          64\n",
      "Memory Avail:       332.22 GB / 503.54 GB (66.0%)\n",
      "Disk Space Avail:   33801.60 GB / 51214.59 GB (66.0%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ... Time limit = 360s\n",
      "AutoGluon will save models to \"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250521_171847\"\n",
      "Train Data Rows:    2400\n",
      "Train Data Columns: 10\n",
      "Label Column:       Company response to consumer\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 4\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "Warning: dtype Int64 is not recognized as a valid dtype by numpy! AutoGluon may incorrectly handle this feature...\n",
      "Cannot interpret 'Int64Dtype()' as a data type\n",
      "\tAvailable Memory:                    340157.77 MB\n",
      "\tTrain Data (Original)  Memory Usage: 1.31 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "Warning: dtype Int64 is not recognized as a valid dtype by numpy! AutoGluon may incorrectly handle this feature...\n",
      "Cannot interpret 'Int64Dtype()' as a data type\n",
      "Warning: dtype Int64 is not recognized as a valid dtype by numpy! AutoGluon may incorrectly handle this feature...\n",
      "Cannot interpret 'Int64Dtype()' as a data type\n",
      "Warning: dtype Int64 is not recognized as a valid dtype by numpy! AutoGluon may incorrectly handle this feature...\n",
      "Cannot interpret 'Int64Dtype()' as a data type\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "Warning: dtype Int64 is not recognized as a valid dtype by numpy! AutoGluon may incorrectly handle this feature...\n",
      "Cannot interpret 'Int64Dtype()' as a data type\n",
      "Warning: dtype Int64 is not recognized as a valid dtype by numpy! AutoGluon may incorrectly handle this feature...\n",
      "Cannot interpret 'Int64Dtype()' as a data type\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "Warning: dtype Int64 is not recognized as a valid dtype by numpy! AutoGluon may incorrectly handle this feature...\n",
      "Cannot interpret 'Int64Dtype()' as a data type\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['Issue', 'Sub-issue', 'Company']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 231\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['ZIP code']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('Int64', []) : 1 | ['ZIP code']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])        : 1 | ['Date received']\n",
      "\t\t('object', [])       : 5 | ['Product', 'Sub-product', 'State', 'Consumer consent provided?', 'Submitted via']\n",
      "\t\t('object', ['text']) : 3 | ['Issue', 'Sub-issue', 'Company']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    :   5 | ['Product', 'Sub-product', 'State', 'Consumer consent provided?', 'Submitted via']\n",
      "\t\t('category', ['text_as_category'])  :   3 | ['Issue', 'Sub-issue', 'Company']\n",
      "\t\t('float', [])                       :   1 | ['Date received']\n",
      "\t\t('int', ['binned', 'text_special']) :  27 | ['Issue.char_count', 'Issue.word_count', 'Issue.capital_ratio', 'Issue.lower_ratio', 'Issue.special_ratio', ...]\n",
      "\t\t('int', ['text_ngram'])             : 145 | ['__nlp__.about', '__nlp__.account', '__nlp__.account status', '__nlp__.action', '__nlp__.america', ...]\n",
      "\t15.3s = Fit runtime\n",
      "\t9 features in original data used to generate 181 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.77 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 15.38s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 110 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 229.69s of the 344.60s of remaining time.\n",
      "\t0.4537\t = Validation score   (accuracy)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 229.44s of the 344.34s of remaining time.\n",
      "\t0.4537\t = Validation score   (accuracy)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 229.27s of the 344.18s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.6471\t = Validation score   (accuracy)\n",
      "\t110.19s\t = Training   runtime\n",
      "\t0.35s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 116.20s of the 231.11s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.01%)\n",
      "\t0.6937\t = Validation score   (accuracy)\n",
      "\t120.08s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 344.62s of the 106.89s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\n",
      "\t0.6937\t = Validation score   (accuracy)\n",
      "\t0.13s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 108 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 106.74s of the 106.69s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.6908\t = Validation score   (accuracy)\n",
      "\t108.24s\t = Training   runtime\n",
      "\t0.28s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 344.62s of the -5.59s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.8, 'NeuralNetFastAI_BAG_L2': 0.16, 'KNeighborsUnif_BAG_L1': 0.04}\n",
      "\t0.695\t = Validation score   (accuracy)\n",
      "\t0.16s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 365.82s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 389.9 rows/s (300 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250521_171847\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250521_172456\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #53~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Jan 15 19:18:46 UTC 2\n",
      "CPU Count:          64\n",
      "Memory Avail:       336.68 GB / 503.54 GB (66.9%)\n",
      "Disk Space Avail:   33801.53 GB / 51214.59 GB (66.0%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ... Time limit = 360s\n",
      "AutoGluon will save models to \"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250521_172456\"\n",
      "Train Data Rows:    2400\n",
      "Train Data Columns: 5\n",
      "Label Column:       Company response to consumer\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 4\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "Warning: dtype Int64 is not recognized as a valid dtype by numpy! AutoGluon may incorrectly handle this feature...\n",
      "Cannot interpret 'Int64Dtype()' as a data type\n",
      "\tAvailable Memory:                    344751.33 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.49 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "Warning: dtype Int64 is not recognized as a valid dtype by numpy! AutoGluon may incorrectly handle this feature...\n",
      "Cannot interpret 'Int64Dtype()' as a data type\n",
      "Warning: dtype Int64 is not recognized as a valid dtype by numpy! AutoGluon may incorrectly handle this feature...\n",
      "Cannot interpret 'Int64Dtype()' as a data type\n",
      "Warning: dtype Int64 is not recognized as a valid dtype by numpy! AutoGluon may incorrectly handle this feature...\n",
      "Cannot interpret 'Int64Dtype()' as a data type\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "Warning: dtype Int64 is not recognized as a valid dtype by numpy! AutoGluon may incorrectly handle this feature...\n",
      "Cannot interpret 'Int64Dtype()' as a data type\n",
      "Warning: dtype Int64 is not recognized as a valid dtype by numpy! AutoGluon may incorrectly handle this feature...\n",
      "Cannot interpret 'Int64Dtype()' as a data type\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "Warning: dtype Int64 is not recognized as a valid dtype by numpy! AutoGluon may incorrectly handle this feature...\n",
      "Cannot interpret 'Int64Dtype()' as a data type\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['ZIP code']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('Int64', []) : 1 | ['ZIP code']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 1 | ['Date received']\n",
      "\t\t('object', []) : 3 | ['Product', 'Consumer consent provided?', 'Submitted via']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) : 3 | ['Product', 'Consumer consent provided?', 'Submitted via']\n",
      "\t\t('float', [])    : 1 | ['Date received']\n",
      "\t0.1s = Fit runtime\n",
      "\t4 features in original data used to generate 4 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.14s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 110 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 239.84s of the 359.82s of remaining time.\n",
      "\t0.4442\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 239.79s of the 359.76s of remaining time.\n",
      "\t0.4583\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 239.73s of the 359.71s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.6375\t = Validation score   (accuracy)\n",
      "\t109.77s\t = Training   runtime\n",
      "\t0.26s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 126.07s of the 246.04s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.6383\t = Validation score   (accuracy)\n",
      "\t68.61s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 53.78s of the 173.76s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.6408\t = Validation score   (accuracy)\n",
      "\t72.7s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 359.86s of the 97.07s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetFastAI_BAG_L1': 0.5, 'LightGBM_BAG_L1': 0.4, 'KNeighborsDist_BAG_L1': 0.05, 'LightGBMXT_BAG_L1': 0.05}\n",
      "\t0.6446\t = Validation score   (accuracy)\n",
      "\t0.16s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 108 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 96.88s of the 96.81s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.6475\t = Validation score   (accuracy)\n",
      "\t106.43s\t = Training   runtime\n",
      "\t0.31s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 359.86s of the -13.86s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetFastAI_BAG_L2': 0.625, 'KNeighborsUnif_BAG_L1': 0.125, 'NeuralNetFastAI_BAG_L1': 0.125, 'LightGBMXT_BAG_L1': 0.125}\n",
      "\t0.65\t = Validation score   (accuracy)\n",
      "\t0.18s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 374.1s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 402.9 rows/s (300 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250521_172456\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250521_173114\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #53~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Jan 15 19:18:46 UTC 2\n",
      "CPU Count:          64\n",
      "Memory Avail:       331.66 GB / 503.54 GB (65.9%)\n",
      "Disk Space Avail:   33800.06 GB / 51214.59 GB (66.0%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ... Time limit = 360s\n",
      "AutoGluon will save models to \"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250521_173114\"\n",
      "Train Data Rows:    2400\n",
      "Train Data Columns: 10\n",
      "Label Column:       Company response to consumer\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 4\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "Warning: dtype Int64 is not recognized as a valid dtype by numpy! AutoGluon may incorrectly handle this feature...\n",
      "Cannot interpret 'Int64Dtype()' as a data type\n",
      "\tAvailable Memory:                    339606.72 MB\n",
      "\tTrain Data (Original)  Memory Usage: 1.31 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "Warning: dtype Int64 is not recognized as a valid dtype by numpy! AutoGluon may incorrectly handle this feature...\n",
      "Cannot interpret 'Int64Dtype()' as a data type\n",
      "Warning: dtype Int64 is not recognized as a valid dtype by numpy! AutoGluon may incorrectly handle this feature...\n",
      "Cannot interpret 'Int64Dtype()' as a data type\n",
      "Warning: dtype Int64 is not recognized as a valid dtype by numpy! AutoGluon may incorrectly handle this feature...\n",
      "Cannot interpret 'Int64Dtype()' as a data type\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "Warning: dtype Int64 is not recognized as a valid dtype by numpy! AutoGluon may incorrectly handle this feature...\n",
      "Cannot interpret 'Int64Dtype()' as a data type\n",
      "Warning: dtype Int64 is not recognized as a valid dtype by numpy! AutoGluon may incorrectly handle this feature...\n",
      "Cannot interpret 'Int64Dtype()' as a data type\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "Warning: dtype Int64 is not recognized as a valid dtype by numpy! AutoGluon may incorrectly handle this feature...\n",
      "Cannot interpret 'Int64Dtype()' as a data type\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['Issue', 'Sub-issue', 'Company']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 228\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['ZIP code']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('Int64', []) : 1 | ['ZIP code']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])        : 1 | ['Date received']\n",
      "\t\t('object', [])       : 5 | ['Product', 'Sub-product', 'State', 'Consumer consent provided?', 'Submitted via']\n",
      "\t\t('object', ['text']) : 3 | ['Issue', 'Sub-issue', 'Company']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    :   5 | ['Product', 'Sub-product', 'State', 'Consumer consent provided?', 'Submitted via']\n",
      "\t\t('category', ['text_as_category'])  :   3 | ['Issue', 'Sub-issue', 'Company']\n",
      "\t\t('float', [])                       :   1 | ['Date received']\n",
      "\t\t('int', ['binned', 'text_special']) :  25 | ['Issue.char_count', 'Issue.word_count', 'Issue.capital_ratio', 'Issue.lower_ratio', 'Issue.special_ratio', ...]\n",
      "\t\t('int', ['text_ngram'])             : 140 | ['__nlp__.about', '__nlp__.account', '__nlp__.action', '__nlp__.america', '__nlp__.america national', ...]\n",
      "\t27.2s = Fit runtime\n",
      "\t9 features in original data used to generate 174 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.74 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 27.29s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 110 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 221.75s of the 332.68s of remaining time.\n",
      "\t0.4579\t = Validation score   (accuracy)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 221.53s of the 332.47s of remaining time.\n",
      "\t0.4313\t = Validation score   (accuracy)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 221.28s of the 332.21s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.6379\t = Validation score   (accuracy)\n",
      "\t108.08s\t = Training   runtime\n",
      "\t0.31s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 109.15s of the 220.09s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.01%)\n",
      "\t0.6904\t = Validation score   (accuracy)\n",
      "\t118.87s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 332.71s of the 96.91s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\n",
      "\t0.6904\t = Validation score   (accuracy)\n",
      "\t0.12s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 108 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 96.76s of the 96.70s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.6767\t = Validation score   (accuracy)\n",
      "\t106.86s\t = Training   runtime\n",
      "\t0.31s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 332.71s of the -14.32s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.692, 'NeuralNetFastAI_BAG_L2': 0.231, 'NeuralNetFastAI_BAG_L1': 0.077}\n",
      "\t0.6967\t = Validation score   (accuracy)\n",
      "\t0.16s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 374.54s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 383.5 rows/s (300 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250521_173114\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250521_173733\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #53~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Jan 15 19:18:46 UTC 2\n",
      "CPU Count:          64\n",
      "Memory Avail:       327.40 GB / 503.54 GB (65.0%)\n",
      "Disk Space Avail:   33799.93 GB / 51214.59 GB (66.0%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ... Time limit = 360s\n",
      "AutoGluon will save models to \"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250521_173733\"\n",
      "Train Data Rows:    2400\n",
      "Train Data Columns: 5\n",
      "Label Column:       Company response to consumer\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 4\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "Warning: dtype Int64 is not recognized as a valid dtype by numpy! AutoGluon may incorrectly handle this feature...\n",
      "Cannot interpret 'Int64Dtype()' as a data type\n",
      "\tAvailable Memory:                    335224.01 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.49 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "Warning: dtype Int64 is not recognized as a valid dtype by numpy! AutoGluon may incorrectly handle this feature...\n",
      "Cannot interpret 'Int64Dtype()' as a data type\n",
      "Warning: dtype Int64 is not recognized as a valid dtype by numpy! AutoGluon may incorrectly handle this feature...\n",
      "Cannot interpret 'Int64Dtype()' as a data type\n",
      "Warning: dtype Int64 is not recognized as a valid dtype by numpy! AutoGluon may incorrectly handle this feature...\n",
      "Cannot interpret 'Int64Dtype()' as a data type\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "Warning: dtype Int64 is not recognized as a valid dtype by numpy! AutoGluon may incorrectly handle this feature...\n",
      "Cannot interpret 'Int64Dtype()' as a data type\n",
      "Warning: dtype Int64 is not recognized as a valid dtype by numpy! AutoGluon may incorrectly handle this feature...\n",
      "Cannot interpret 'Int64Dtype()' as a data type\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "Warning: dtype Int64 is not recognized as a valid dtype by numpy! AutoGluon may incorrectly handle this feature...\n",
      "Cannot interpret 'Int64Dtype()' as a data type\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['ZIP code']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('Int64', []) : 1 | ['ZIP code']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 1 | ['Date received']\n",
      "\t\t('object', []) : 3 | ['Product', 'Consumer consent provided?', 'Submitted via']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) : 3 | ['Product', 'Consumer consent provided?', 'Submitted via']\n",
      "\t\t('float', [])    : 1 | ['Date received']\n",
      "\t0.1s = Fit runtime\n",
      "\t4 features in original data used to generate 4 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.15s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 110 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 239.84s of the 359.83s of remaining time.\n",
      "\t0.4554\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 239.78s of the 359.77s of remaining time.\n",
      "\t0.44\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 239.73s of the 359.71s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.6408\t = Validation score   (accuracy)\n",
      "\t109.6s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 126.22s of the 246.21s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.6383\t = Validation score   (accuracy)\n",
      "\t63.72s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 58.71s of the 178.69s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.6404\t = Validation score   (accuracy)\n",
      "\t77.11s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 359.85s of the 97.58s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetFastAI_BAG_L1': 0.923, 'LightGBM_BAG_L1': 0.077}\n",
      "\t0.6429\t = Validation score   (accuracy)\n",
      "\t0.15s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 108 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 97.40s of the 97.35s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.6417\t = Validation score   (accuracy)\n",
      "\t104.67s\t = Training   runtime\n",
      "\t0.3s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 359.85s of the -11.40s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetFastAI_BAG_L2': 0.545, 'LightGBMXT_BAG_L1': 0.273, 'NeuralNetFastAI_BAG_L1': 0.091, 'LightGBM_BAG_L1': 0.091}\n",
      "\t0.6475\t = Validation score   (accuracy)\n",
      "\t0.18s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 371.64s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 406.6 rows/s (300 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250521_173733\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250521_174348\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #53~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Jan 15 19:18:46 UTC 2\n",
      "CPU Count:          64\n",
      "Memory Avail:       331.49 GB / 503.54 GB (65.8%)\n",
      "Disk Space Avail:   33799.82 GB / 51214.59 GB (66.0%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ... Time limit = 360s\n",
      "AutoGluon will save models to \"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250521_174348\"\n",
      "Train Data Rows:    2400\n",
      "Train Data Columns: 10\n",
      "Label Column:       Company response to consumer\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 4\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "Warning: dtype Int64 is not recognized as a valid dtype by numpy! AutoGluon may incorrectly handle this feature...\n",
      "Cannot interpret 'Int64Dtype()' as a data type\n",
      "\tAvailable Memory:                    339409.50 MB\n",
      "\tTrain Data (Original)  Memory Usage: 1.31 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "Warning: dtype Int64 is not recognized as a valid dtype by numpy! AutoGluon may incorrectly handle this feature...\n",
      "Cannot interpret 'Int64Dtype()' as a data type\n",
      "Warning: dtype Int64 is not recognized as a valid dtype by numpy! AutoGluon may incorrectly handle this feature...\n",
      "Cannot interpret 'Int64Dtype()' as a data type\n",
      "Warning: dtype Int64 is not recognized as a valid dtype by numpy! AutoGluon may incorrectly handle this feature...\n",
      "Cannot interpret 'Int64Dtype()' as a data type\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "Warning: dtype Int64 is not recognized as a valid dtype by numpy! AutoGluon may incorrectly handle this feature...\n",
      "Cannot interpret 'Int64Dtype()' as a data type\n",
      "Warning: dtype Int64 is not recognized as a valid dtype by numpy! AutoGluon may incorrectly handle this feature...\n",
      "Cannot interpret 'Int64Dtype()' as a data type\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "Warning: dtype Int64 is not recognized as a valid dtype by numpy! AutoGluon may incorrectly handle this feature...\n",
      "Cannot interpret 'Int64Dtype()' as a data type\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['Issue', 'Sub-issue', 'Company']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 218\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['ZIP code']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('Int64', []) : 1 | ['ZIP code']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])        : 1 | ['Date received']\n",
      "\t\t('object', [])       : 5 | ['Product', 'Sub-product', 'State', 'Consumer consent provided?', 'Submitted via']\n",
      "\t\t('object', ['text']) : 3 | ['Issue', 'Sub-issue', 'Company']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    :   5 | ['Product', 'Sub-product', 'State', 'Consumer consent provided?', 'Submitted via']\n",
      "\t\t('category', ['text_as_category'])  :   3 | ['Issue', 'Sub-issue', 'Company']\n",
      "\t\t('float', [])                       :   1 | ['Date received']\n",
      "\t\t('int', ['binned', 'text_special']) :  27 | ['Issue.char_count', 'Issue.word_count', 'Issue.capital_ratio', 'Issue.lower_ratio', 'Issue.special_ratio', ...]\n",
      "\t\t('int', ['text_ngram'])             : 143 | ['__nlp__.about', '__nlp__.account', '__nlp__.account status', '__nlp__.action', '__nlp__.america', ...]\n",
      "\t14.0s = Fit runtime\n",
      "\t9 features in original data used to generate 179 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.76 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 14.04s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 110 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 230.58s of the 345.93s of remaining time.\n",
      "\t0.455\t = Validation score   (accuracy)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 230.33s of the 345.68s of remaining time.\n",
      "\t0.43\t = Validation score   (accuracy)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 230.16s of the 345.51s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.6496\t = Validation score   (accuracy)\n",
      "\t111.68s\t = Training   runtime\n",
      "\t0.28s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 114.63s of the 229.99s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.01%)\n",
      "\t0.6833\t = Validation score   (accuracy)\n",
      "\t121.64s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 345.96s of the 104.14s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\n",
      "\t0.6833\t = Validation score   (accuracy)\n",
      "\t0.13s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 108 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 103.98s of the 103.93s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.6883\t = Validation score   (accuracy)\n",
      "\t103.66s\t = Training   runtime\n",
      "\t0.3s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 345.96s of the -3.68s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetFastAI_BAG_L2': 1.0}\n",
      "\t0.6883\t = Validation score   (accuracy)\n",
      "\t0.17s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 363.91s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 411.4 rows/s (300 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250521_174348\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250521_174955\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #53~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Jan 15 19:18:46 UTC 2\n",
      "CPU Count:          64\n",
      "Memory Avail:       336.10 GB / 503.54 GB (66.7%)\n",
      "Disk Space Avail:   33800.75 GB / 51214.59 GB (66.0%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ... Time limit = 360s\n",
      "AutoGluon will save models to \"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250521_174955\"\n",
      "Train Data Rows:    2400\n",
      "Train Data Columns: 5\n",
      "Label Column:       Company response to consumer\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 4\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "Warning: dtype Int64 is not recognized as a valid dtype by numpy! AutoGluon may incorrectly handle this feature...\n",
      "Cannot interpret 'Int64Dtype()' as a data type\n",
      "\tAvailable Memory:                    344153.52 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.49 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "Warning: dtype Int64 is not recognized as a valid dtype by numpy! AutoGluon may incorrectly handle this feature...\n",
      "Cannot interpret 'Int64Dtype()' as a data type\n",
      "Warning: dtype Int64 is not recognized as a valid dtype by numpy! AutoGluon may incorrectly handle this feature...\n",
      "Cannot interpret 'Int64Dtype()' as a data type\n",
      "Warning: dtype Int64 is not recognized as a valid dtype by numpy! AutoGluon may incorrectly handle this feature...\n",
      "Cannot interpret 'Int64Dtype()' as a data type\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "Warning: dtype Int64 is not recognized as a valid dtype by numpy! AutoGluon may incorrectly handle this feature...\n",
      "Cannot interpret 'Int64Dtype()' as a data type\n",
      "Warning: dtype Int64 is not recognized as a valid dtype by numpy! AutoGluon may incorrectly handle this feature...\n",
      "Cannot interpret 'Int64Dtype()' as a data type\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "Warning: dtype Int64 is not recognized as a valid dtype by numpy! AutoGluon may incorrectly handle this feature...\n",
      "Cannot interpret 'Int64Dtype()' as a data type\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['ZIP code']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('Int64', []) : 1 | ['ZIP code']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 1 | ['Date received']\n",
      "\t\t('object', []) : 3 | ['Product', 'Consumer consent provided?', 'Submitted via']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) : 3 | ['Product', 'Consumer consent provided?', 'Submitted via']\n",
      "\t\t('float', [])    : 1 | ['Date received']\n",
      "\t0.1s = Fit runtime\n",
      "\t4 features in original data used to generate 4 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.16s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 110 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 239.83s of the 359.81s of remaining time.\n",
      "\t0.4617\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 239.78s of the 359.76s of remaining time.\n",
      "\t0.4425\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 239.73s of the 359.71s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.6504\t = Validation score   (accuracy)\n",
      "\t109.26s\t = Training   runtime\n",
      "\t0.31s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 126.62s of the 246.59s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.6438\t = Validation score   (accuracy)\n",
      "\t78.35s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 44.36s of the 164.34s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.6512\t = Validation score   (accuracy)\n",
      "\t66.23s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 359.84s of the 93.99s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBM_BAG_L1': 1.0}\n",
      "\t0.6512\t = Validation score   (accuracy)\n",
      "\t0.17s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 108 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 93.79s of the 93.74s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.6567\t = Validation score   (accuracy)\n",
      "\t106.0s\t = Training   runtime\n",
      "\t0.3s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 359.84s of the -16.43s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetFastAI_BAG_L2': 0.667, 'NeuralNetFastAI_BAG_L1': 0.167, 'LightGBM_BAG_L1': 0.167}\n",
      "\t0.66\t = Validation score   (accuracy)\n",
      "\t0.19s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 376.67s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 393.6 rows/s (300 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250521_174955\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250521_175615\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #53~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Jan 15 19:18:46 UTC 2\n",
      "CPU Count:          64\n",
      "Memory Avail:       330.62 GB / 503.54 GB (65.7%)\n",
      "Disk Space Avail:   33800.44 GB / 51214.59 GB (66.0%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ... Time limit = 360s\n",
      "AutoGluon will save models to \"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250521_175615\"\n",
      "Train Data Rows:    2400\n",
      "Train Data Columns: 10\n",
      "Label Column:       Company response to consumer\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 4\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "Warning: dtype Int64 is not recognized as a valid dtype by numpy! AutoGluon may incorrectly handle this feature...\n",
      "Cannot interpret 'Int64Dtype()' as a data type\n",
      "\tAvailable Memory:                    338564.89 MB\n",
      "\tTrain Data (Original)  Memory Usage: 1.32 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "Warning: dtype Int64 is not recognized as a valid dtype by numpy! AutoGluon may incorrectly handle this feature...\n",
      "Cannot interpret 'Int64Dtype()' as a data type\n",
      "Warning: dtype Int64 is not recognized as a valid dtype by numpy! AutoGluon may incorrectly handle this feature...\n",
      "Cannot interpret 'Int64Dtype()' as a data type\n",
      "Warning: dtype Int64 is not recognized as a valid dtype by numpy! AutoGluon may incorrectly handle this feature...\n",
      "Cannot interpret 'Int64Dtype()' as a data type\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "Warning: dtype Int64 is not recognized as a valid dtype by numpy! AutoGluon may incorrectly handle this feature...\n",
      "Cannot interpret 'Int64Dtype()' as a data type\n",
      "Warning: dtype Int64 is not recognized as a valid dtype by numpy! AutoGluon may incorrectly handle this feature...\n",
      "Cannot interpret 'Int64Dtype()' as a data type\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "Warning: dtype Int64 is not recognized as a valid dtype by numpy! AutoGluon may incorrectly handle this feature...\n",
      "Cannot interpret 'Int64Dtype()' as a data type\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['Issue', 'Sub-issue', 'Company']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 231\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['ZIP code']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('Int64', []) : 1 | ['ZIP code']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])        : 1 | ['Date received']\n",
      "\t\t('object', [])       : 5 | ['Product', 'Sub-product', 'State', 'Consumer consent provided?', 'Submitted via']\n",
      "\t\t('object', ['text']) : 3 | ['Issue', 'Sub-issue', 'Company']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    :   5 | ['Product', 'Sub-product', 'State', 'Consumer consent provided?', 'Submitted via']\n",
      "\t\t('category', ['text_as_category'])  :   3 | ['Issue', 'Sub-issue', 'Company']\n",
      "\t\t('float', [])                       :   1 | ['Date received']\n",
      "\t\t('int', ['binned', 'text_special']) :  26 | ['Issue.char_count', 'Issue.word_count', 'Issue.capital_ratio', 'Issue.lower_ratio', 'Issue.special_ratio', ...]\n",
      "\t\t('int', ['text_ngram'])             : 146 | ['__nlp__.about', '__nlp__.account', '__nlp__.account status', '__nlp__.action', '__nlp__.america', ...]\n",
      "\t27.4s = Fit runtime\n",
      "\t9 features in original data used to generate 181 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.77 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 27.49s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 110 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 221.61s of the 332.48s of remaining time.\n",
      "\t0.4242\t = Validation score   (accuracy)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t0.36s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 221.14s of the 332.01s of remaining time.\n",
      "\t0.4154\t = Validation score   (accuracy)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 220.98s of the 331.84s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.6496\t = Validation score   (accuracy)\n",
      "\t112.32s\t = Training   runtime\n",
      "\t0.33s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 104.72s of the 215.59s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.01%)\n",
      "\t0.6946\t = Validation score   (accuracy)\n",
      "\t115.63s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 332.51s of the 95.65s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\n",
      "\t0.6946\t = Validation score   (accuracy)\n",
      "\t0.13s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 108 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 95.49s of the 95.44s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.6887\t = Validation score   (accuracy)\n",
      "\t105.9s\t = Training   runtime\n",
      "\t0.31s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 332.51s of the -14.68s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetFastAI_BAG_L2': 0.522, 'LightGBMXT_BAG_L1': 0.435, 'KNeighborsUnif_BAG_L1': 0.043}\n",
      "\t0.6979\t = Validation score   (accuracy)\n",
      "\t0.15s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 374.9s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 363.6 rows/s (300 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250521_175615\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250521_180233\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #53~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Jan 15 19:18:46 UTC 2\n",
      "CPU Count:          64\n",
      "Memory Avail:       329.49 GB / 503.54 GB (65.4%)\n",
      "Disk Space Avail:   33796.29 GB / 51214.59 GB (66.0%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ... Time limit = 360s\n",
      "AutoGluon will save models to \"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250521_180233\"\n",
      "Train Data Rows:    2400\n",
      "Train Data Columns: 5\n",
      "Label Column:       Company response to consumer\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 4\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "Warning: dtype Int64 is not recognized as a valid dtype by numpy! AutoGluon may incorrectly handle this feature...\n",
      "Cannot interpret 'Int64Dtype()' as a data type\n",
      "\tAvailable Memory:                    337415.63 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.49 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "Warning: dtype Int64 is not recognized as a valid dtype by numpy! AutoGluon may incorrectly handle this feature...\n",
      "Cannot interpret 'Int64Dtype()' as a data type\n",
      "Warning: dtype Int64 is not recognized as a valid dtype by numpy! AutoGluon may incorrectly handle this feature...\n",
      "Cannot interpret 'Int64Dtype()' as a data type\n",
      "Warning: dtype Int64 is not recognized as a valid dtype by numpy! AutoGluon may incorrectly handle this feature...\n",
      "Cannot interpret 'Int64Dtype()' as a data type\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "Warning: dtype Int64 is not recognized as a valid dtype by numpy! AutoGluon may incorrectly handle this feature...\n",
      "Cannot interpret 'Int64Dtype()' as a data type\n",
      "Warning: dtype Int64 is not recognized as a valid dtype by numpy! AutoGluon may incorrectly handle this feature...\n",
      "Cannot interpret 'Int64Dtype()' as a data type\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "Warning: dtype Int64 is not recognized as a valid dtype by numpy! AutoGluon may incorrectly handle this feature...\n",
      "Cannot interpret 'Int64Dtype()' as a data type\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['ZIP code']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('Int64', []) : 1 | ['ZIP code']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 1 | ['Date received']\n",
      "\t\t('object', []) : 3 | ['Product', 'Consumer consent provided?', 'Submitted via']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) : 3 | ['Product', 'Consumer consent provided?', 'Submitted via']\n",
      "\t\t('float', [])    : 1 | ['Date received']\n",
      "\t0.1s = Fit runtime\n",
      "\t4 features in original data used to generate 4 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.03 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.15s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 110 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 239.84s of the 359.81s of remaining time.\n",
      "\t0.4313\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 239.78s of the 359.75s of remaining time.\n",
      "\t0.4233\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 239.72s of the 359.70s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.6571\t = Validation score   (accuracy)\n",
      "\t109.62s\t = Training   runtime\n",
      "\t0.29s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 126.24s of the 246.21s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.6529\t = Validation score   (accuracy)\n",
      "\t60.61s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 61.86s of the 181.83s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.6575\t = Validation score   (accuracy)\n",
      "\t79.96s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 359.85s of the 97.81s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBM_BAG_L1': 1.0}\n",
      "\t0.6575\t = Validation score   (accuracy)\n",
      "\t0.16s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 108 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 97.63s of the 97.58s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.6696\t = Validation score   (accuracy)\n",
      "\t106.29s\t = Training   runtime\n",
      "\t0.26s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 359.85s of the -12.81s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetFastAI_BAG_L2': 0.636, 'NeuralNetFastAI_BAG_L1': 0.273, 'LightGBM_BAG_L1': 0.091}\n",
      "\t0.6721\t = Validation score   (accuracy)\n",
      "\t0.19s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 373.06s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 420.7 rows/s (300 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250521_180233\")\n"
     ]
    }
   ],
   "source": [
    "from baseline_eval import evaluate_baseline, plot_model_performance_summary\n",
    "results = evaluate_baseline(\n",
    "    df=loaded_df,\n",
    "    model='AGTabular',\n",
    "    df_name=dataset_config['dataset_name'],\n",
    "    label_col= dataset_config['target'],\n",
    "    task_type=dataset_config['task'],\n",
    "    textual_cols=textual_cols,\n",
    "    k_folds=5,\n",
    "    seed=0,\n",
    "    max_samples=3000,\n",
    "    output_path=f\"../../baseline_results/{dataset_config['task']}/{dataset_config['dataset_name']}.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bab50c48-0372-4dad-904f-de8b3066440b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving plot to ../../baseline_results/plots/clf/score\n",
      "Saving plot to ../../baseline_results/plots/clf/loss\n",
      "Saving plot to ../../baseline_results/plots/clf/roc_auc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score':                                     mean       std\n",
       " model                                             \n",
       " AutoGluon_Tabular_without_text  0.629667  0.024364\n",
       " AutoGluon_Tabular_with_text     0.679000  0.010967,\n",
       " 'loss':                                     mean       std\n",
       " model                                             \n",
       " AutoGluon_Tabular_with_text     0.810386  0.046411\n",
       " AutoGluon_Tabular_without_text  0.818811  0.026589,\n",
       " 'roc_auc':                                     mean       std\n",
       " model                                             \n",
       " AutoGluon_Tabular_without_text  0.845981  0.013781\n",
       " AutoGluon_Tabular_with_text     0.876902  0.012650}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs = pd.read_csv(f\"../../baseline_results/{dataset_config['task']}/{dataset_config['dataset_name']}.csv\")\n",
    "plot_model_performance_summary(name=dataset_config['dataset_name'],task=dataset_config['task'], df=rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e00a75-8307-4957-ba67-36b9b38788c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
