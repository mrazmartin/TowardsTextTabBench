{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0200d09",
   "metadata": {},
   "source": [
    "### Let's start with downloading the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4d0c4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "# to reach the dataloader_functions module\n",
    "module_path = os.path.abspath(os.path.join( \"..\"))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from dataloader_functions.download_data import download_raw_data\n",
    "current_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b8103e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO update this section per dataset\n",
    "dataset_config = {\n",
    "    'dataset_name': 'HS_cards',\n",
    "    'source': 'kaggle', # ['kaggle', 'local', 'openml', 'hf']\n",
    "    'remote_path': 'jeradrose/hearthstone-cards',\n",
    "    'files': ['cards_flat.csv'],\n",
    "    'rename_files': ['hs_cards.csv'],\n",
    "    'task': 'clf', # ['reg', 'clf']\n",
    "    'target': 'player_class',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4336bfef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36mInfo:\u001b[0m Dataset already downloaded in \u001b[1;35m/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/../../datasets_files/raw/classification/HS_cards\u001b[0m.\n",
      "Downloaded HS_cards dataset to /home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/../../datasets_files/raw/classification/HS_cards\n"
     ]
    }
   ],
   "source": [
    "if dataset_config['task'] == 'clf':\n",
    "    dataset_subfolder = os.path.join('raw', 'classification', dataset_config['dataset_name']) \n",
    "elif dataset_config['task'] == 'reg':\n",
    "    dataset_subfolder = os.path.join('raw', 'regression', dataset_config['dataset_name'])\n",
    "else:\n",
    "    raise ValueError(f\"Unknown task: {dataset_config['task']}\")\n",
    "\n",
    "# this path needs to be modified based on the location of the notebook\n",
    "download_path = os.path.join(current_dir, '..', '..', 'datasets_files', dataset_subfolder)\n",
    "\n",
    "if download_raw_data(\n",
    "    dataset_config=dataset_config,\n",
    "    download_path=download_path,\n",
    "    force_download=False,\n",
    "    remove_unlisted=True,\n",
    ") is not None:\n",
    "    print(f\"Downloaded {dataset_config['dataset_name']} dataset to {download_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d886637",
   "metadata": {},
   "source": [
    "### Now we need to preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48bcaebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader_functions.load_and_pp_raw_data import _drop_empty_columns, _drop_single_value_columns\n",
    "from dataloader_functions.utils.data_2_df import read_any_to_df\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "current_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0861820c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading /home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/../../datasets_files/raw/classification/HS_cards/hs_cards.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>player_class</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>set</th>\n",
       "      <th>text</th>\n",
       "      <th>cost</th>\n",
       "      <th>attack</th>\n",
       "      <th>health</th>\n",
       "      <th>rarity</th>\n",
       "      <th>collectible</th>\n",
       "      <th>flavor</th>\n",
       "      <th>mechanics</th>\n",
       "      <th>dust</th>\n",
       "      <th>play_requirements</th>\n",
       "      <th>race</th>\n",
       "      <th>how_to_earn</th>\n",
       "      <th>how_to_earn_golden</th>\n",
       "      <th>targeting_arrow_text</th>\n",
       "      <th>faction</th>\n",
       "      <th>durability</th>\n",
       "      <th>entourage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KARA_00_07</td>\n",
       "      <td>MAGE</td>\n",
       "      <td>SPELL</td>\n",
       "      <td>Astral Portal</td>\n",
       "      <td>KARA</td>\n",
       "      <td>Summon a random &lt;b&gt;Legendary&lt;/b&gt; minion.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'REQ_NUM_MINION_SLOTS': 1}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NEW1_008a</td>\n",
       "      <td>DRUID</td>\n",
       "      <td>SPELL</td>\n",
       "      <td>Ancient Teachings</td>\n",
       "      <td>EXPERT1</td>\n",
       "      <td>Draw a card.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BRM_010t2</td>\n",
       "      <td>DRUID</td>\n",
       "      <td>MINION</td>\n",
       "      <td>Druid of the Flame</td>\n",
       "      <td>BRM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>COMMON</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[40, 400, 5, 50]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BEAST</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id player_class    type                name      set  \\\n",
       "0  KARA_00_07         MAGE   SPELL       Astral Portal     KARA   \n",
       "1   NEW1_008a        DRUID   SPELL   Ancient Teachings  EXPERT1   \n",
       "2   BRM_010t2        DRUID  MINION  Druid of the Flame      BRM   \n",
       "\n",
       "                                       text  cost  attack  health  rarity  \\\n",
       "0  Summon a random <b>Legendary</b> minion.   1.0     NaN     NaN     NaN   \n",
       "1                              Draw a card.   0.0     NaN     NaN     NaN   \n",
       "2                                       NaN   3.0     2.0     5.0  COMMON   \n",
       "\n",
       "  collectible flavor mechanics              dust            play_requirements  \\\n",
       "0         NaN    NaN       NaN               NaN  {'REQ_NUM_MINION_SLOTS': 1}   \n",
       "1         NaN    NaN       NaN               NaN                          NaN   \n",
       "2         NaN    NaN       NaN  [40, 400, 5, 50]                          NaN   \n",
       "\n",
       "    race how_to_earn how_to_earn_golden targeting_arrow_text faction  \\\n",
       "0    NaN         NaN                NaN                  NaN     NaN   \n",
       "1    NaN         NaN                NaN                  NaN     NaN   \n",
       "2  BEAST         NaN                NaN                  NaN     NaN   \n",
       "\n",
       "   durability entourage  \n",
       "0         NaN       NaN  \n",
       "1         NaN       NaN  \n",
       "2         NaN       NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dataset_files_df = []\n",
    "\n",
    "if dataset_config['rename_files'] is None or len(dataset_config['rename_files']) == 0:\n",
    "    dataset_config['rename_files'] = dataset_config['files']\n",
    "\n",
    "for file in dataset_config['rename_files']:\n",
    "\n",
    "    file_location = os.path.join(download_path, file)\n",
    "\n",
    "    print(f\"Loading {file_location}\")\n",
    "\n",
    "    dataset_files_df.append(read_any_to_df(file_location))\n",
    "\n",
    "# example of the loaded df data:\n",
    "pd.set_option('display.max_columns', None)\n",
    "dataset_files_df[0].head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d099b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped: Index(['mechanics', 'dust', 'play_requirements', 'race', 'how_to_earn',\n",
      "       'how_to_earn_golden', 'targeting_arrow_text', 'faction', 'durability',\n",
      "       'entourage'],\n",
      "      dtype='object')\n",
      "Dataframe shape before/afrer cleaning: (2819, 22) / (2816, 11)\n"
     ]
    }
   ],
   "source": [
    "## Run some basic data cleaning\n",
    "\n",
    "dataset_files_gen_cleaned = []\n",
    "missing_ratio_threshold = 0.63 # TODO the threshold can be changed\n",
    "\n",
    "for df_file in dataset_files_df:\n",
    "    df_size = df_file.shape\n",
    "    # 1. Drop columns with more than 50% missing values\n",
    "    df_file = _drop_empty_columns(df_file, threshold=missing_ratio_threshold)   \n",
    "    # 2. Drop columns with only one unique value\n",
    "    df_file = _drop_single_value_columns(df_file)\n",
    "    # 3. remove duplicates\n",
    "    df_file = df_file.drop_duplicates()\n",
    "    # 4. remove rows with missing target values\n",
    "    df_file = df_file[df_file[dataset_config['target']].notna()]\n",
    "    # 5. drop unnamed columns\n",
    "    df_file = df_file.loc[:, ~df_file.columns.str.contains('^Unnamed')]\n",
    "\n",
    "    dataset_files_gen_cleaned.append(df_file)\n",
    "\n",
    "    print(f\"Dataframe shape before/afrer cleaning: {df_size} / {df_file.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0a2a11a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe shape before/afrer by-hand cleaning: (2816, 11) / (2816, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player_class</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>set</th>\n",
       "      <th>text</th>\n",
       "      <th>cost</th>\n",
       "      <th>attack</th>\n",
       "      <th>health</th>\n",
       "      <th>rarity</th>\n",
       "      <th>flavor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MAGE</td>\n",
       "      <td>SPELL</td>\n",
       "      <td>Astral Portal</td>\n",
       "      <td>KARA</td>\n",
       "      <td>Summon a random &lt;b&gt;Legendary&lt;/b&gt; minion.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DRUID</td>\n",
       "      <td>SPELL</td>\n",
       "      <td>Ancient Teachings</td>\n",
       "      <td>EXPERT1</td>\n",
       "      <td>Draw a card.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DRUID</td>\n",
       "      <td>MINION</td>\n",
       "      <td>Druid of the Flame</td>\n",
       "      <td>BRM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>COMMON</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  player_class    type                name      set  \\\n",
       "0         MAGE   SPELL       Astral Portal     KARA   \n",
       "1        DRUID   SPELL   Ancient Teachings  EXPERT1   \n",
       "2        DRUID  MINION  Druid of the Flame      BRM   \n",
       "\n",
       "                                       text  cost  attack  health  rarity  \\\n",
       "0  Summon a random <b>Legendary</b> minion.   1.0     NaN     NaN     NaN   \n",
       "1                              Draw a card.   0.0     NaN     NaN     NaN   \n",
       "2                                       NaN   3.0     2.0     5.0  COMMON   \n",
       "\n",
       "  flavor  \n",
       "0    NaN  \n",
       "1    NaN  \n",
       "2    NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## TODO: Now run custom data cleaning -> remove non-essential columns\n",
    "\n",
    "cols_to_drop = ['id']\n",
    "\n",
    "dataset_files_cleaned = []\n",
    "\n",
    "# assuming for multiple files we still want to drop the same columns\n",
    "for df_file in dataset_files_gen_cleaned:\n",
    "    df_size = df_file.shape\n",
    "    for col in cols_to_drop:\n",
    "        if col in df_file.columns:\n",
    "            df_file.drop(col, axis=1, inplace=True)\n",
    "        else:\n",
    "            print(f\"Column {col} not found in dataframe\")\n",
    "\n",
    "    dataset_files_cleaned.append(df_file)    \n",
    "    print(f\"Dataframe shape before/afrer by-hand cleaning: {df_size} / {df_file.shape}\")\n",
    "\n",
    "dataset_files_cleaned[0].head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d90a681b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe shape before custom cleaning: (2816, 10)\n",
      "Dataframe shape after custom clearning: (2810, 10)\n"
     ]
    }
   ],
   "source": [
    "# TODO: some custom data cleaning\n",
    "\n",
    "import copy \n",
    "tmp_df = copy.deepcopy(dataset_files_cleaned)\n",
    "dataset_files_by_hand_cleaned = []\n",
    "\n",
    "for df_file in dataset_files_cleaned:\n",
    "    print(f\"Dataframe shape before custom cleaning: {df_file.shape}\")\n",
    "    # TODO: add custom data cleaning here\n",
    "    # 1. drop the cards belonging to class 'deathknight' and 'dream' \n",
    "    df_file = df_file[df_file['player_class'] != 'DREAM']\n",
    "    df_file = df_file[df_file['player_class'] != 'DEATHKNIGHT']\n",
    "\n",
    "    print(f\"Dataframe shape after custom clearning: {df_file.shape}\")\n",
    "\n",
    "    dataset_files_by_hand_cleaned.append(df_file)\n",
    "\n",
    "# reset the dataframe list to the version before custom cleaning -> next cells work wuth dataset_files_by_hand_cleaned\n",
    "dataset_files_cleaned = tmp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581b17e1",
   "metadata": {},
   "source": [
    "### Now it is time to visualize our changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1500c210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player_class</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>set</th>\n",
       "      <th>text</th>\n",
       "      <th>cost</th>\n",
       "      <th>attack</th>\n",
       "      <th>health</th>\n",
       "      <th>rarity</th>\n",
       "      <th>flavor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MAGE</td>\n",
       "      <td>SPELL</td>\n",
       "      <td>Astral Portal</td>\n",
       "      <td>KARA</td>\n",
       "      <td>Summon a random &lt;b&gt;Legendary&lt;/b&gt; minion.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DRUID</td>\n",
       "      <td>SPELL</td>\n",
       "      <td>Ancient Teachings</td>\n",
       "      <td>EXPERT1</td>\n",
       "      <td>Draw a card.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DRUID</td>\n",
       "      <td>MINION</td>\n",
       "      <td>Druid of the Flame</td>\n",
       "      <td>BRM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>COMMON</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  player_class    type                name      set  \\\n",
       "0         MAGE   SPELL       Astral Portal     KARA   \n",
       "1        DRUID   SPELL   Ancient Teachings  EXPERT1   \n",
       "2        DRUID  MINION  Druid of the Flame      BRM   \n",
       "\n",
       "                                       text  cost  attack  health  rarity  \\\n",
       "0  Summon a random <b>Legendary</b> minion.   1.0     NaN     NaN     NaN   \n",
       "1                              Draw a card.   0.0     NaN     NaN     NaN   \n",
       "2                                       NaN   3.0     2.0     5.0  COMMON   \n",
       "\n",
       "  flavor  \n",
       "0    NaN  \n",
       "1    NaN  \n",
       "2    NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "dataset_files_by_hand_cleaned[0].head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f71269d",
   "metadata": {},
   "source": [
    "Let's figure out which columns should be viewed as categorical / numerical / textual\n",
    "\n",
    "we can start with a simple heuristic:\n",
    "1. numerical is everything which\n",
    "    - keeps most of its character length after non-numeral strip\n",
    "    - has about the same number of unique values after the strip\n",
    "    + for the purpose of keeping \"semantic information\", hand picked columns can be viewed also as non-numerical, that is not the default benchmark approach though\n",
    "\n",
    "2. categorical is everthing non numerical, which can be then divided into N (where N << Num instances) unique categories\n",
    "\n",
    "3. textual is everything else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "436f9ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Threshold for categorical vs textual: 50\n",
      "Numerical columns (3): ['cost', 'attack', 'health']\n",
      "Categorical columns (4): ['player_class', 'type', 'set', 'rarity']\n",
      "Textual columns (3): ['name', 'text', 'flavor']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def is_mostly_numeric(series, length_threshold=0.5, unique_threshold=0.8):\n",
    "    \"\"\"Check if column is mostly numeric after stripping non-numeric chars.\"\"\"\n",
    "    stripped = series.astype(str).str.replace(r\"[^\\d\\.\\-]\", \"\", regex=True)\n",
    "    \n",
    "    original_len = series.astype(str).str.len().replace(0, 1)  # avoid div by zero\n",
    "    length_ratio = (stripped.str.len() / original_len).mean()\n",
    "\n",
    "    unique_ratio = stripped.nunique(dropna=False) / max(series.nunique(dropna=False), 1)\n",
    "\n",
    "    return length_ratio > length_threshold and unique_ratio > unique_threshold\n",
    "\n",
    "def classify_columns(df, unique_ratio_threshold=None, explicit_nunique_threshold=None):\n",
    "    \"\"\"\n",
    "    Classify dataframe columns into numerical, categorical, textual.\n",
    "    - numerical: true numerics or digit-heavy strings.\n",
    "    - categorical: low-cardinality discrete values.\n",
    "    - textual: high-cardinality free-text fields.\n",
    "\n",
    "    Params:\n",
    "    - unique_ratio_threshold: Ratio (e.g., 0.05 = 5% of dataset size)\n",
    "    - explicit_nunique_threshold: Absolute number (overrides ratio if set)\n",
    "    \"\"\"\n",
    "    n_rows = len(df)\n",
    "\n",
    "    # Determine threshold\n",
    "    if explicit_nunique_threshold is not None:\n",
    "        nunique_threshold = explicit_nunique_threshold\n",
    "    elif unique_ratio_threshold is not None:\n",
    "        nunique_threshold = int(unique_ratio_threshold * n_rows)\n",
    "    else:\n",
    "        nunique_threshold = int(0.05 * n_rows)  # default 5%\n",
    "\n",
    "    nunique_threshold = max(10, nunique_threshold)  # safeguard for small datasets\n",
    "    print(f\"Threshold for categorical vs textual: {nunique_threshold}\")\n",
    "\n",
    "    numerical_cols = []\n",
    "    categorical_cols = []\n",
    "    textual_cols = []\n",
    "\n",
    "    for col in df.columns:\n",
    "        series = df[col]\n",
    "\n",
    "        if pd.api.types.is_numeric_dtype(series):\n",
    "            numerical_cols.append(col)\n",
    "        \n",
    "        elif pd.api.types.is_string_dtype(series) or pd.api.types.is_object_dtype(series):\n",
    "            if is_mostly_numeric(series):\n",
    "                numerical_cols.append(col)\n",
    "            else:\n",
    "                nunique = series.nunique(dropna=False)\n",
    "                if nunique <= nunique_threshold:\n",
    "                    categorical_cols.append(col)\n",
    "                else:\n",
    "                    textual_cols.append(col)\n",
    "        else:\n",
    "            print(f\"⚠️ Unhandled column type: '{col}' (dtype={series.dtype})\")\n",
    "\n",
    "    print(f\"Numerical columns ({len(numerical_cols)}): {numerical_cols}\")\n",
    "    print(f\"Categorical columns ({len(categorical_cols)}): {categorical_cols}\")\n",
    "    print(f\"Textual columns ({len(textual_cols)}): {textual_cols}\")\n",
    "\n",
    "    return numerical_cols, categorical_cols, textual_cols\n",
    "\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "for df_file in dataset_files_by_hand_cleaned:\n",
    "    # Ratio-based (5% of rows)\n",
    "    # numerical_cols, categorical_cols, textual_cols = classify_columns(df_file, unique_ratio_threshold=0.05)\n",
    "    print(\"\")\n",
    "    # OR explicit value (e.g., anything <= 50 is categorical)\n",
    "    numerical_cols, categorical_cols, textual_cols = classify_columns(df_file, explicit_nunique_threshold=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6499589b",
   "metadata": {},
   "source": [
    "Now let's just try to visualize the kept features, their example values, and their cat/num/text allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "afffbdb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column Name</th>\n",
       "      <th>Example Value</th>\n",
       "      <th>Type</th>\n",
       "      <th># Categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>player_class</td>\n",
       "      <td>MAGE</td>\n",
       "      <td>categorical</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>type</td>\n",
       "      <td>SPELL</td>\n",
       "      <td>categorical</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>name</td>\n",
       "      <td>Astral Portal</td>\n",
       "      <td>textual</td>\n",
       "      <td>2195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>set</td>\n",
       "      <td>KARA</td>\n",
       "      <td>categorical</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>text</td>\n",
       "      <td>Summon a random &lt;b&gt;Legendary&lt;/b&gt; minion.</td>\n",
       "      <td>textual</td>\n",
       "      <td>1875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cost</td>\n",
       "      <td>1.0</td>\n",
       "      <td>numerical</td>\n",
       "      <td>~ 15 ~</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>attack</td>\n",
       "      <td>2.0</td>\n",
       "      <td>numerical</td>\n",
       "      <td>~ 31 ~</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>health</td>\n",
       "      <td>5.0</td>\n",
       "      <td>numerical</td>\n",
       "      <td>~ 42 ~</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rarity</td>\n",
       "      <td>COMMON</td>\n",
       "      <td>categorical</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>flavor</td>\n",
       "      <td>It's like putting racing stripes and a giant s...</td>\n",
       "      <td>textual</td>\n",
       "      <td>1056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Column Name                                      Example Value  \\\n",
       "0  player_class                                               MAGE   \n",
       "1          type                                              SPELL   \n",
       "2          name                                      Astral Portal   \n",
       "3           set                                               KARA   \n",
       "4          text           Summon a random <b>Legendary</b> minion.   \n",
       "5          cost                                                1.0   \n",
       "6        attack                                                2.0   \n",
       "7        health                                                5.0   \n",
       "8        rarity                                             COMMON   \n",
       "9        flavor  It's like putting racing stripes and a giant s...   \n",
       "\n",
       "          Type # Categories  \n",
       "0  categorical           10  \n",
       "1  categorical            6  \n",
       "2      textual         2195  \n",
       "3  categorical           17  \n",
       "4      textual         1875  \n",
       "5    numerical       ~ 15 ~  \n",
       "6    numerical       ~ 31 ~  \n",
       "7    numerical       ~ 42 ~  \n",
       "8  categorical            5  \n",
       "9      textual         1056  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary = []\n",
    "for col in df_file.columns:\n",
    "    if col in categorical_cols:\n",
    "        col_type = \"categorical\"\n",
    "        num_categories = df_file[col].nunique(dropna=True)\n",
    "        num_categories_display = int(num_categories)\n",
    "    elif col in textual_cols:\n",
    "        col_type = \"textual\"\n",
    "        num_categories = df_file[col].nunique(dropna=True)\n",
    "        num_categories_display = int(num_categories)\n",
    "    elif col in numerical_cols:\n",
    "        col_type = \"numerical\"\n",
    "        num_categories = df_file[col].nunique(dropna=True)\n",
    "        num_categories_display = '~ ' + str(num_categories) + ' ~'\n",
    "    else:\n",
    "        col_type = \"unknown\"\n",
    "        num_categories_display = '--'\n",
    "\n",
    "    example = df_file[col].dropna().iloc[0] if df_file[col].dropna().size > 0 else None\n",
    "    summary.append({\n",
    "        'Column Name': col,\n",
    "        'Example Value': str(example),\n",
    "        'Type': col_type,\n",
    "        '# Categories': num_categories_display\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary)\n",
    "\n",
    "# TODO: by hand changes of the type and category count -> e.g. for 'Location':\n",
    "#    # Post-processing: override the type and category count for 'Location'\n",
    "#    # summary_df.loc[summary_df['Column Name'] == 'Location', 'Type'] = 'textual'\n",
    "#    # num_categories = df_file['Location'].nunique(dropna=True)\n",
    "#    # summary_df.loc[summary_df['Column Name'] == 'Location', '# Categories'] = int(num_categories)\n",
    "\n",
    "display(summary_df)  # Or print(summary_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ef8954",
   "metadata": {},
   "source": [
    "### Saving the processed data and loading it back up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2fe5eab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/../../datasets_files/raw/classification/HS_cards/hs_cards_processed.pkl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Handle rename_files fallback\n",
    "if dataset_config['rename_files'] is None or len(dataset_config['rename_files']) == 0:\n",
    "    dataset_config['rename_files'] = dataset_config['files']\n",
    "\n",
    "for i, df_file in enumerate(dataset_files_by_hand_cleaned):\n",
    "    df_with_meta = df_file.copy()\n",
    "\n",
    "    # Get corresponding file name\n",
    "    file_name = dataset_config['rename_files'][i]\n",
    "    file_base = os.path.splitext(file_name)[0]\n",
    "\n",
    "    # Try assigning multi-index header from summary\n",
    "    try:\n",
    "        df_with_meta.columns = pd.MultiIndex.from_frame(\n",
    "            summary_df[['Column Name', 'Type', '# Categories']]\n",
    "        )\n",
    "        local_summary = summary_df.copy()\n",
    "    except ValueError:\n",
    "        local_summary = summary_df.copy()\n",
    "        if dataset_config['target'] in local_summary['Column Name'].values:\n",
    "            local_summary = local_summary[local_summary['Column Name'] != dataset_config['target']]\n",
    "            df_with_meta.columns = pd.MultiIndex.from_frame(\n",
    "                local_summary[['Column Name', 'Type', '# Categories']]\n",
    "            )\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "    # Construct and save everything together\n",
    "    output_filename = f\"{file_base}_processed.pkl\"\n",
    "    output_path = os.path.join(download_path, output_filename)\n",
    "\n",
    "    save_bundle = {\n",
    "        'data': df_with_meta,\n",
    "        'summary': local_summary,\n",
    "        'config': dataset_config\n",
    "    }\n",
    "\n",
    "    pd.to_pickle(save_bundle, output_path)\n",
    "    print(f\"Saved: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c7bcd87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== HS_CARDS ===\n",
      "Loaded config keys: ['dataset_name', 'source', 'remote_path', 'files', 'rename_files', 'task', 'target']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column Name</th>\n",
       "      <th>Type</th>\n",
       "      <th># Categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>player_class</td>\n",
       "      <td>categorical</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>type</td>\n",
       "      <td>categorical</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>name</td>\n",
       "      <td>textual</td>\n",
       "      <td>2195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>set</td>\n",
       "      <td>categorical</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>text</td>\n",
       "      <td>textual</td>\n",
       "      <td>1875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cost</td>\n",
       "      <td>numerical</td>\n",
       "      <td>~ 15 ~</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>attack</td>\n",
       "      <td>numerical</td>\n",
       "      <td>~ 31 ~</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>health</td>\n",
       "      <td>numerical</td>\n",
       "      <td>~ 42 ~</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rarity</td>\n",
       "      <td>categorical</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>flavor</td>\n",
       "      <td>textual</td>\n",
       "      <td>1056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Column Name         Type # Categories\n",
       "0  player_class  categorical           10\n",
       "1          type  categorical            6\n",
       "2          name      textual         2195\n",
       "3           set  categorical           17\n",
       "4          text      textual         1875\n",
       "5          cost    numerical       ~ 15 ~\n",
       "6        attack    numerical       ~ 31 ~\n",
       "7        health    numerical       ~ 42 ~\n",
       "8        rarity  categorical            5\n",
       "9        flavor      textual         1056"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Column Name</th>\n",
       "      <th>player_class</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>set</th>\n",
       "      <th>text</th>\n",
       "      <th>cost</th>\n",
       "      <th>attack</th>\n",
       "      <th>health</th>\n",
       "      <th>rarity</th>\n",
       "      <th>flavor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MAGE</td>\n",
       "      <td>SPELL</td>\n",
       "      <td>Astral Portal</td>\n",
       "      <td>KARA</td>\n",
       "      <td>Summon a random &lt;b&gt;Legendary&lt;/b&gt; minion.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DRUID</td>\n",
       "      <td>SPELL</td>\n",
       "      <td>Ancient Teachings</td>\n",
       "      <td>EXPERT1</td>\n",
       "      <td>Draw a card.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DRUID</td>\n",
       "      <td>MINION</td>\n",
       "      <td>Druid of the Flame</td>\n",
       "      <td>BRM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>COMMON</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Column Name player_class    type                name      set  \\\n",
       "0                   MAGE   SPELL       Astral Portal     KARA   \n",
       "1                  DRUID   SPELL   Ancient Teachings  EXPERT1   \n",
       "2                  DRUID  MINION  Druid of the Flame      BRM   \n",
       "\n",
       "Column Name                                      text  cost  attack  health  \\\n",
       "0            Summon a random <b>Legendary</b> minion.   1.0     NaN     NaN   \n",
       "1                                        Draw a card.   0.0     NaN     NaN   \n",
       "2                                                 NaN   3.0     2.0     5.0   \n",
       "\n",
       "Column Name  rarity flavor  \n",
       "0               NaN    NaN  \n",
       "1               NaN    NaN  \n",
       "2            COMMON    NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "if dataset_config['task'] == 'clf':\n",
    "    dataset_subfolder = os.path.join('raw', 'classification', dataset_config['dataset_name']) \n",
    "elif dataset_config['task'] == 'reg':\n",
    "    dataset_subfolder = os.path.join('raw', 'regression', dataset_config['dataset_name'])\n",
    "else:\n",
    "    raise ValueError(f\"Unknown task: {dataset_config['task']}\")\n",
    "\n",
    "# this path needs to be modified based on the location of the notebook\n",
    "download_path = os.path.join(current_dir, '..', '..', 'datasets_files', dataset_subfolder)\n",
    "\n",
    "# Loop through processed files in rename_files\n",
    "for file_name in dataset_config['rename_files']:\n",
    "    # Remove .csv or .tsv extension to get the base name\n",
    "    file_base = os.path.splitext(file_name)[0]\n",
    "    processed_filename = f\"{file_base}_processed.pkl\"\n",
    "    processed_path = os.path.join(download_path, processed_filename)\n",
    "\n",
    "    # Load the bundled dictionary (data + summary + config)\n",
    "    bundle = pd.read_pickle(processed_path)\n",
    "\n",
    "    # Extract components\n",
    "    loaded_df = bundle['data']\n",
    "    summary_df = bundle['summary']\n",
    "    loaded_config = bundle['config']\n",
    "\n",
    "    print(f\"\\n=== {file_base.upper()} ===\")\n",
    "    print(f\"Loaded config keys: {list(loaded_config.keys())}\")\n",
    "\n",
    "    # Show metadata\n",
    "    meta_df = pd.DataFrame(loaded_df.columns.tolist(), columns=['Column Name', 'Type', '# Categories'])\n",
    "    display(meta_df)\n",
    "\n",
    "    # Flatten for modeling\n",
    "    loaded_df.columns = loaded_df.columns.get_level_values(0)\n",
    "    display(loaded_df.head(n=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d67dfa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MAGE' 'DRUID' 'NEUTRAL' 'WARRIOR' 'WARLOCK' 'PALADIN' 'SHAMAN' 'HUNTER'\n",
      " 'ROGUE' 'PRIEST']\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Print unique values in player_class column\n",
    "print(loaded_df['player_class'].unique())\n",
    "\n",
    "# Plot the distribution of player_class with counts\n",
    "value_counts = loaded_df['player_class'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "value_counts.plot(kind='bar')\n",
    "\n",
    "# Add counts as text labels on top of bars\n",
    "for i, count in enumerate(value_counts):\n",
    "    plt.text(i, count, str(count), ha='center', va='bottom')\n",
    "\n",
    "plt.title('Distribution of player_class')\n",
    "plt.xlabel('player_class')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)  # Rotate x labels if needed\n",
    "plt.tight_layout()       # Adjust layout to prevent clipping\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8258255e-2df5-466a-aea1-f1a2bdfca721",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250521_181620\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #53~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Jan 15 19:18:46 UTC 2\n",
      "CPU Count:          64\n",
      "Memory Avail:       330.45 GB / 503.54 GB (65.6%)\n",
      "Disk Space Avail:   33795.70 GB / 51214.59 GB (66.0%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[WRAPPER] Running stratified downsampling mode for task: clf\n",
      "\u001b[1;36mInfo:\u001b[0m \n",
      "[INFO] Downsampling dataframe: HS_cards (original rows: 2810)\n",
      "\u001b[1;33mInfo:\u001b[0m Trying to sample ~1000 rows per class (total=10000)\n",
      "\u001b[1;32mInfo:\u001b[0m [INFO] Class MAGE has only 108 instances. Keeping all.\n",
      "\u001b[1;32mInfo:\u001b[0m [INFO] Class DRUID has only 159 instances. Keeping all.\n",
      "\u001b[1;32mInfo:\u001b[0m [INFO] Class WARRIOR has only 125 instances. Keeping all.\n",
      "\u001b[1;32mInfo:\u001b[0m [INFO] Class WARLOCK has only 105 instances. Keeping all.\n",
      "\u001b[1;32mInfo:\u001b[0m [INFO] Class PALADIN has only 103 instances. Keeping all.\n",
      "\u001b[1;32mInfo:\u001b[0m [INFO] Class SHAMAN has only 105 instances. Keeping all.\n",
      "\u001b[1;32mInfo:\u001b[0m [INFO] Class HUNTER has only 115 instances. Keeping all.\n",
      "\u001b[1;32mInfo:\u001b[0m [INFO] Class ROGUE has only 107 instances. Keeping all.\n",
      "\u001b[1;32mInfo:\u001b[0m [INFO] Class PRIEST has only 101 instances. Keeping all.\n",
      "\u001b[1;32mInfo:\u001b[0m Filling up with all remaining 782 samples.\n",
      "\u001b[1;36mInfo:\u001b[0m Final downsampled dataset has 2810 rows. Per class counts: [NEUTRAL: 1782, DRUID: 159, WARRIOR: 125, HUNTER: 115, MAGE: 108, ROGUE: 107, SHAMAN: 105, WARLOCK: 105, PALADIN: 103, PRIEST: 101]\n",
      "\n",
      "Downsampled 2810 rows for HS_cards dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Beginning AutoGluon training ... Time limit = 360s\n",
      "AutoGluon will save models to \"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250521_181620\"\n",
      "Train Data Rows:    2248\n",
      "Train Data Columns: 9\n",
      "Label Column:       player_class\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 10\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    338413.03 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.91 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['text', 'flavor']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 157\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])        : 3 | ['cost', 'attack', 'health']\n",
      "\t\t('object', [])       : 4 | ['type', 'name', 'set', 'rarity']\n",
      "\t\t('object', ['text']) : 2 | ['text', 'flavor']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    :   4 | ['type', 'name', 'set', 'rarity']\n",
      "\t\t('category', ['text_as_category'])  :   2 | ['text', 'flavor']\n",
      "\t\t('float', [])                       :   3 | ['cost', 'attack', 'health']\n",
      "\t\t('int', ['binned', 'text_special']) :  36 | ['text.char_count', 'text.word_count', 'text.capital_ratio', 'text.lower_ratio', 'text.digit_ratio', ...]\n",
      "\t\t('int', ['text_ngram'])             : 156 | ['__nlp__.about', '__nlp__.add', '__nlp__.after', '__nlp__.all', '__nlp__.all minions', ...]\n",
      "\t3.9s = Fit runtime\n",
      "\t9 features in original data used to generate 201 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 4.0s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 110 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 237.27s of the 355.97s of remaining time.\n",
      "\t0.6134\t = Validation score   (accuracy)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t0.41s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 236.70s of the 355.40s of remaining time.\n",
      "\t0.6068\t = Validation score   (accuracy)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.3s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 236.27s of the 354.97s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.6971\t = Validation score   (accuracy)\n",
      "\t114.71s\t = Training   runtime\n",
      "\t0.36s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 99.78s of the 218.48s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.02%)\n",
      "\t0.6931\t = Validation score   (accuracy)\n",
      "\t108.68s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 356.00s of the 106.28s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetFastAI_BAG_L1': 0.5, 'LightGBMXT_BAG_L1': 0.438, 'KNeighborsUnif_BAG_L1': 0.062}\n",
      "\t0.7104\t = Validation score   (accuracy)\n",
      "\t0.15s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 108 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 106.07s of the 106.02s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.6944\t = Validation score   (accuracy)\n",
      "\t108.32s\t = Training   runtime\n",
      "\t0.35s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 356.00s of the -6.00s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.5, 'NeuralNetFastAI_BAG_L1': 0.25, 'NeuralNetFastAI_BAG_L2': 0.25}\n",
      "\t0.7109\t = Validation score   (accuracy)\n",
      "\t0.18s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 366.27s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 292.3 rows/s (281 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250521_181620\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250521_182235\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #53~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Jan 15 19:18:46 UTC 2\n",
      "CPU Count:          64\n",
      "Memory Avail:       329.59 GB / 503.54 GB (65.5%)\n",
      "Disk Space Avail:   33795.31 GB / 51214.59 GB (66.0%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ... Time limit = 360s\n",
      "AutoGluon will save models to \"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250521_182235\"\n",
      "Train Data Rows:    2248\n",
      "Train Data Columns: 6\n",
      "Label Column:       player_class\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 10\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    337467.63 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.42 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 3 | ['cost', 'attack', 'health']\n",
      "\t\t('object', []) : 3 | ['type', 'set', 'rarity']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) : 3 | ['type', 'set', 'rarity']\n",
      "\t\t('float', [])    : 3 | ['cost', 'attack', 'health']\n",
      "\t0.1s = Fit runtime\n",
      "\t6 features in original data used to generate 6 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.06 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.13s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 110 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 239.85s of the 359.84s of remaining time.\n",
      "\t0.5703\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 239.77s of the 359.76s of remaining time.\n",
      "\t0.5658\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 239.69s of the 359.68s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.6641\t = Validation score   (accuracy)\n",
      "\t105.33s\t = Training   runtime\n",
      "\t0.31s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 131.55s of the 251.54s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.01%)\n",
      "\t0.6579\t = Validation score   (accuracy)\n",
      "\t131.85s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 359.87s of the 116.36s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetFastAI_BAG_L1': 0.9, 'LightGBMXT_BAG_L1': 0.1}\n",
      "\t0.6655\t = Validation score   (accuracy)\n",
      "\t0.16s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 108 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 116.16s of the 116.12s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.661\t = Validation score   (accuracy)\n",
      "\t102.83s\t = Training   runtime\n",
      "\t0.32s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 10.49s of the 10.44s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.01%)\n",
      "\t0.6299\t = Validation score   (accuracy)\n",
      "\t32.42s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 359.87s of the -25.07s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetFastAI_BAG_L1': 0.818, 'NeuralNetFastAI_BAG_L2': 0.182}\n",
      "\t0.6681\t = Validation score   (accuracy)\n",
      "\t0.22s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 385.34s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 368.5 rows/s (281 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250521_182235\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250521_182903\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #53~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Jan 15 19:18:46 UTC 2\n",
      "CPU Count:          64\n",
      "Memory Avail:       330.20 GB / 503.54 GB (65.6%)\n",
      "Disk Space Avail:   33798.87 GB / 51214.59 GB (66.0%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ... Time limit = 360s\n",
      "AutoGluon will save models to \"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250521_182903\"\n",
      "Train Data Rows:    2248\n",
      "Train Data Columns: 9\n",
      "Label Column:       player_class\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 10\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    338136.24 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.92 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['text', 'flavor']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 162\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])        : 3 | ['cost', 'attack', 'health']\n",
      "\t\t('object', [])       : 4 | ['type', 'name', 'set', 'rarity']\n",
      "\t\t('object', ['text']) : 2 | ['text', 'flavor']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    :   4 | ['type', 'name', 'set', 'rarity']\n",
      "\t\t('category', ['text_as_category'])  :   2 | ['text', 'flavor']\n",
      "\t\t('float', [])                       :   3 | ['cost', 'attack', 'health']\n",
      "\t\t('int', ['binned', 'text_special']) :  36 | ['text.char_count', 'text.word_count', 'text.capital_ratio', 'text.lower_ratio', 'text.digit_ratio', ...]\n",
      "\t\t('int', ['text_ngram'])             : 159 | ['__nlp__.about', '__nlp__.add', '__nlp__.after', '__nlp__.all', '__nlp__.all minions', ...]\n",
      "\t3.7s = Fit runtime\n",
      "\t9 features in original data used to generate 204 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.83 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 3.8s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 110 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 237.40s of the 356.17s of remaining time.\n",
      "\t0.621\t = Validation score   (accuracy)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t0.26s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 237.01s of the 355.77s of remaining time.\n",
      "\t0.6148\t = Validation score   (accuracy)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 236.79s of the 355.55s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.7015\t = Validation score   (accuracy)\n",
      "\t109.85s\t = Training   runtime\n",
      "\t0.31s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 124.13s of the 242.89s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.02%)\n",
      "\t0.7024\t = Validation score   (accuracy)\n",
      "\t131.86s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 356.20s of the 106.83s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetFastAI_BAG_L1': 0.571, 'LightGBMXT_BAG_L1': 0.429}\n",
      "\t0.7082\t = Validation score   (accuracy)\n",
      "\t0.14s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 108 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 106.66s of the 106.62s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.7015\t = Validation score   (accuracy)\n",
      "\t109.42s\t = Training   runtime\n",
      "\t0.41s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 356.20s of the -7.10s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.357, 'NeuralNetFastAI_BAG_L2': 0.357, 'NeuralNetFastAI_BAG_L1': 0.214, 'KNeighborsUnif_BAG_L1': 0.071}\n",
      "\t0.7144\t = Validation score   (accuracy)\n",
      "\t0.17s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 367.34s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 308.5 rows/s (281 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250521_182903\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250521_183515\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #53~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Jan 15 19:18:46 UTC 2\n",
      "CPU Count:          64\n",
      "Memory Avail:       324.42 GB / 503.54 GB (64.4%)\n",
      "Disk Space Avail:   33798.71 GB / 51214.59 GB (66.0%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ... Time limit = 360s\n",
      "AutoGluon will save models to \"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250521_183515\"\n",
      "Train Data Rows:    2248\n",
      "Train Data Columns: 6\n",
      "Label Column:       player_class\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 10\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    332211.89 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.42 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 3 | ['cost', 'attack', 'health']\n",
      "\t\t('object', []) : 3 | ['type', 'set', 'rarity']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) : 3 | ['type', 'set', 'rarity']\n",
      "\t\t('float', [])    : 3 | ['cost', 'attack', 'health']\n",
      "\t0.1s = Fit runtime\n",
      "\t6 features in original data used to generate 6 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.06 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.12s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 110 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 239.86s of the 359.85s of remaining time.\n",
      "\t0.6134\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 239.79s of the 359.78s of remaining time.\n",
      "\t0.6023\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 239.72s of the 359.71s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.6726\t = Validation score   (accuracy)\n",
      "\t107.58s\t = Training   runtime\n",
      "\t0.34s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 128.38s of the 248.38s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.01%)\n",
      "\t0.665\t = Validation score   (accuracy)\n",
      "\t134.97s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 359.88s of the 109.14s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetFastAI_BAG_L1': 1.0}\n",
      "\t0.6726\t = Validation score   (accuracy)\n",
      "\t0.16s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 108 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 108.95s of the 108.89s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.6708\t = Validation score   (accuracy)\n",
      "\t108.78s\t = Training   runtime\n",
      "\t0.32s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 359.88s of the -4.17s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetFastAI_BAG_L1': 1.0}\n",
      "\t0.6726\t = Validation score   (accuracy)\n",
      "\t0.2s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 364.43s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 814.0 rows/s (281 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250521_183515\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250521_184121\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #53~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Jan 15 19:18:46 UTC 2\n",
      "CPU Count:          64\n",
      "Memory Avail:       329.82 GB / 503.54 GB (65.5%)\n",
      "Disk Space Avail:   33798.43 GB / 51214.59 GB (66.0%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ... Time limit = 360s\n",
      "AutoGluon will save models to \"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250521_184121\"\n",
      "Train Data Rows:    2248\n",
      "Train Data Columns: 9\n",
      "Label Column:       player_class\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 10\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    337744.91 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.92 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['text', 'flavor']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 159\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])        : 3 | ['cost', 'attack', 'health']\n",
      "\t\t('object', [])       : 4 | ['type', 'name', 'set', 'rarity']\n",
      "\t\t('object', ['text']) : 2 | ['text', 'flavor']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    :   4 | ['type', 'name', 'set', 'rarity']\n",
      "\t\t('category', ['text_as_category'])  :   2 | ['text', 'flavor']\n",
      "\t\t('float', [])                       :   3 | ['cost', 'attack', 'health']\n",
      "\t\t('int', ['binned', 'text_special']) :  38 | ['text.char_count', 'text.word_count', 'text.capital_ratio', 'text.lower_ratio', 'text.digit_ratio', ...]\n",
      "\t\t('int', ['text_ngram'])             : 156 | ['__nlp__.10', '__nlp__.about', '__nlp__.add', '__nlp__.after', '__nlp__.all', ...]\n",
      "\t4.0s = Fit runtime\n",
      "\t9 features in original data used to generate 203 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.82 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 4.06s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 110 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 237.23s of the 355.92s of remaining time.\n",
      "\t0.609\t = Validation score   (accuracy)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 236.92s of the 355.60s of remaining time.\n",
      "\t0.6014\t = Validation score   (accuracy)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 236.72s of the 355.40s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.6922\t = Validation score   (accuracy)\n",
      "\t110.28s\t = Training   runtime\n",
      "\t0.32s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 122.34s of the 241.02s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.02%)\n",
      "\t0.6984\t = Validation score   (accuracy)\n",
      "\t129.59s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 355.94s of the 106.98s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetFastAI_BAG_L1': 0.5, 'LightGBMXT_BAG_L1': 0.455, 'KNeighborsUnif_BAG_L1': 0.045}\n",
      "\t0.7104\t = Validation score   (accuracy)\n",
      "\t0.16s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 108 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 106.78s of the 106.73s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.6975\t = Validation score   (accuracy)\n",
      "\t108.17s\t = Training   runtime\n",
      "\t0.3s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 355.94s of the -5.67s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.542, 'NeuralNetFastAI_BAG_L1': 0.292, 'NeuralNetFastAI_BAG_L2': 0.125, 'KNeighborsUnif_BAG_L1': 0.042}\n",
      "\t0.7109\t = Validation score   (accuracy)\n",
      "\t0.17s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 365.9s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 352.8 rows/s (281 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250521_184121\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250521_184731\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #53~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Jan 15 19:18:46 UTC 2\n",
      "CPU Count:          64\n",
      "Memory Avail:       331.77 GB / 503.54 GB (65.9%)\n",
      "Disk Space Avail:   33798.09 GB / 51214.59 GB (66.0%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ... Time limit = 360s\n",
      "AutoGluon will save models to \"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250521_184731\"\n",
      "Train Data Rows:    2248\n",
      "Train Data Columns: 6\n",
      "Label Column:       player_class\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 10\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    339727.34 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.42 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 3 | ['cost', 'attack', 'health']\n",
      "\t\t('object', []) : 3 | ['type', 'set', 'rarity']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) : 3 | ['type', 'set', 'rarity']\n",
      "\t\t('float', [])    : 3 | ['cost', 'attack', 'health']\n",
      "\t0.1s = Fit runtime\n",
      "\t6 features in original data used to generate 6 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.06 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.13s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 110 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 239.85s of the 359.85s of remaining time.\n",
      "\t0.6019\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 239.77s of the 359.76s of remaining time.\n",
      "\t0.5939\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 239.69s of the 359.68s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.6628\t = Validation score   (accuracy)\n",
      "\t106.05s\t = Training   runtime\n",
      "\t0.31s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 129.79s of the 249.78s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.01%)\n",
      "\t0.657\t = Validation score   (accuracy)\n",
      "\t134.75s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 359.87s of the 110.85s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetFastAI_BAG_L1': 1.0}\n",
      "\t0.6628\t = Validation score   (accuracy)\n",
      "\t0.14s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 108 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 110.69s of the 110.64s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.6624\t = Validation score   (accuracy)\n",
      "\t105.98s\t = Training   runtime\n",
      "\t0.31s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 359.87s of the 0.45s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetFastAI_BAG_L1': 0.5, 'NeuralNetFastAI_BAG_L2': 0.3, 'LightGBMXT_BAG_L1': 0.2}\n",
      "\t0.6664\t = Validation score   (accuracy)\n",
      "\t0.16s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 359.77s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 386.7 rows/s (281 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250521_184731\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250521_185335\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #53~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Jan 15 19:18:46 UTC 2\n",
      "CPU Count:          64\n",
      "Memory Avail:       324.88 GB / 503.54 GB (64.5%)\n",
      "Disk Space Avail:   33797.82 GB / 51214.59 GB (66.0%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ... Time limit = 360s\n",
      "AutoGluon will save models to \"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250521_185335\"\n",
      "Train Data Rows:    2248\n",
      "Train Data Columns: 9\n",
      "Label Column:       player_class\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 10\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    332699.45 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.91 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['text', 'flavor']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 167\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])        : 3 | ['cost', 'attack', 'health']\n",
      "\t\t('object', [])       : 4 | ['type', 'name', 'set', 'rarity']\n",
      "\t\t('object', ['text']) : 2 | ['text', 'flavor']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    :   4 | ['type', 'name', 'set', 'rarity']\n",
      "\t\t('category', ['text_as_category'])  :   2 | ['text', 'flavor']\n",
      "\t\t('float', [])                       :   3 | ['cost', 'attack', 'health']\n",
      "\t\t('int', ['binned', 'text_special']) :  38 | ['text.char_count', 'text.word_count', 'text.capital_ratio', 'text.lower_ratio', 'text.digit_ratio', ...]\n",
      "\t\t('int', ['text_ngram'])             : 164 | ['__nlp__.10', '__nlp__.about', '__nlp__.add', '__nlp__.after', '__nlp__.all', ...]\n",
      "\t4.7s = Fit runtime\n",
      "\t9 features in original data used to generate 211 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.86 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 4.72s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 110 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 236.79s of the 355.26s of remaining time.\n",
      "\t0.6174\t = Validation score   (accuracy)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 236.58s of the 355.05s of remaining time.\n",
      "\t0.6117\t = Validation score   (accuracy)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 236.38s of the 354.85s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.6984\t = Validation score   (accuracy)\n",
      "\t111.12s\t = Training   runtime\n",
      "\t0.38s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 121.33s of the 239.79s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.02%)\n",
      "\t0.706\t = Validation score   (accuracy)\n",
      "\t128.93s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 355.28s of the 106.32s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetFastAI_BAG_L1': 0.524, 'LightGBMXT_BAG_L1': 0.476}\n",
      "\t0.7126\t = Validation score   (accuracy)\n",
      "\t0.17s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 108 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 106.12s of the 106.07s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.6997\t = Validation score   (accuracy)\n",
      "\t109.32s\t = Training   runtime\n",
      "\t0.34s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 355.28s of the -7.55s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetFastAI_BAG_L1': 0.357, 'LightGBMXT_BAG_L1': 0.286, 'NeuralNetFastAI_BAG_L2': 0.214, 'KNeighborsUnif_BAG_L1': 0.071, 'KNeighborsDist_BAG_L1': 0.071}\n",
      "\t0.7175\t = Validation score   (accuracy)\n",
      "\t0.19s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 367.81s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 310.9 rows/s (281 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250521_185335\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250521_185946\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #53~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Jan 15 19:18:46 UTC 2\n",
      "CPU Count:          64\n",
      "Memory Avail:       323.37 GB / 503.54 GB (64.2%)\n",
      "Disk Space Avail:   33797.58 GB / 51214.59 GB (66.0%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ... Time limit = 360s\n",
      "AutoGluon will save models to \"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250521_185946\"\n",
      "Train Data Rows:    2248\n",
      "Train Data Columns: 6\n",
      "Label Column:       player_class\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 10\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    331085.04 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.42 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 3 | ['cost', 'attack', 'health']\n",
      "\t\t('object', []) : 3 | ['type', 'set', 'rarity']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) : 3 | ['type', 'set', 'rarity']\n",
      "\t\t('float', [])    : 3 | ['cost', 'attack', 'health']\n",
      "\t0.1s = Fit runtime\n",
      "\t6 features in original data used to generate 6 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.06 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.11s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 110 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 239.86s of the 359.85s of remaining time.\n",
      "\t0.5819\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 239.79s of the 359.78s of remaining time.\n",
      "\t0.573\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 239.71s of the 359.70s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.6681\t = Validation score   (accuracy)\n",
      "\t107.59s\t = Training   runtime\n",
      "\t0.28s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 128.26s of the 248.25s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.01%)\n",
      "\t0.6619\t = Validation score   (accuracy)\n",
      "\t134.09s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 359.88s of the 110.01s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetFastAI_BAG_L1': 1.0}\n",
      "\t0.6681\t = Validation score   (accuracy)\n",
      "\t0.14s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 108 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 109.84s of the 109.80s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.6668\t = Validation score   (accuracy)\n",
      "\t107.21s\t = Training   runtime\n",
      "\t0.24s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 359.88s of the -1.56s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetFastAI_BAG_L1': 1.0}\n",
      "\t0.6681\t = Validation score   (accuracy)\n",
      "\t0.17s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 361.78s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1015.6 rows/s (281 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250521_185946\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250521_190550\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #53~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Jan 15 19:18:46 UTC 2\n",
      "CPU Count:          64\n",
      "Memory Avail:       333.23 GB / 503.54 GB (66.2%)\n",
      "Disk Space Avail:   33797.38 GB / 51214.59 GB (66.0%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ... Time limit = 360s\n",
      "AutoGluon will save models to \"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250521_190550\"\n",
      "Train Data Rows:    2248\n",
      "Train Data Columns: 9\n",
      "Label Column:       player_class\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 10\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    342463.79 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.91 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['text', 'flavor']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 167\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])        : 3 | ['cost', 'attack', 'health']\n",
      "\t\t('object', [])       : 4 | ['type', 'name', 'set', 'rarity']\n",
      "\t\t('object', ['text']) : 2 | ['text', 'flavor']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    :   4 | ['type', 'name', 'set', 'rarity']\n",
      "\t\t('category', ['text_as_category'])  :   2 | ['text', 'flavor']\n",
      "\t\t('float', [])                       :   3 | ['cost', 'attack', 'health']\n",
      "\t\t('int', ['binned', 'text_special']) :  38 | ['text.char_count', 'text.word_count', 'text.capital_ratio', 'text.lower_ratio', 'text.digit_ratio', ...]\n",
      "\t\t('int', ['text_ngram'])             : 164 | ['__nlp__.10', '__nlp__.about', '__nlp__.add', '__nlp__.after', '__nlp__.all', ...]\n",
      "\t4.2s = Fit runtime\n",
      "\t9 features in original data used to generate 211 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.86 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 4.24s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 110 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 237.11s of the 355.73s of remaining time.\n",
      "\t0.6157\t = Validation score   (accuracy)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 236.89s of the 355.52s of remaining time.\n",
      "\t0.6161\t = Validation score   (accuracy)\n",
      "\t0.04s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 236.71s of the 355.33s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.7122\t = Validation score   (accuracy)\n",
      "\t109.05s\t = Training   runtime\n",
      "\t0.29s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 123.68s of the 242.30s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.02%)\n",
      "\t0.7144\t = Validation score   (accuracy)\n",
      "\t130.33s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 355.76s of the 107.71s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.526, 'NeuralNetFastAI_BAG_L1': 0.474}\n",
      "\t0.7229\t = Validation score   (accuracy)\n",
      "\t0.15s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 108 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 107.53s of the 107.48s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.7157\t = Validation score   (accuracy)\n",
      "\t107.14s\t = Training   runtime\n",
      "\t0.29s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 355.76s of the -3.89s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetFastAI_BAG_L2': 0.375, 'LightGBMXT_BAG_L1': 0.333, 'NeuralNetFastAI_BAG_L1': 0.292}\n",
      "\t0.7255\t = Validation score   (accuracy)\n",
      "\t0.17s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 364.13s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 380.8 rows/s (281 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250521_190550\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250521_191157\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #53~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Jan 15 19:18:46 UTC 2\n",
      "CPU Count:          64\n",
      "Memory Avail:       334.65 GB / 503.54 GB (66.5%)\n",
      "Disk Space Avail:   33795.96 GB / 51214.59 GB (66.0%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ... Time limit = 360s\n",
      "AutoGluon will save models to \"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250521_191157\"\n",
      "Train Data Rows:    2248\n",
      "Train Data Columns: 6\n",
      "Label Column:       player_class\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 10\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    342711.36 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.42 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 3 | ['cost', 'attack', 'health']\n",
      "\t\t('object', []) : 3 | ['type', 'set', 'rarity']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) : 3 | ['type', 'set', 'rarity']\n",
      "\t\t('float', [])    : 3 | ['cost', 'attack', 'health']\n",
      "\t0.1s = Fit runtime\n",
      "\t6 features in original data used to generate 6 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.06 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.13s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 110 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 239.85s of the 359.85s of remaining time.\n",
      "\t0.3995\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 239.78s of the 359.77s of remaining time.\n",
      "\t0.3919\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 239.71s of the 359.71s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.6784\t = Validation score   (accuracy)\n",
      "\t104.55s\t = Training   runtime\n",
      "\t0.26s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 131.40s of the 251.40s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.01%)\n",
      "\t0.6708\t = Validation score   (accuracy)\n",
      "\t135.83s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 359.87s of the 111.35s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetFastAI_BAG_L1': 0.952, 'LightGBMXT_BAG_L1': 0.048}\n",
      "\t0.6793\t = Validation score   (accuracy)\n",
      "\t0.14s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 108 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 111.18s of the 111.13s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.6726\t = Validation score   (accuracy)\n",
      "\t105.13s\t = Training   runtime\n",
      "\t0.27s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 359.87s of the 1.46s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetFastAI_BAG_L1': 0.6, 'NeuralNetFastAI_BAG_L2': 0.28, 'LightGBMXT_BAG_L1': 0.08, 'KNeighborsUnif_BAG_L1': 0.04}\n",
      "\t0.6824\t = Validation score   (accuracy)\n",
      "\t0.16s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 358.76s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 416.8 rows/s (281 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250521_191157\")\n"
     ]
    }
   ],
   "source": [
    "from baseline_eval import evaluate_baseline, plot_model_performance_summary\n",
    "results = evaluate_baseline(\n",
    "    df=loaded_df,\n",
    "    model='AGTabular',\n",
    "    df_name=dataset_config['dataset_name'],\n",
    "    label_col= dataset_config['target'],\n",
    "    task_type=dataset_config['task'],\n",
    "    textual_cols=textual_cols,\n",
    "    k_folds=5,\n",
    "    seed=0,\n",
    "    max_samples=10000,\n",
    "    output_path=f\"../../baseline_results/{dataset_config['task']}/{dataset_config['dataset_name']}.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a16626c-cd8c-48e3-95be-476a4976c393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving plot to ../../baseline_results/plots/clf/score\n",
      "Saving plot to ../../baseline_results/plots/clf/loss\n",
      "Saving plot to ../../baseline_results/plots/clf/roc_auc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score':                                    mean       std\n",
       " model                                            \n",
       " AutoGluon_Tabular_without_text  0.65516  0.027376\n",
       " AutoGluon_Tabular_with_text     0.70000  0.023390,\n",
       " 'loss':                                     mean       std\n",
       " model                                             \n",
       " AutoGluon_Tabular_with_text     1.066827  0.058750\n",
       " AutoGluon_Tabular_without_text  1.185922  0.070553,\n",
       " 'roc_auc':                                     mean       std\n",
       " model                                             \n",
       " AutoGluon_Tabular_without_text  0.774096  0.017523\n",
       " AutoGluon_Tabular_with_text     0.827878  0.006535}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs = pd.read_csv(f\"../../baseline_results/{dataset_config['task']}/{dataset_config['dataset_name']}.csv\")\n",
    "plot_model_performance_summary(name=dataset_config['dataset_name'],task=dataset_config['task'], df=rs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
