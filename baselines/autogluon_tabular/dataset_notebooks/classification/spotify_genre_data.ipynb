{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0200d09",
   "metadata": {},
   "source": [
    "### Let's start with downloading the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4d0c4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "# to reach the dataloader_functions module\n",
    "module_path = os.path.abspath(os.path.join( \"..\"))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from dataloader_functions.download_data import download_raw_data\n",
    "current_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b8103e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO update this section per dataset\n",
    "dataset_config = {\n",
    "    'dataset_name': 'spotfy_genre',\n",
    "    'source': 'kaggle', # ['kaggle', 'local', 'openml', 'hf']\n",
    "    'remote_path': 'maharshipandya/-spotify-tracks-dataset',\n",
    "    'files': ['dataset.csv'],\n",
    "    'rename_files': ['spotify_data.csv'],\n",
    "    'task': 'clf', # ['reg', 'clf']\n",
    "    'target': 'track_genre',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4336bfef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36mInfo:\u001b[0m Dataset already downloaded in \u001b[1;35m/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/../../datasets_files/raw/classification/spotfy_genre\u001b[0m.\n",
      "Downloaded spotfy_genre dataset to /home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/../../datasets_files/raw/classification/spotfy_genre\n"
     ]
    }
   ],
   "source": [
    "if dataset_config['task'] == 'clf':\n",
    "    dataset_subfolder = os.path.join('raw', 'classification', dataset_config['dataset_name']) \n",
    "elif dataset_config['task'] == 'reg':\n",
    "    dataset_subfolder = os.path.join('raw', 'regression', dataset_config['dataset_name'])\n",
    "else:\n",
    "    raise ValueError(f\"Unknown task: {dataset_config['task']}\")\n",
    "\n",
    "# this path needs to be modified based on the location of the notebook\n",
    "download_path = os.path.join(current_dir, '..', '..', 'datasets_files', dataset_subfolder)\n",
    "\n",
    "if download_raw_data(\n",
    "    dataset_config=dataset_config,\n",
    "    download_path=download_path,\n",
    "    force_download=False,\n",
    "    remove_unlisted=True,\n",
    ") is not None:\n",
    "    print(f\"Downloaded {dataset_config['dataset_name']} dataset to {download_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d886637",
   "metadata": {},
   "source": [
    "### Now we need to preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48bcaebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader_functions.load_and_pp_raw_data import _drop_empty_columns, _drop_single_value_columns\n",
    "from dataloader_functions.utils.data_2_df import read_any_to_df\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "current_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0861820c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading /home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/../../datasets_files/raw/classification/spotfy_genre/spotify_data.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>track_id</th>\n",
       "      <th>artists</th>\n",
       "      <th>album_name</th>\n",
       "      <th>track_name</th>\n",
       "      <th>popularity</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>explicit</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>track_genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5SuOikwiRyPMVoIQDJUgSV</td>\n",
       "      <td>Gen Hoshino</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>73</td>\n",
       "      <td>230666</td>\n",
       "      <td>False</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.461</td>\n",
       "      <td>1</td>\n",
       "      <td>-6.746</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1430</td>\n",
       "      <td>0.0322</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.715</td>\n",
       "      <td>87.917</td>\n",
       "      <td>4</td>\n",
       "      <td>acoustic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4qPNDBW1i3p13qLCt0Ki3A</td>\n",
       "      <td>Ben Woodward</td>\n",
       "      <td>Ghost (Acoustic)</td>\n",
       "      <td>Ghost - Acoustic</td>\n",
       "      <td>55</td>\n",
       "      <td>149610</td>\n",
       "      <td>False</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.166</td>\n",
       "      <td>1</td>\n",
       "      <td>-17.235</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0763</td>\n",
       "      <td>0.9240</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.267</td>\n",
       "      <td>77.489</td>\n",
       "      <td>4</td>\n",
       "      <td>acoustic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1iJBSr7s7jYXzM8EGcbK5b</td>\n",
       "      <td>Ingrid Michaelson;ZAYN</td>\n",
       "      <td>To Begin Again</td>\n",
       "      <td>To Begin Again</td>\n",
       "      <td>57</td>\n",
       "      <td>210826</td>\n",
       "      <td>False</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.359</td>\n",
       "      <td>0</td>\n",
       "      <td>-9.734</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0557</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.120</td>\n",
       "      <td>76.332</td>\n",
       "      <td>4</td>\n",
       "      <td>acoustic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                track_id                 artists  \\\n",
       "0           0  5SuOikwiRyPMVoIQDJUgSV             Gen Hoshino   \n",
       "1           1  4qPNDBW1i3p13qLCt0Ki3A            Ben Woodward   \n",
       "2           2  1iJBSr7s7jYXzM8EGcbK5b  Ingrid Michaelson;ZAYN   \n",
       "\n",
       "         album_name        track_name  popularity  duration_ms  explicit  \\\n",
       "0            Comedy            Comedy          73       230666     False   \n",
       "1  Ghost (Acoustic)  Ghost - Acoustic          55       149610     False   \n",
       "2    To Begin Again    To Begin Again          57       210826     False   \n",
       "\n",
       "   danceability  energy  key  loudness  mode  speechiness  acousticness  \\\n",
       "0         0.676   0.461    1    -6.746     0       0.1430        0.0322   \n",
       "1         0.420   0.166    1   -17.235     1       0.0763        0.9240   \n",
       "2         0.438   0.359    0    -9.734     1       0.0557        0.2100   \n",
       "\n",
       "   instrumentalness  liveness  valence   tempo  time_signature track_genre  \n",
       "0          0.000001     0.358    0.715  87.917               4    acoustic  \n",
       "1          0.000006     0.101    0.267  77.489               4    acoustic  \n",
       "2          0.000000     0.117    0.120  76.332               4    acoustic  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dataset_files_df = []\n",
    "\n",
    "if dataset_config['rename_files'] is None or len(dataset_config['rename_files']) == 0:\n",
    "    dataset_config['rename_files'] = dataset_config['files']\n",
    "\n",
    "for file in dataset_config['rename_files']:\n",
    "\n",
    "    file_location = os.path.join(download_path, file)\n",
    "\n",
    "    print(f\"Loading {file_location}\")\n",
    "\n",
    "    dataset_files_df.append(read_any_to_df(file_location))\n",
    "\n",
    "# example of the loaded df data:\n",
    "pd.set_option('display.max_columns', None)\n",
    "dataset_files_df[0].head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "866a0110-7374-4b7e-b57c-4de4c7e8ed2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before: (114000, 21), after: (10000, 21)\n"
     ]
    }
   ],
   "source": [
    "# there are way too many differnt targets -> downsample to 10 only\n",
    "target_genres = ['pop', 'rock', 'hip-hop', 'jazz', 'classical', 'metal', 'electronic', 'indie', 'r-n-b', 'country']\n",
    "for df in dataset_files_df:\n",
    "    shape_before = df.shape\n",
    "    # drop all rows which are not in the target_genres\n",
    "    df.drop(df[~df['track_genre'].isin(target_genres)].index, inplace=True)\n",
    "    print(f\"Shape before: {shape_before}, after: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d099b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped: Index([], dtype='object')\n",
      "Dataframe shape before/afrer cleaning: (10000, 21) / (10000, 20)\n"
     ]
    }
   ],
   "source": [
    "## Run some basic data cleaning\n",
    "\n",
    "dataset_files_gen_cleaned = []\n",
    "missing_ratio_threshold = 0.5 # TODO the threshold can be changed\n",
    "\n",
    "for df_file in dataset_files_df:\n",
    "    df_size = df_file.shape\n",
    "    # 1. Drop columns with more than 50% missing values\n",
    "    df_file = _drop_empty_columns(df_file, threshold=missing_ratio_threshold)   \n",
    "    # 2. Drop columns with only one unique value\n",
    "    df_file = _drop_single_value_columns(df_file)\n",
    "    # 3. remove duplicates\n",
    "    df_file = df_file.drop_duplicates()\n",
    "    # 4. remove rows with missing target values\n",
    "    df_file = df_file[df_file[dataset_config['target']].notna()]\n",
    "    # 5. drop unnamed columns\n",
    "    df_file = df_file.loc[:, ~df_file.columns.str.contains('^Unnamed')]\n",
    "\n",
    "    dataset_files_gen_cleaned.append(df_file)\n",
    "\n",
    "    print(f\"Dataframe shape before/afrer cleaning: {df_size} / {df_file.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0a2a11a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe shape before/afrer by-hand cleaning: (10000, 20) / (10000, 19)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artists</th>\n",
       "      <th>album_name</th>\n",
       "      <th>track_name</th>\n",
       "      <th>popularity</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>explicit</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>track_genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16000</th>\n",
       "      <td>Bombay Jayashri</td>\n",
       "      <td>Rehnaa Hai Terre Dil Mein</td>\n",
       "      <td>Zara Zara</td>\n",
       "      <td>58</td>\n",
       "      <td>298266</td>\n",
       "      <td>False</td>\n",
       "      <td>0.643</td>\n",
       "      <td>0.268</td>\n",
       "      <td>11</td>\n",
       "      <td>-15.073</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0900</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.316</td>\n",
       "      <td>0.620</td>\n",
       "      <td>143.813</td>\n",
       "      <td>4</td>\n",
       "      <td>classical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16001</th>\n",
       "      <td>Shankar;Ehsaan;Loy;Alisha Chinai;Shankar Mahad...</td>\n",
       "      <td>Bunty Aur Babli</td>\n",
       "      <td>Kajra Re</td>\n",
       "      <td>59</td>\n",
       "      <td>482586</td>\n",
       "      <td>False</td>\n",
       "      <td>0.484</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.132</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1640</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.680</td>\n",
       "      <td>91.975</td>\n",
       "      <td>4</td>\n",
       "      <td>classical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16002</th>\n",
       "      <td>Bombay Jayashri;DJ Aftab</td>\n",
       "      <td>Hindi Slowed Reverb Bollywood Lofi</td>\n",
       "      <td>Zara Zara - Lofi</td>\n",
       "      <td>54</td>\n",
       "      <td>219437</td>\n",
       "      <td>False</td>\n",
       "      <td>0.608</td>\n",
       "      <td>0.638</td>\n",
       "      <td>11</td>\n",
       "      <td>-6.008</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0292</td>\n",
       "      <td>0.581</td>\n",
       "      <td>0.017200</td>\n",
       "      <td>0.448</td>\n",
       "      <td>0.439</td>\n",
       "      <td>140.109</td>\n",
       "      <td>4</td>\n",
       "      <td>classical</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 artists  \\\n",
       "16000                                    Bombay Jayashri   \n",
       "16001  Shankar;Ehsaan;Loy;Alisha Chinai;Shankar Mahad...   \n",
       "16002                           Bombay Jayashri;DJ Aftab   \n",
       "\n",
       "                               album_name        track_name  popularity  \\\n",
       "16000           Rehnaa Hai Terre Dil Mein         Zara Zara          58   \n",
       "16001                     Bunty Aur Babli          Kajra Re          59   \n",
       "16002  Hindi Slowed Reverb Bollywood Lofi  Zara Zara - Lofi          54   \n",
       "\n",
       "       duration_ms  explicit  danceability  energy  key  loudness  mode  \\\n",
       "16000       298266     False         0.643   0.268   11   -15.073     0   \n",
       "16001       482586     False         0.484   0.898    0    -4.132     1   \n",
       "16002       219437     False         0.608   0.638   11    -6.008     0   \n",
       "\n",
       "       speechiness  acousticness  instrumentalness  liveness  valence  \\\n",
       "16000       0.0900         0.593          0.000002     0.316    0.620   \n",
       "16001       0.1640         0.365          0.000000     0.091    0.680   \n",
       "16002       0.0292         0.581          0.017200     0.448    0.439   \n",
       "\n",
       "         tempo  time_signature track_genre  \n",
       "16000  143.813               4   classical  \n",
       "16001   91.975               4   classical  \n",
       "16002  140.109               4   classical  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## TODO: Now run custom data cleaning -> remove non-essential columns\n",
    "\n",
    "cols_to_drop = ['track_id']\n",
    "\n",
    "dataset_files_cleaned = []\n",
    "\n",
    "# assuming for multiple files we still want to drop the same columns\n",
    "for df_file in dataset_files_gen_cleaned:\n",
    "    df_size = df_file.shape\n",
    "    for col in cols_to_drop:\n",
    "        if col in df_file.columns:\n",
    "            df_file.drop(col, axis=1, inplace=True)\n",
    "        else:\n",
    "            print(f\"Column {col} not found in dataframe\")\n",
    "\n",
    "    dataset_files_cleaned.append(df_file)    \n",
    "    print(f\"Dataframe shape before/afrer by-hand cleaning: {df_size} / {df_file.shape}\")\n",
    "\n",
    "dataset_files_cleaned[0].head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d90a681b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe shape before custom cleaning: (10000, 19)\n",
      "Dataframe shape after custom clearning: (10000, 19)\n"
     ]
    }
   ],
   "source": [
    "# TODO: some custom data cleaning\n",
    "\n",
    "import copy \n",
    "tmp_df = copy.deepcopy(dataset_files_cleaned)\n",
    "dataset_files_by_hand_cleaned = []\n",
    "\n",
    "for df_file in dataset_files_cleaned:\n",
    "    print(f\"Dataframe shape before custom cleaning: {df_file.shape}\")\n",
    "    # TODO: add custom data cleaning here\n",
    "    # e.g. remove columns with too many unique values\n",
    "    print(f\"Dataframe shape after custom clearning: {df_file.shape}\")\n",
    "\n",
    "    dataset_files_by_hand_cleaned.append(df_file)\n",
    "\n",
    "# reset the dataframe list to the version before custom cleaning -> next cells work wuth dataset_files_by_hand_cleaned\n",
    "dataset_files_cleaned = tmp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581b17e1",
   "metadata": {},
   "source": [
    "### Now it is time to visualize our changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1500c210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artists</th>\n",
       "      <th>album_name</th>\n",
       "      <th>track_name</th>\n",
       "      <th>popularity</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>explicit</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>track_genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16000</th>\n",
       "      <td>Bombay Jayashri</td>\n",
       "      <td>Rehnaa Hai Terre Dil Mein</td>\n",
       "      <td>Zara Zara</td>\n",
       "      <td>58</td>\n",
       "      <td>298266</td>\n",
       "      <td>False</td>\n",
       "      <td>0.643</td>\n",
       "      <td>0.268</td>\n",
       "      <td>11</td>\n",
       "      <td>-15.073</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0900</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.316</td>\n",
       "      <td>0.620</td>\n",
       "      <td>143.813</td>\n",
       "      <td>4</td>\n",
       "      <td>classical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16001</th>\n",
       "      <td>Shankar;Ehsaan;Loy;Alisha Chinai;Shankar Mahad...</td>\n",
       "      <td>Bunty Aur Babli</td>\n",
       "      <td>Kajra Re</td>\n",
       "      <td>59</td>\n",
       "      <td>482586</td>\n",
       "      <td>False</td>\n",
       "      <td>0.484</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.132</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1640</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.680</td>\n",
       "      <td>91.975</td>\n",
       "      <td>4</td>\n",
       "      <td>classical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16002</th>\n",
       "      <td>Bombay Jayashri;DJ Aftab</td>\n",
       "      <td>Hindi Slowed Reverb Bollywood Lofi</td>\n",
       "      <td>Zara Zara - Lofi</td>\n",
       "      <td>54</td>\n",
       "      <td>219437</td>\n",
       "      <td>False</td>\n",
       "      <td>0.608</td>\n",
       "      <td>0.638</td>\n",
       "      <td>11</td>\n",
       "      <td>-6.008</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0292</td>\n",
       "      <td>0.581</td>\n",
       "      <td>0.017200</td>\n",
       "      <td>0.448</td>\n",
       "      <td>0.439</td>\n",
       "      <td>140.109</td>\n",
       "      <td>4</td>\n",
       "      <td>classical</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 artists  \\\n",
       "16000                                    Bombay Jayashri   \n",
       "16001  Shankar;Ehsaan;Loy;Alisha Chinai;Shankar Mahad...   \n",
       "16002                           Bombay Jayashri;DJ Aftab   \n",
       "\n",
       "                               album_name        track_name  popularity  \\\n",
       "16000           Rehnaa Hai Terre Dil Mein         Zara Zara          58   \n",
       "16001                     Bunty Aur Babli          Kajra Re          59   \n",
       "16002  Hindi Slowed Reverb Bollywood Lofi  Zara Zara - Lofi          54   \n",
       "\n",
       "       duration_ms  explicit  danceability  energy  key  loudness  mode  \\\n",
       "16000       298266     False         0.643   0.268   11   -15.073     0   \n",
       "16001       482586     False         0.484   0.898    0    -4.132     1   \n",
       "16002       219437     False         0.608   0.638   11    -6.008     0   \n",
       "\n",
       "       speechiness  acousticness  instrumentalness  liveness  valence  \\\n",
       "16000       0.0900         0.593          0.000002     0.316    0.620   \n",
       "16001       0.1640         0.365          0.000000     0.091    0.680   \n",
       "16002       0.0292         0.581          0.017200     0.448    0.439   \n",
       "\n",
       "         tempo  time_signature track_genre  \n",
       "16000  143.813               4   classical  \n",
       "16001   91.975               4   classical  \n",
       "16002  140.109               4   classical  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "dataset_files_by_hand_cleaned[0].head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f71269d",
   "metadata": {},
   "source": [
    "Let's figure out which columns should be viewed as categorical / numerical / textual\n",
    "\n",
    "we can start with a simple heuristic:\n",
    "1. numerical is everything which\n",
    "    - keeps most of its character length after non-numeral strip\n",
    "    - has about the same number of unique values after the strip\n",
    "    + for the purpose of keeping \"semantic information\", hand picked columns can be viewed also as non-numerical, that is not the default benchmark approach though\n",
    "\n",
    "2. categorical is everthing non numerical, which can be then divided into N (where N << Num instances) unique categories\n",
    "\n",
    "3. textual is everything else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "436f9ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Threshold for categorical vs textual: 50\n",
      "Numerical columns (11): ['popularity', 'duration_ms', 'danceability', 'energy', 'loudness', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']\n",
      "Categorical columns (5): ['explicit', 'key', 'mode', 'time_signature', 'track_genre']\n",
      "Textual columns (3): ['artists', 'album_name', 'track_name']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def is_mostly_numeric(series, length_threshold=0.5, unique_threshold=0.8):\n",
    "    \"\"\"Check if column is mostly numeric after stripping non-numeric chars.\"\"\"\n",
    "    stripped = series.astype(str).str.replace(r\"[^\\d\\.\\-]\", \"\", regex=True)\n",
    "    \n",
    "    original_len = series.astype(str).str.len().replace(0, 1)  # avoid div by zero\n",
    "    length_ratio = (stripped.str.len() / original_len).mean()\n",
    "\n",
    "    unique_ratio = stripped.nunique(dropna=False) / max(series.nunique(dropna=False), 1)\n",
    "\n",
    "    return length_ratio > length_threshold and unique_ratio > unique_threshold\n",
    "\n",
    "def classify_columns(df, unique_ratio_threshold=None, explicit_nunique_threshold=None):\n",
    "    \"\"\"\n",
    "    Classify dataframe columns into numerical, categorical, textual.\n",
    "    - Binary categorical (2 unique values) is considered categorical.\n",
    "    \"\"\"\n",
    "    n_rows = len(df)\n",
    "\n",
    "    # Determine threshold for categorical vs textual\n",
    "    if explicit_nunique_threshold is not None:\n",
    "        nunique_threshold = explicit_nunique_threshold\n",
    "    elif unique_ratio_threshold is not None:\n",
    "        nunique_threshold = int(unique_ratio_threshold * n_rows)\n",
    "    else:\n",
    "        nunique_threshold = int(0.05 * n_rows)  # default 5%\n",
    "\n",
    "    nunique_threshold = max(10, nunique_threshold)  # safeguard\n",
    "    print(f\"Threshold for categorical vs textual: {nunique_threshold}\")\n",
    "\n",
    "    numerical_cols = []\n",
    "    categorical_cols = []\n",
    "    textual_cols = []\n",
    "\n",
    "    for col in df.columns:\n",
    "        series = df[col]\n",
    "        nunique = series.nunique(dropna=False)\n",
    "\n",
    "        if pd.api.types.is_numeric_dtype(series):\n",
    "            if nunique <= nunique_threshold:\n",
    "                categorical_cols.append(col)\n",
    "            else:\n",
    "                numerical_cols.append(col)\n",
    "        \n",
    "        elif pd.api.types.is_string_dtype(series) or pd.api.types.is_object_dtype(series):\n",
    "            if is_mostly_numeric(series):\n",
    "                numerical_cols.append(col)\n",
    "            else:\n",
    "                if nunique <= nunique_threshold:\n",
    "                    categorical_cols.append(col)\n",
    "                else:\n",
    "                    textual_cols.append(col)\n",
    "        else:\n",
    "            print(f\"⚠️ Unhandled column type: '{col}' (dtype={series.dtype})\")\n",
    "\n",
    "    print(f\"Numerical columns ({len(numerical_cols)}): {numerical_cols}\")\n",
    "    print(f\"Categorical columns ({len(categorical_cols)}): {categorical_cols}\")\n",
    "    print(f\"Textual columns ({len(textual_cols)}): {textual_cols}\")\n",
    "\n",
    "    return numerical_cols, categorical_cols, textual_cols\n",
    "\n",
    "# Example usage:\n",
    "for df_file in dataset_files_by_hand_cleaned:\n",
    "    # Ratio-based (5% of rows)\n",
    "    # umerical_cols, categorical_cols, textual_cols = classify_columns(df_file, unique_ratio_threshold=0.05)\n",
    "    print(\"\")\n",
    "    # OR explicit value (e.g., anything <= 50 is categorical)\n",
    "    numerical_cols, categorical_cols, textual_cols = classify_columns(df_file, explicit_nunique_threshold=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6499589b",
   "metadata": {},
   "source": [
    "Now let's just try to visualize the kept features, their example values, and their cat/num/text allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afffbdb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column Name</th>\n",
       "      <th>Example Value</th>\n",
       "      <th>Type</th>\n",
       "      <th># Categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>artists</td>\n",
       "      <td>Bombay Jayashri</td>\n",
       "      <td>textual</td>\n",
       "      <td>3503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>album_name</td>\n",
       "      <td>Rehnaa Hai Terre Dil Mein</td>\n",
       "      <td>textual</td>\n",
       "      <td>4329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>track_name</td>\n",
       "      <td>Zara Zara</td>\n",
       "      <td>textual</td>\n",
       "      <td>6827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>popularity</td>\n",
       "      <td>58</td>\n",
       "      <td>numerical</td>\n",
       "      <td>~ 100 ~</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>duration_ms</td>\n",
       "      <td>298266</td>\n",
       "      <td>numerical</td>\n",
       "      <td>~ 6476 ~</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>explicit</td>\n",
       "      <td>False</td>\n",
       "      <td>categorical</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>danceability</td>\n",
       "      <td>0.643</td>\n",
       "      <td>numerical</td>\n",
       "      <td>~ 812 ~</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>energy</td>\n",
       "      <td>0.268</td>\n",
       "      <td>numerical</td>\n",
       "      <td>~ 1212 ~</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>key</td>\n",
       "      <td>11</td>\n",
       "      <td>categorical</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>loudness</td>\n",
       "      <td>-15.073</td>\n",
       "      <td>numerical</td>\n",
       "      <td>~ 5515 ~</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mode</td>\n",
       "      <td>0</td>\n",
       "      <td>categorical</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>speechiness</td>\n",
       "      <td>0.09</td>\n",
       "      <td>numerical</td>\n",
       "      <td>~ 1051 ~</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>acousticness</td>\n",
       "      <td>0.593</td>\n",
       "      <td>numerical</td>\n",
       "      <td>~ 2418 ~</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>instrumentalness</td>\n",
       "      <td>2.06e-06</td>\n",
       "      <td>numerical</td>\n",
       "      <td>~ 2683 ~</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>liveness</td>\n",
       "      <td>0.316</td>\n",
       "      <td>numerical</td>\n",
       "      <td>~ 1235 ~</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>valence</td>\n",
       "      <td>0.62</td>\n",
       "      <td>numerical</td>\n",
       "      <td>~ 1166 ~</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>tempo</td>\n",
       "      <td>143.813</td>\n",
       "      <td>numerical</td>\n",
       "      <td>~ 6542 ~</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>time_signature</td>\n",
       "      <td>4</td>\n",
       "      <td>categorical</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>track_genre</td>\n",
       "      <td>classical</td>\n",
       "      <td>categorical</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Column Name              Example Value         Type # Categories\n",
       "0            artists            Bombay Jayashri      textual         3503\n",
       "1         album_name  Rehnaa Hai Terre Dil Mein      textual         4329\n",
       "2         track_name                  Zara Zara      textual         6827\n",
       "3         popularity                         58    numerical      ~ 100 ~\n",
       "4        duration_ms                     298266    numerical     ~ 6476 ~\n",
       "5           explicit                      False  categorical            2\n",
       "6       danceability                      0.643    numerical      ~ 812 ~\n",
       "7             energy                      0.268    numerical     ~ 1212 ~\n",
       "8                key                         11  categorical           12\n",
       "9           loudness                    -15.073    numerical     ~ 5515 ~\n",
       "10              mode                          0  categorical            2\n",
       "11       speechiness                       0.09    numerical     ~ 1051 ~\n",
       "12      acousticness                      0.593    numerical     ~ 2418 ~\n",
       "13  instrumentalness                   2.06e-06    numerical     ~ 2683 ~\n",
       "14          liveness                      0.316    numerical     ~ 1235 ~\n",
       "15           valence                       0.62    numerical     ~ 1166 ~\n",
       "16             tempo                    143.813    numerical     ~ 6542 ~\n",
       "17    time_signature                          4  categorical            5\n",
       "18       track_genre                  classical  categorical           10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary = []\n",
    "for col in df_file.columns:\n",
    "    if col in categorical_cols:\n",
    "        col_type = \"categorical\"\n",
    "        num_categories = df_file[col].nunique(dropna=True)\n",
    "        num_categories_display = int(num_categories)\n",
    "    elif col in textual_cols:\n",
    "        col_type = \"textual\"\n",
    "        num_categories = df_file[col].nunique(dropna=True)\n",
    "        num_categories_display = int(num_categories)\n",
    "    elif col in numerical_cols:\n",
    "        col_type = \"numerical\"\n",
    "        num_categories = df_file[col].nunique(dropna=True)\n",
    "        num_categories_display = '~ ' + str(num_categories) + ' ~'\n",
    "    else:\n",
    "        col_type = \"unknown\"\n",
    "        num_categories_display = '--'\n",
    "\n",
    "    example = df_file[col].dropna().iloc[0] if df_file[col].dropna().size > 0 else None\n",
    "    summary.append({\n",
    "        'Column Name': col,\n",
    "        'Example Value': str(example),\n",
    "        'Type': col_type,\n",
    "        '# Categories': num_categories_display\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary)\n",
    "\n",
    "# TODO: by hand changes of the type and category count -> e.g. for 'Location':\n",
    "#    # Post-processing: override the type and category count for 'Location'\n",
    "#    # summary_df.loc[summary_df['Column Name'] == 'Location', 'Type'] = 'textual'\n",
    "#    # num_categories = df_file['Location'].nunique(dropna=True)\n",
    "#    # summary_df.loc[summary_df['Column Name'] == 'Location', '# Categories'] = int(num_categories)\n",
    "\n",
    "display(summary_df)  # Or print(summary_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ef8954",
   "metadata": {},
   "source": [
    "### Saving the processed data and loading it back up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2fe5eab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/../../datasets_files/raw/classification/spotfy_genre/spotify_data_processed.pkl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Handle rename_files fallback\n",
    "if dataset_config['rename_files'] is None or len(dataset_config['rename_files']) == 0:\n",
    "    dataset_config['rename_files'] = dataset_config['files']\n",
    "\n",
    "for i, df_file in enumerate(dataset_files_by_hand_cleaned):\n",
    "    df_with_meta = df_file.copy()\n",
    "\n",
    "    # Get corresponding file name\n",
    "    file_name = dataset_config['rename_files'][i]\n",
    "    file_base = os.path.splitext(file_name)[0]\n",
    "\n",
    "    # Try assigning multi-index header from summary\n",
    "    try:\n",
    "        df_with_meta.columns = pd.MultiIndex.from_frame(\n",
    "            summary_df[['Column Name', 'Type', '# Categories']]\n",
    "        )\n",
    "        local_summary = summary_df.copy()\n",
    "    except ValueError:\n",
    "        local_summary = summary_df.copy()\n",
    "        if dataset_config['target'] in local_summary['Column Name'].values:\n",
    "            local_summary = local_summary[local_summary['Column Name'] != dataset_config['target']]\n",
    "            df_with_meta.columns = pd.MultiIndex.from_frame(\n",
    "                local_summary[['Column Name', 'Type', '# Categories']]\n",
    "            )\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "    # Construct and save everything together\n",
    "    output_filename = f\"{file_base}_processed.pkl\"\n",
    "    output_path = os.path.join(download_path, output_filename)\n",
    "\n",
    "    save_bundle = {\n",
    "        'data': df_with_meta,\n",
    "        'summary': local_summary,\n",
    "        'config': dataset_config\n",
    "    }\n",
    "\n",
    "    pd.to_pickle(save_bundle, output_path)\n",
    "    print(f\"Saved: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c7bcd87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SPOTIFY_DATA ===\n",
      "Loaded config keys: ['dataset_name', 'source', 'remote_path', 'files', 'rename_files', 'task', 'target']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column Name</th>\n",
       "      <th>Type</th>\n",
       "      <th># Categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>artists</td>\n",
       "      <td>textual</td>\n",
       "      <td>3503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>album_name</td>\n",
       "      <td>textual</td>\n",
       "      <td>4329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>track_name</td>\n",
       "      <td>textual</td>\n",
       "      <td>6827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>popularity</td>\n",
       "      <td>numerical</td>\n",
       "      <td>~ 100 ~</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>duration_ms</td>\n",
       "      <td>numerical</td>\n",
       "      <td>~ 6476 ~</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>explicit</td>\n",
       "      <td>categorical</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>danceability</td>\n",
       "      <td>numerical</td>\n",
       "      <td>~ 812 ~</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>energy</td>\n",
       "      <td>numerical</td>\n",
       "      <td>~ 1212 ~</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>key</td>\n",
       "      <td>categorical</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>loudness</td>\n",
       "      <td>numerical</td>\n",
       "      <td>~ 5515 ~</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mode</td>\n",
       "      <td>categorical</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>speechiness</td>\n",
       "      <td>numerical</td>\n",
       "      <td>~ 1051 ~</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>acousticness</td>\n",
       "      <td>numerical</td>\n",
       "      <td>~ 2418 ~</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>instrumentalness</td>\n",
       "      <td>numerical</td>\n",
       "      <td>~ 2683 ~</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>liveness</td>\n",
       "      <td>numerical</td>\n",
       "      <td>~ 1235 ~</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>valence</td>\n",
       "      <td>numerical</td>\n",
       "      <td>~ 1166 ~</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>tempo</td>\n",
       "      <td>numerical</td>\n",
       "      <td>~ 6542 ~</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>time_signature</td>\n",
       "      <td>categorical</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>track_genre</td>\n",
       "      <td>categorical</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Column Name         Type # Categories\n",
       "0            artists      textual         3503\n",
       "1         album_name      textual         4329\n",
       "2         track_name      textual         6827\n",
       "3         popularity    numerical      ~ 100 ~\n",
       "4        duration_ms    numerical     ~ 6476 ~\n",
       "5           explicit  categorical            2\n",
       "6       danceability    numerical      ~ 812 ~\n",
       "7             energy    numerical     ~ 1212 ~\n",
       "8                key  categorical           12\n",
       "9           loudness    numerical     ~ 5515 ~\n",
       "10              mode  categorical            2\n",
       "11       speechiness    numerical     ~ 1051 ~\n",
       "12      acousticness    numerical     ~ 2418 ~\n",
       "13  instrumentalness    numerical     ~ 2683 ~\n",
       "14          liveness    numerical     ~ 1235 ~\n",
       "15           valence    numerical     ~ 1166 ~\n",
       "16             tempo    numerical     ~ 6542 ~\n",
       "17    time_signature  categorical            5\n",
       "18       track_genre  categorical           10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Column Name</th>\n",
       "      <th>artists</th>\n",
       "      <th>album_name</th>\n",
       "      <th>track_name</th>\n",
       "      <th>popularity</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>explicit</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>track_genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16000</th>\n",
       "      <td>Bombay Jayashri</td>\n",
       "      <td>Rehnaa Hai Terre Dil Mein</td>\n",
       "      <td>Zara Zara</td>\n",
       "      <td>58</td>\n",
       "      <td>298266</td>\n",
       "      <td>False</td>\n",
       "      <td>0.643</td>\n",
       "      <td>0.268</td>\n",
       "      <td>11</td>\n",
       "      <td>-15.073</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0900</td>\n",
       "      <td>0.593</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.316</td>\n",
       "      <td>0.620</td>\n",
       "      <td>143.813</td>\n",
       "      <td>4</td>\n",
       "      <td>classical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16001</th>\n",
       "      <td>Shankar;Ehsaan;Loy;Alisha Chinai;Shankar Mahad...</td>\n",
       "      <td>Bunty Aur Babli</td>\n",
       "      <td>Kajra Re</td>\n",
       "      <td>59</td>\n",
       "      <td>482586</td>\n",
       "      <td>False</td>\n",
       "      <td>0.484</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0</td>\n",
       "      <td>-4.132</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1640</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.680</td>\n",
       "      <td>91.975</td>\n",
       "      <td>4</td>\n",
       "      <td>classical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16002</th>\n",
       "      <td>Bombay Jayashri;DJ Aftab</td>\n",
       "      <td>Hindi Slowed Reverb Bollywood Lofi</td>\n",
       "      <td>Zara Zara - Lofi</td>\n",
       "      <td>54</td>\n",
       "      <td>219437</td>\n",
       "      <td>False</td>\n",
       "      <td>0.608</td>\n",
       "      <td>0.638</td>\n",
       "      <td>11</td>\n",
       "      <td>-6.008</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0292</td>\n",
       "      <td>0.581</td>\n",
       "      <td>0.017200</td>\n",
       "      <td>0.448</td>\n",
       "      <td>0.439</td>\n",
       "      <td>140.109</td>\n",
       "      <td>4</td>\n",
       "      <td>classical</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Column Name                                            artists  \\\n",
       "16000                                          Bombay Jayashri   \n",
       "16001        Shankar;Ehsaan;Loy;Alisha Chinai;Shankar Mahad...   \n",
       "16002                                 Bombay Jayashri;DJ Aftab   \n",
       "\n",
       "Column Name                          album_name        track_name  popularity  \\\n",
       "16000                 Rehnaa Hai Terre Dil Mein         Zara Zara          58   \n",
       "16001                           Bunty Aur Babli          Kajra Re          59   \n",
       "16002        Hindi Slowed Reverb Bollywood Lofi  Zara Zara - Lofi          54   \n",
       "\n",
       "Column Name  duration_ms  explicit  danceability  energy  key  loudness  mode  \\\n",
       "16000             298266     False         0.643   0.268   11   -15.073     0   \n",
       "16001             482586     False         0.484   0.898    0    -4.132     1   \n",
       "16002             219437     False         0.608   0.638   11    -6.008     0   \n",
       "\n",
       "Column Name  speechiness  acousticness  instrumentalness  liveness  valence  \\\n",
       "16000             0.0900         0.593          0.000002     0.316    0.620   \n",
       "16001             0.1640         0.365          0.000000     0.091    0.680   \n",
       "16002             0.0292         0.581          0.017200     0.448    0.439   \n",
       "\n",
       "Column Name    tempo  time_signature track_genre  \n",
       "16000        143.813               4   classical  \n",
       "16001         91.975               4   classical  \n",
       "16002        140.109               4   classical  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Loop through processed files in rename_files\n",
    "for file_name in dataset_config['rename_files']:\n",
    "    # Remove .csv or .tsv extension to get the base name\n",
    "    file_base = os.path.splitext(file_name)[0]\n",
    "    processed_filename = f\"{file_base}_processed.pkl\"\n",
    "    processed_path = os.path.join(download_path, processed_filename)\n",
    "\n",
    "    # Load the bundled dictionary (data + summary + config)\n",
    "    bundle = pd.read_pickle(processed_path)\n",
    "\n",
    "    # Extract components\n",
    "    loaded_df = bundle['data']\n",
    "    summary_df = bundle['summary']\n",
    "    loaded_config = bundle['config']\n",
    "\n",
    "    print(f\"\\n=== {file_base.upper()} ===\")\n",
    "    print(f\"Loaded config keys: {list(loaded_config.keys())}\")\n",
    "\n",
    "    # Show metadata\n",
    "    meta_df = pd.DataFrame(loaded_df.columns.tolist(), columns=['Column Name', 'Type', '# Categories'])\n",
    "    display(meta_df)\n",
    "\n",
    "    # Flatten for modeling\n",
    "    loaded_df.columns = loaded_df.columns.get_level_values(0)\n",
    "    display(loaded_df.head(n=3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba2546a",
   "metadata": {},
   "source": [
    "### Bonus insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8914fd98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target values: ['classical', 'country', 'electronic', 'hip-hop', 'indie', 'jazz', 'metal', 'pop', 'r-n-b', 'rock']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, \"Distribution of 'track_genre' target\")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0cAAAJaCAYAAADkhTxyAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAAXgdJREFUeJzt3XdclfX///HnAWWIDDUBMUMcqRjuRZqakos004Zm5tZP7qwcmbtcH3PmRy23qZmW5ij3yr1x4cxVipoIiBu4fn/443w9AgoEnAM+7rfbud087+t9rut13iDwPO/rel8mwzAMAQAAAMBzzs7aBQAAAACALSAcAQAAAIAIRwAAAAAgiXAEAAAAAJIIRwAAAAAgiXAEAAAAAJIIRwAAAAAgiXAEAAAAAJIIRwAAAAAgiXAEIIsbPHiwTCZThhyrZs2aqlmzpvn55s2bZTKZtGTJkgw5fuvWrVWwYMEMOVZqRUdHq3379vL29pbJZFLPnj2tXVKK1KxZU6+88oq1ywAApBPCEYBMY/bs2TKZTOaHk5OTfHx8VLduXU2cOFG3bt1Kk+NcvnxZgwcP1qFDh9Jkf2nJlmtLjuHDh2v27Nn6+OOPNW/ePLVs2TLJvgULFtTgwYPNz48fP67Bgwfr/Pnz6V8onmrw4MHJCuILFizQ+PHj072etJLZ6gWQ9ghHADKdoUOHat68eZoyZYq6desmSerZs6cCAgJ0+PBhi75ffvml7t69m6L9X758WUOGDElxAFm7dq3Wrl2botek1NNq+/7773Xy5Ml0Pf6/tXHjRlWpUkWDBg3Shx9+qPLlyyf7tcePH9eQIUMIR5lIZgsbma1eAGkvm7ULAICUql+/vipUqGB+3q9fP23cuFFvvvmmGjVqpNDQUDk7O0uSsmXLpmzZ0vdH3Z07d5QjRw45ODik63GeJXv27FY9fnJcu3ZN/v7+6X4cwzB079498/cBnu727dtycXGxdhnJEhMTo7i4OKv/fwOQNTFzBCBLqFWrlgYMGKALFy7ohx9+MLcnds3RunXrVK1aNXl4eChnzpwqVqyYvvjiC0mPrhOqWLGiJKlNmzbmU/hmz54t6f+uOdm/f7+qV6+uHDlymF/75DVH8WJjY/XFF1/I29tbLi4uatSokS5dumTRp2DBgmrdunWC1z6+z2fVltg1R7dv39ann36qAgUKyNHRUcWKFdOYMWNkGIZFP5PJpK5du2rZsmV65ZVX5OjoqJIlS2r16tWJD/gTrl27pnbt2snLy0tOTk4qXbq05syZY94ef/3VuXPntGrVKnPtyZ0Fmj17tt59911J0uuvv25+/ebNmyU9Gr8333xTa9asUYUKFeTs7Kxp06ZJkmbNmqVatWrJ09NTjo6O8vf315QpUxI9zu+//64aNWrI1dVVbm5uqlixohYsWPDU2tauXascOXKoefPmiomJSdb7kaTFixfL399fTk5OeuWVV7R06dJEv4ZxcXEaP368SpYsKScnJ3l5ealTp066efOmRb/4Mdi2bZsqVaokJycnFSpUSHPnzrXoF3966pYtW9S5c2d5enrqxRdftBiD1157TS4uLnJ1dVVwcLCOHTuW7PcVr2bNmlq1apUuXLhg/nrFv7cHDx5o4MCBKl++vNzd3eXi4qLXXntNmzZtstjH+fPnZTKZNGbMGI0fP16FCxeWo6Ojjh8/LunR91WFChXk5OSkwoULa9q0aUleZ/jDDz+ofPnycnZ2Vu7cudWsWTOL/4dPqxfA84OZIwBZRsuWLfXFF19o7dq16tChQ6J9jh07pjfffFOlSpXS0KFD5ejoqDNnzmj79u2SpBIlSmjo0KEaOHCgOnbsqNdee02S9Oqrr5r3cePGDdWvX1/NmjXThx9+KC8vr6fW9fXXX8tkMqlPnz66du2axo8fr6CgIB06dChFMxvJqe1xhmGoUaNG2rRpk9q1a6cyZcpozZo1+vzzz/X3339r3LhxFv23bdumX375RZ07d5arq6smTpyopk2b6uLFi8qTJ0+Sdd29e1c1a9bUmTNn1LVrV/n5+Wnx4sVq3bq1IiIi1KNHD5UoUULz5s3TJ598ohdffFGffvqpJClv3rzJeu/Vq1dX9+7dNXHiRH3xxRcqUaKEeUzinTx5Us2bN1enTp3UoUMHFStWTJI0ZcoUlSxZUo0aNVK2bNm0YsUKde7cWXFxcerSpYv59bNnz1bbtm1VsmRJ9evXTx4eHjp48KBWr16tDz74ING6Vq5cqXfeeUfvv/++Zs6cKXt7+2S9n1WrVun9999XQECARowYoZs3b6pdu3bKnz9/gr6dOnXS7Nmz1aZNG3Xv3l3nzp3Tt99+q4MHD2r79u0WM4ZnzpzRO++8o3bt2qlVq1aaOXOmWrdurfLly6tkyZIW++3cubPy5s2rgQMH6vbt25KkefPmqVWrVqpbt65GjRqlO3fuaMqUKapWrZoOHjyYorDQv39/RUZG6q+//jJ/r+XMmVOSFBUVpenTp6t58+bq0KGDbt26pRkzZqhu3bras2ePypQpY7GvWbNm6d69e+rYsaMcHR2VO3duHTx4UPXq1VO+fPk0ZMgQxcbGaujQoYl+T3399dcaMGCA3nvvPbVv317Xr1/XpEmTVL16dR08eFAeHh5PrRfAc8QAgExi1qxZhiRj7969SfZxd3c3ypYta34+aNAg4/EfdePGjTMkGdevX09yH3v37jUkGbNmzUqwrUaNGoYkY+rUqYluq1Gjhvn5pk2bDElG/vz5jaioKHP7Tz/9ZEgyJkyYYG7z9fU1WrVq9cx9Pq22Vq1aGb6+vubny5YtMyQZX331lUW/d955xzCZTMaZM2fMbZIMBwcHi7aQkBBDkjFp0qQEx3rc+PHjDUnGDz/8YG578OCBERgYaOTMmdPivfv6+hrBwcFP3V9SFi9ebEgyNm3alGCbr6+vIclYvXp1gm137txJ0Fa3bl2jUKFC5ucRERGGq6urUblyZePu3bsWfePi4sz/rlGjhlGyZEnDMAzj559/NrJnz2506NDBiI2NTdF7CQgIMF588UXj1q1b5rbNmzcbkiy+hn/88YchyZg/f77F61evXp2gPX4Mtm7dam67du2a4ejoaHz66afmtvj/R9WqVTNiYmLM7bdu3TI8PDyMDh06WBwrLCzMcHd3T9CeHMHBwRbvJ15MTIxx//59i7abN28aXl5eRtu2bc1t586dMyQZbm5uxrVr1yz6N2zY0MiRI4fx999/m9tOnz5tZMuWzeL//Pnz5w17e3vj66+/tnj9kSNHjGzZslm0J1UvgOcHp9UByFJy5sz51FXrPDw8JEm//vqr4uLiUnUMR0dHtWnTJtn9P/roI7m6upqfv/POO8qXL59+++23VB0/uX777TfZ29ure/fuFu2ffvqpDMPQ77//btEeFBSkwoULm5+XKlVKbm5u+vPPP595HG9vbzVv3tzclj17dnXv3l3R0dHasmVLGrybZ/Pz81PdunUTtD8+OxcZGal//vlHNWrU0J9//qnIyEhJj061vHXrlvr27SsnJyeL1yd2itbChQv1/vvvq1OnTpo2bZrs7JL/6/Ty5cs6cuSIPvroI4uZiRo1aiggIMCi7+LFi+Xu7q433nhD//zzj/lRvnx55cyZM8FpaP7+/uYZRenRzFyxYsUS/Rp26NDBYqZr3bp1ioiIUPPmzS2OZW9vr8qVKyc41r9hb29vvmYoLi5O4eHhiomJUYUKFXTgwIEE/Zs2bWoxIxQbG6v169ercePG8vHxMbcXKVJE9evXt3jtL7/8ori4OL333nsW78vb21tFixZN0/cFIPPjtDoAWUp0dLQ8PT2T3P7+++9r+vTpat++vfr27avatWurSZMmeuedd5L9B27+/PlTdDF40aJFLZ6bTCYVKVIk3Vddu3Dhgnx8fCyCmfR/p6JduHDBov2ll15KsI9cuXIluLYlseMULVo0wfgldZz04ufnl2j79u3bNWjQIO3cuVN37tyx2BYZGSl3d3edPXtWkpJ1D6Nz587pww8/1LvvvqtJkyaluM748ShSpEiCbUWKFLEIB6dPn1ZkZGSS39PXrl2zeJ6Sr+GT43X69GlJj67fS4ybm1ui7ak1Z84cffPNNzpx4oQePnyYZF2JtV27dk13795Ncgwfd/r0aRmGkeD/YbzMsJAJgIxDOAKQZfz111+KjIxM9A+meM7Oztq6das2bdqkVatWafXq1Vq0aJFq1aqltWvXJuuakfRYAS2pG9XGxsYm+zqWfyup4xhPLN5gqxL7upw9e1a1a9dW8eLFNXbsWBUoUEAODg767bffNG7cuFTNHubLl88887dv3z6LlRPTWlxcnDw9PTV//vxEtz95fU1KvoZPjlf8WMybN0/e3t4J+qflqo8//PCDWrdurcaNG+vzzz+Xp6en7O3tNWLECHNQfVqtKREXFyeTyaTff/890fHhuiIAjyMcAcgy5s2bJ0mJnlr1ODs7O9WuXVu1a9fW2LFjNXz4cPXv31+bNm1SUFBQkkElteI/kY9nGIbOnDmjUqVKmdty5cqliIiIBK+9cOGCChUqZH6ektp8fX21fv163bp1y2L26MSJE+btacHX11eHDx9WXFycxexRWh8nNV+XFStW6P79+1q+fLnFrMqTp1LFn0549OjRp4ZrSXJyctLKlStVq1Yt1atXT1u2bEmw2MHTxI/HmTNnEmx7sq1w4cJav369qlatmu7LksePgaenp4KCgtJkn0l9zZYsWaJChQrpl19+segzaNCgZO3X09NTTk5OyR5DwzDk5+enl19+OVX1Anh+cM0RgCxh48aNGjZsmPz8/NSiRYsk+4WHhydoi18Z6/79+5Jkvt9LYmElNebOnWtxHdSSJUt05coVi2sjChcurF27dunBgwfmtpUrVyZY8jsltTVo0ECxsbH69ttvLdrHjRsnk8mU4NqM1GrQoIHCwsK0aNEic1tMTIwmTZqknDlzqkaNGmlynNR8XeJnCh6fOYmMjNSsWbMs+tWpU0eurq4aMWKE7t27Z7EtsVkXd3d3rVmzRp6ennrjjTcSne1Iio+Pj1555RXNnTtX0dHR5vYtW7boyJEjFn3fe+89xcbGatiwYQn2ExMTk2bfo9KjDxXc3Nw0fPhwi9Pc4l2/fj3F+3RxcTFf1/W4xL4uu3fv1s6dO5O1X3t7ewUFBWnZsmW6fPmyuf3MmTMJrqVr0qSJ7O3tNWTIkARfS8MwdOPGjWfWC+D5wcwRgEzn999/14kTJxQTE6OrV69q48aNWrdunXx9fbV8+fIEF9Q/bujQodq6dauCg4Pl6+ura9eu6X//+59efPFFVatWTdKjoOLh4aGpU6fK1dVVLi4uqly5cpLXtDxL7ty5Va1aNbVp00ZXr17V+PHjVaRIEYvlxtu3b68lS5aoXr16eu+993T27Fn98MMPFgskpLS2hg0b6vXXX1f//v11/vx5lS5dWmvXrtWvv/6qnj17Jth3anXs2FHTpk1T69attX//fhUsWFBLlizR9u3bNX78+ATXPKVWmTJlZG9vr1GjRikyMlKOjo7m+xclpU6dOnJwcFDDhg3VqVMnRUdH6/vvv5enp6euXLli7ufm5qZx48apffv2qlixoj744APlypVLISEhunPnjsU9m+K98MIL5ntmBQUFadu2bYkuxZ2Y4cOH66233lLVqlXVpk0b3bx5U99++61eeeUVi8BUo0YNderUSSNGjNChQ4dUp04dZc+eXadPn9bixYs1YcIEvfPOOykYxaS5ublpypQpatmypcqVK6dmzZopb968unjxolatWqWqVasmCNrPUr58eS1atEi9evVSxYoVlTNnTjVs2FBvvvmmfvnlF7399tsKDg7WuXPnNHXqVPn7+1u8/6cZPHiw1q5dq6pVq+rjjz82fxDwyiuv6NChQ+Z+hQsX1ldffaV+/frp/Pnzaty4sVxdXXXu3DktXbpUHTt21GefffbUegE8R6y0Sh4ApFj8EsTxDwcHB8Pb29t44403jAkTJlgsGR3vyaW8N2zYYLz11luGj4+P4eDgYPj4+BjNmzc3Tp06ZfG6X3/91fD39zcvCxy/dPbjSzk/KamlvBcuXGj069fP8PT0NJydnY3g4GDjwoULCV7/zTffGPnz5zccHR2NqlWrGvv27Uuwz6fV9uRS3obxaHnmTz75xPDx8TGyZ89uFC1a1Pjvf/9rsTy1YTxayrtLly4JakpqifEnXb161WjTpo3xwgsvGA4ODkZAQECiy43/m6W8DcMwvv/+e6NQoUKGvb29xbLeT9vv8uXLjVKlShlOTk5GwYIFjVGjRhkzZ840JBnnzp1L0PfVV181nJ2dDTc3N6NSpUrGwoULzdsT+/qfOXPGyJcvn1GiRImnLhH/pB9//NEoXry44ejoaLzyyivG8uXLjaZNmxrFixdP0Pe7774zypcvbzg7Oxuurq5GQECA0bt3b+Py5cvmPkmNwZPfQ89aEn/Tpk1G3bp1DXd3d8PJyckoXLiw0bp1a2Pfvn3Jfm/xoqOjjQ8++MDw8PCwWKY8Li7OGD58uOHr62s4OjoaZcuWNVauXJngezh+Ke///ve/ie5/w4YNRtmyZQ0HBwejcOHCxvTp041PP/3UcHJyStD3559/NqpVq2a4uLgYLi4uRvHixY0uXboYJ0+efGa9AJ4fJsPIJFfaAgCQxZUpU0Z58+bVunXrrF1KptW4cWMdO3YswbV+AJAcXHMEAEAGe/jwoWJiYizaNm/erJCQENWsWdM6RWVCd+/etXh++vRp/fbbb4whgFRj5ggAgDQSGRmZ4A/2J3l7e+v8+fMKCgrShx9+KB8fH504cUJTp06Vu7u7jh49qjx58mRQxZlbvnz51Lp1axUqVEgXLlzQlClTdP/+fR08eDDJ+xoBwNOwIAMAAGmkR48eiS7e8DjDMJQrVy6VL19e06dP1/Xr1+Xi4qLg4GCNHDmSYJQC9erV08KFCxUWFiZHR0cFBgZq+PDhBCMAqcbMEQAAaeT48eMWS0snJq3uIQQASHuEIwAAAAAQCzIAAAAAgKQsfM1RXFycLl++LFdXV5lMJmuXAwAAAMBKDMPQrVu35OPjIzu7pOeHsmw4unz5sgoUKGDtMgAAAADYiEuXLunFF19McnuWDUeurq6SHg2Am5ublasBAAAAYC1RUVEqUKCAOSMkJcuGo/hT6dzc3AhHAAAAAJ55uQ0LMgAAAACACEcAAAAAIIlwBAAAAACSCEcAAAAAIIlwBAAAAACSCEcAAAAAIIlwlGpbt25Vw4YN5ePjI5PJpGXLlllsNwxDAwcOVL58+eTs7KygoCCdPn3aok94eLhatGghNzc3eXh4qF27doqOjrboc/jwYb322mtycnJSgQIFNHr06PR+a+mGMUsdxi3lGLPUYdxSjjFLHcYt5Riz1GHcUu65HzMji4qMjDQkGZGRkemy/99++83o37+/8csvvxiSjKVLl1psHzlypOHu7m4sW7bMCAkJMRo1amT4+fkZd+/eNfepV6+eUbp0aWPXrl3GH3/8YRQpUsRo3ry5xXvw8vIyWrRoYRw9etRYuHCh4ezsbEybNi1d3lN6Y8xSh3FLOcYsdRi3lGPMUodxSznGLHUYt5TLqmOW3GxAOEoDT37jxMXFGd7e3sZ///tfc1tERITh6OhoLFy40DAMwzh+/Lghydi7d6+5z++//26YTCbj77//NgzDMP73v/8ZuXLlMu7fv2/u06dPH6NYsWLp/I7SH2OWOoxbyjFmqcO4pRxjljqMW8oxZqnDuKVcVhqz5GYDTqtLB+fOnVNYWJiCgoLMbe7u7qpcubJ27twpSdq5c6c8PDxUoUIFc5+goCDZ2dlp9+7d5j7Vq1eXg4ODuU/dunV18uRJ3bx5M4PeTcZgzFKHcUs5xix1GLeUY8xSh3FLOcYsdRi3lHsexoxwlA7CwsIkSV5eXhbtXl5e5m1hYWHy9PS02J4tWzblzp3bok9i+3j8GFkFY5Y6jFvKMWapw7ilHGOWOoxbyjFmqcO4pdzzMGaEIwAAAAAQ4ShdeHt7S5KuXr1q0X716lXzNm9vb127ds1ie0xMjMLDwy36JLaPx4+RVTBmqcO4pRxjljqMW8oxZqnDuKUcY5Y6jFvKPQ9jRjhKB35+fvL29taGDRvMbVFRUdq9e7cCAwMlSYGBgYqIiND+/fvNfTZu3Ki4uDhVrlzZ3Gfr1q16+PChuc+6detUrFgx5cqVK4PeTcZgzFKHcUs5xix1GLeUY8xSh3FLOcYsdRi3lHsuxizdloSwsvRere7WrVvGwYMHjYMHDxqSjLFjxxoHDx40Lly4YBjGo2UOPTw8jF9//dU4fPiw8dZbbyW6zGHZsmWN3bt3G9u2bTOKFi1qscxhRESE4eXlZbRs2dI4evSo8eOPPxo5cuTItEtDMmapw7ilHGOWOoxbyjFmqcO4pRxjljqMW8pl1TFLt6W8t2zZYrz55ptGvnz5El37PC4uzhgwYIDh7e1tODk5GbVr1zZOnTpl0efGjRvGBx98YLi6uhru7u5G27ZtjVu3bln0CQkJMapVq2Y4OjoaL774ojFq1KgU1Zne4WjTpk2GpASPVq1aGYbxf+Pg5eVlODo6GrVr1zZOnjxpsY8bN24YzZs3N3LmzGm4ubkZbdq0eeo45M+f3xg5cmS6vJ+MwJilDuOWcoxZ6jBuKceYpQ7jlnKMWeowbimXVccsudnAZBiGkZKZpt9//13bt29X+fLl1aRJEy1dulSNGzc2bx81apRGjBihOXPmyM/PTwMGDNCRI0d0/PhxOTk5SZLq16+vK1euaNq0aXr48KHatGmjihUrasGCBZIeTc+9/PLLCgoKUr9+/XTkyBG1bdtW48ePV8eOHZNVZ1RUlNzd3RUZGSk3N7eUvEUAAAAAWUhys0GKw5HFi00mi3BkGIZ8fHz06aef6rPPPpMkRUZGysvLS7Nnz1azZs0UGhoqf39/7d2717z++erVq9WgQQP99ddf8vHx0ZQpU9S/f3+FhYWZ1z/v27evli1bphMnTqTpAAAAAADI2pKbDdJ0QQZr3hjq/v37ioqKsngAAAAAQHJlS8udpeWNofz8/BLsI35bYqtYjBgxQkOGDEmbN5KIgn1Xpdu+/63zI4OtXUKSbHXcGLPUYdxSjjFLHcYt5Riz1GHcUo4xSx3GLeWsMWZZZinvfv36KTIy0vy4dOmStUsCAAAAkImkaTiy5o2hHB0d5ebmZvEAAAAAgORK03D0XNwYCgAAAECWlOJwFB0drUOHDunQoUOSHi3CcOjQIV28eFEmk0k9e/bUV199peXLl+vIkSP66KOP5OPjY17RrkSJEqpXr546dOigPXv2aPv27eratauaNWsmHx8fSdIHH3wgBwcHtWvXTseOHdOiRYs0YcIE9erVK83eOAAAAAA8LsULMuzbt0+vv/66+Xl8YGnVqpVmz56t3r176/bt2+rYsaMiIiJUrVo1rV692nyPI0maP3++unbtqtq1a8vOzk5NmzbVxIkTzdvd3d21du1adenSReXLl9cLL7yggQMHJvseRwAAAACQUikORzVr1tTTbo1kMpk0dOhQDR06NMk+uXPnNt/wNSmlSpXSH3/8kdLyAAAAACBVssxqdQAAAADwbxCOAAAAAECEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQlA7hKDY2VgMGDJCfn5+cnZ1VuHBhDRs2TIZhmPsYhqGBAwcqX758cnZ2VlBQkE6fPm2xn/DwcLVo0UJubm7y8PBQu3btFB0dndblAgAAAICkdAhHo0aN0pQpU/Ttt98qNDRUo0aN0ujRozVp0iRzn9GjR2vixImaOnWqdu/eLRcXF9WtW1f37t0z92nRooWOHTumdevWaeXKldq6das6duyY1uUCAAAAgCQpW1rvcMeOHXrrrbcUHBwsSSpYsKAWLlyoPXv2SHo0azR+/Hh9+eWXeuuttyRJc+fOlZeXl5YtW6ZmzZopNDRUq1ev1t69e1WhQgVJ0qRJk9SgQQONGTNGPj4+aV02AAAAgOdcms8cvfrqq9qwYYNOnTolSQoJCdG2bdtUv359SdK5c+cUFhamoKAg82vc3d1VuXJl7dy5U5K0c+dOeXh4mIORJAUFBcnOzk67d+9O9Lj3799XVFSUxQMAAAAAkivNZ4769u2rqKgoFS9eXPb29oqNjdXXX3+tFi1aSJLCwsIkSV5eXhav8/LyMm8LCwuTp6enZaHZsil37tzmPk8aMWKEhgwZktZvBwAAAMBzIs1njn766SfNnz9fCxYs0IEDBzRnzhyNGTNGc+bMSetDWejXr58iIyPNj0uXLqXr8QAAAABkLWk+c/T555+rb9++atasmSQpICBAFy5c0IgRI9SqVSt5e3tLkq5evap8+fKZX3f16lWVKVNGkuTt7a1r165Z7DcmJkbh4eHm1z/J0dFRjo6Oaf12AAAAADwn0nzm6M6dO7Kzs9ytvb294uLiJEl+fn7y9vbWhg0bzNujoqK0e/duBQYGSpICAwMVERGh/fv3m/ts3LhRcXFxqly5clqXDAAAAABpP3PUsGFDff3113rppZdUsmRJHTx4UGPHjlXbtm0lSSaTST179tRXX32lokWLys/PTwMGDJCPj48aN24sSSpRooTq1aunDh06aOrUqXr48KG6du2qZs2asVIdAAAAgHSR5uFo0qRJGjBggDp37qxr167Jx8dHnTp10sCBA819evfurdu3b6tjx46KiIhQtWrVtHr1ajk5OZn7zJ8/X127dlXt2rVlZ2enpk2bauLEiWldLgAAAABISodw5OrqqvHjx2v8+PFJ9jGZTBo6dKiGDh2aZJ/cuXNrwYIFaV0eAAAAACQqza85AgAAAIDMiHAEAAAAACIcAQAAAIAkwhEAAAAASCIcAQAAAIAkwhEAAAAASCIcAQAAAIAkwhEAAAAASCIcAQAAAIAkwhEAAAAASCIcAQAAAIAkwhEAAAAASCIcAQAAAIAkwhEAAAAASCIcAQAAAIAkwhEAAAAASCIcAQAAAIAkwhEAAAAASCIcAQAAAIAkwhEAAAAASCIcAQAAAIAkwhEAAAAASCIcAQAAAIAkwhEAAAAASCIcAQAAAIAkwhEAAAAASCIcAQAAAIAkwhEAAAAASCIcAQAAAIAkwhEAAAAASCIcAQAAAIAkwhEAAAAASCIcAQAAAIAkwhEAAAAASCIcAQAAAIAkwhEAAAAASCIcAQAAAIAkwhEAAAAASCIcAQAAAIAkwhEAAAAASCIcAQAAAIAkwhEAAAAASCIcAQAAAIAkwhEAAAAASCIcAQAAAIAkwhEAAAAASCIcAQAAAIAkwhEAAAAASCIcAQAAAIAkwhEAAAAASCIcAQAAAIAkwhEAAAAASCIcAQAAAIAkwhEAAAAASCIcAQAAAIAkwhEAAAAASCIcAQAAAIAkwhEAAAAASCIcAQAAAIAkwhEAAAAASCIcAQAAAIAkwhEAAAAASCIcAQAAAIAkwhEAAAAASCIcAQAAAIAkwhEAAAAASCIcAQAAAIAkwhEAAAAASCIcAQAAAIAkwhEAAAAASCIcAQAAAIAkwhEAAAAASCIcAQAAAIAkwhEAAAAASCIcAQAAAIAkwhEAAAAASCIcAQAAAICkdApHf//9tz788EPlyZNHzs7OCggI0L59+8zbDcPQwIEDlS9fPjk7OysoKEinT5+22Ed4eLhatGghNzc3eXh4qF27doqOjk6PcgEAAAAg7cPRzZs3VbVqVWXPnl2///67jh8/rm+++Ua5cuUy9xk9erQmTpyoqVOnavfu3XJxcVHdunV17949c58WLVro2LFjWrdunVauXKmtW7eqY8eOaV0uAAAAAEiSsqX1DkeNGqUCBQpo1qxZ5jY/Pz/zvw3D0Pjx4/Xll1/qrbfekiTNnTtXXl5eWrZsmZo1a6bQ0FCtXr1ae/fuVYUKFSRJkyZNUoMGDTRmzBj5+PikddkAAAAAnnNpPnO0fPlyVahQQe+++648PT1VtmxZff/99+bt586dU1hYmIKCgsxt7u7uqly5snbu3ClJ2rlzpzw8PMzBSJKCgoJkZ2en3bt3J3rc+/fvKyoqyuIBAAAAAMmV5uHozz//1JQpU1S0aFGtWbNGH3/8sbp37645c+ZIksLCwiRJXl5eFq/z8vIybwsLC5Onp6fF9mzZsil37tzmPk8aMWKE3N3dzY8CBQqk9VsDAAAAkIWleTiKi4tTuXLlNHz4cJUtW1YdO3ZUhw4dNHXq1LQ+lIV+/fopMjLS/Lh06VK6Hg8AAABA1pLm4Shfvnzy9/e3aCtRooQuXrwoSfL29pYkXb161aLP1atXzdu8vb117do1i+0xMTEKDw8393mSo6Oj3NzcLB4AAAAAkFxpHo6qVq2qkydPWrSdOnVKvr6+kh4tzuDt7a0NGzaYt0dFRWn37t0KDAyUJAUGBioiIkL79+8399m4caPi4uJUuXLltC4ZAAAAANJ+tbpPPvlEr776qoYPH6733ntPe/bs0XfffafvvvtOkmQymdSzZ0999dVXKlq0qPz8/DRgwAD5+PiocePGkh7NNNWrV898Ot7Dhw/VtWtXNWvWjJXqAAAAAKSLNA9HFStW1NKlS9WvXz8NHTpUfn5+Gj9+vFq0aGHu07t3b92+fVsdO3ZURESEqlWrptWrV8vJycncZ/78+eratatq164tOzs7NW3aVBMnTkzrcgEAAABAUjqEI0l688039eabbya53WQyaejQoRo6dGiSfXLnzq0FCxakR3kAAAAAkECaX3MEAAAAAJkR4QgAAAAARDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEmEIwAAAACQRDgCAAAAAEkZEI5Gjhwpk8mknj17mtvu3bunLl26KE+ePMqZM6eaNm2qq1evWrzu4sWLCg4OVo4cOeTp6anPP/9cMTEx6V0uAAAAgOdUuoajvXv3atq0aSpVqpRF+yeffKIVK1Zo8eLF2rJliy5fvqwmTZqYt8fGxio4OFgPHjzQjh07NGfOHM2ePVsDBw5Mz3IBAAAAPMfSLRxFR0erRYsW+v7775UrVy5ze2RkpGbMmKGxY8eqVq1aKl++vGbNmqUdO3Zo165dkqS1a9fq+PHj+uGHH1SmTBnVr19fw4YN0+TJk/XgwYP0KhkAAADAcyzdwlGXLl0UHBysoKAgi/b9+/fr4cOHFu3FixfXSy+9pJ07d0qSdu7cqYCAAHl5eZn71K1bV1FRUTp27Fiix7t//76ioqIsHgAAAACQXNnSY6c//vijDhw4oL179ybYFhYWJgcHB3l4eFi0e3l5KSwszNzn8WAUvz1+W2JGjBihIUOGpEH1AAAAAJ5HaT5zdOnSJfXo0UPz58+Xk5NTWu8+Sf369VNkZKT5cenSpQw7NgAAAIDML83D0f79+3Xt2jWVK1dO2bJlU7Zs2bRlyxZNnDhR2bJlk5eXlx48eKCIiAiL1129elXe3t6SJG9v7wSr18U/j+/zJEdHR7m5uVk8AAAAACC50jwc1a5dW0eOHNGhQ4fMjwoVKqhFixbmf2fPnl0bNmwwv+bkyZO6ePGiAgMDJUmBgYE6cuSIrl27Zu6zbt06ubm5yd/fP61LBgAAAIC0v+bI1dVVr7zyikWbi4uL8uTJY25v166devXqpdy5c8vNzU3dunVTYGCgqlSpIkmqU6eO/P391bJlS40ePVphYWH68ssv1aVLFzk6OqZ1yQAAAACQPgsyPMu4ceNkZ2enpk2b6v79+6pbt67+97//mbfb29tr5cqV+vjjjxUYGCgXFxe1atVKQ4cOtUa5AAAAAJ4DGRKONm/ebPHcyclJkydP1uTJk5N8ja+vr3777bd0rgwAAAAAHkm3+xwBAAAAQGZCOAIAAAAAEY4AAAAAQBLhCAAAAAAkEY4AAAAAQBLhCAAAAAAkEY4AAAAAQBLhCAAAAAAkEY4AAAAAQBLhCAAAAAAkEY4AAAAAQBLhCAAAAAAkEY4AAAAAQBLhCAAAAAAkEY4AAAAAQBLhCAAAAAAkEY4AAAAAQBLhCAAAAAAkEY4AAAAAQBLhCAAAAAAkEY4AAAAAQBLhCAAAAAAkEY4AAAAAQBLhCAAAAAAkEY4AAAAAQBLhCAAAAAAkEY4AAAAAQBLhCAAAAAAkEY4AAAAAQBLhCAAAAAAkEY4AAAAAQBLhCAAAAAAkEY4AAAAAQBLhCAAAAAAkEY4AAAAAQBLhCAAAAAAkEY4AAAAAQBLhCAAAAAAkEY4AAAAAQBLhCAAAAAAkEY4AAAAAQBLhCAAAAAAkEY4AAAAAQBLhCAAAAAAkEY4AAAAAQBLhCAAAAAAkEY4AAAAAQBLhCAAAAAAkEY4AAAAAQBLhCAAAAAAkEY4AAAAAQBLhCAAAAAAkEY4AAAAAQBLhCAAAAAAkEY4AAAAAQBLhCAAAAAAkEY4AAAAAQBLhCAAAAAAkEY4AAAAAQBLhCAAAAAAkEY4AAAAAQBLhCAAAAAAkEY4AAAAAQBLhCAAAAAAkEY4AAAAAQBLhCAAAAAAkEY4AAAAAQBLhCAAAAAAkEY4AAAAAQBLhCAAAAAAkEY4AAAAAQBLhCAAAAAAkEY4AAAAAQBLhCAAAAAAkEY4AAAAAQBLhCAAAAAAkEY4AAAAAQFI6hKMRI0aoYsWKcnV1laenpxo3bqyTJ09a9Ll37566dOmiPHnyKGfOnGratKmuXr1q0efixYsKDg5Wjhw55Onpqc8//1wxMTFpXS4AAAAASEqHcLRlyxZ16dJFu3bt0rp16/Tw4UPVqVNHt2/fNvf55JNPtGLFCi1evFhbtmzR5cuX1aRJE/P22NhYBQcH68GDB9qxY4fmzJmj2bNna+DAgWldLgAAAABIkrKl9Q5Xr15t8Xz27Nny9PTU/v37Vb16dUVGRmrGjBlasGCBatWqJUmaNWuWSpQooV27dqlKlSpau3atjh8/rvXr18vLy0tlypTRsGHD1KdPHw0ePFgODg5pXTYAAACA51y6X3MUGRkpScqdO7ckaf/+/Xr48KGCgoLMfYoXL66XXnpJO3fulCTt3LlTAQEB8vLyMvepW7euoqKidOzYsUSPc//+fUVFRVk8AAAAACC50jUcxcXFqWfPnqpatapeeeUVSVJYWJgcHBzk4eFh0dfLy0thYWHmPo8Ho/jt8dsSM2LECLm7u5sfBQoUSON3AwAAACArS9dw1KVLFx09elQ//vhjeh5GktSvXz9FRkaaH5cuXUr3YwIAAADIOtL8mqN4Xbt21cqVK7V161a9+OKL5nZvb289ePBAERERFrNHV69elbe3t7nPnj17LPYXv5pdfJ8nOTo6ytHRMY3fBQAAAIDnRZrPHBmGoa5du2rp0qXauHGj/Pz8LLaXL19e2bNn14YNG8xtJ0+e1MWLFxUYGChJCgwM1JEjR3Tt2jVzn3Xr1snNzU3+/v5pXTIAAAAApP3MUZcuXbRgwQL9+uuvcnV1NV8j5O7uLmdnZ7m7u6tdu3bq1auXcufOLTc3N3Xr1k2BgYGqUqWKJKlOnTry9/dXy5YtNXr0aIWFhenLL79Uly5dmB0CAAAAkC7SPBxNmTJFklSzZk2L9lmzZql169aSpHHjxsnOzk5NmzbV/fv3VbduXf3vf/8z97W3t9fKlSv18ccfKzAwUC4uLmrVqpWGDh2a1uUCAAAAgKR0CEeGYTyzj5OTkyZPnqzJkycn2cfX11e//fZbWpYGAAAAAElK9/scAQAAAEBmQDgCAAAAABGOAAAAAEAS4QgAAAAAJBGOAAAAAEAS4QgAAAAAJBGOAAAAAEAS4QgAAAAAJBGOAAAAAEAS4QgAAAAAJBGOAAAAAEAS4QgAAAAAJBGOAAAAAEAS4QgAAAAAJBGOAAAAAEAS4QgAAAAAJBGOAAAAAEAS4QgAAAAAJBGOAAAAAEAS4QgAAAAAJBGOAAAAAEAS4QgAAAAAJBGOAAAAAEAS4QgAAAAAJBGOAAAAAEAS4QgAAAAAJBGOAAAAAEAS4QgAAAAAJBGOAAAAAEAS4QgAAAAAJBGOAAAAAEAS4QgAAAAAJBGOAAAAAEAS4QgAAAAAJBGOAAAAAEAS4QgAAAAAJBGOAAAAAEAS4QgAAAAAJBGOAAAAAEAS4QgAAAAAJBGOAAAAAEAS4QgAAAAAJBGOAAAAAEAS4QgAAAAAJBGOAAAAAEAS4QgAAAAAJBGOAAAAAEAS4QgAAAAAJBGOAAAAAEAS4QgAAAAAJBGOAAAAAEAS4QgAAAAAJBGOAAAAAEAS4QgAAAAAJBGOAAAAAEAS4QgAAAAAJBGOAAAAAEAS4QgAAAAAJBGOAAAAAEAS4QgAAAAAJBGOAAAAAEAS4QgAAAAAJBGOAAAAAEAS4QgAAAAAJBGOAAAAAEAS4QgAAAAAJBGOAAAAAEAS4QgAAAAAJBGOAAAAAEAS4QgAAAAAJBGOAAAAAEAS4QgAAAAAJBGOAAAAAEAS4QgAAAAAJBGOAAAAAEAS4QgAAAAAJBGOAAAAAECSjYejyZMnq2DBgnJyclLlypW1Z88ea5cEAAAAIIuy2XC0aNEi9erVS4MGDdKBAwdUunRp1a1bV9euXbN2aQAAAACyIJsNR2PHjlWHDh3Upk0b+fv7a+rUqcqRI4dmzpxp7dIAAAAAZEHZrF1AYh48eKD9+/erX79+5jY7OzsFBQVp586dib7m/v37un//vvl5ZGSkJCkqKipNaoq7fydN9pMe0uo9pgdbHTfGLHUYt5RjzFKHcUs5xix1GLeUY8xSh3FLubQcs/h9GYbx1H4m41k9rODy5cvKnz+/duzYocDAQHN77969tWXLFu3evTvBawYPHqwhQ4ZkZJkAAAAAMpFLly7pxRdfTHK7Tc4cpUa/fv3Uq1cv8/O4uDiFh4crT548MplMVqwsoaioKBUoUECXLl2Sm5ubtcvJFBiz1GHcUo4xSx3GLeUYs9Rh3FKOMUsdxi3lbHnMDMPQrVu35OPj89R+NhmOXnjhBdnb2+vq1asW7VevXpW3t3eir3F0dJSjo6NFm4eHR3qVmCbc3Nxs7hvH1jFmqcO4pRxjljqMW8oxZqnDuKUcY5Y6jFvK2eqYubu7P7OPTS7I4ODgoPLly2vDhg3mtri4OG3YsMHiNDsAAAAASCs2OXMkSb169VKrVq1UoUIFVapUSePHj9ft27fVpk0ba5cGAAAAIAuy2XD0/vvv6/r16xo4cKDCwsJUpkwZrV69Wl5eXtYu7V9zdHTUoEGDEpwGiKQxZqnDuKUcY5Y6jFvKMWapw7ilHGOWOoxbymWFMbPJ1eoAAAAAIKPZ5DVHAAAAAJDRCEcAAAAAIMIRAAAAAEgiHAEAAACAJMIRAAAZolatWhoyZEiC9ps3b6pWrVpWqAgA8CRWq0snUVFRye5ri3cQtgWDBg1S27Zt5evra+1SMo29e/cqLi5OlStXtmjfvXu37O3tVaFCBStVBsDOzk558uRR1apVNX/+fLm4uEiSrl69Kh8fH8XGxlq5QgAAM0fpxMPDQ7ly5XrqI74PEvfrr7+qcOHCql27thYsWKD79+9buySb16VLF126dClB+99//60uXbpYoSI8Dx48eKCTJ08qJibG2qXYvPXr1yssLExVqlTR+fPnrV0OngP79u3TvHnzNG/ePO3bt8/a5WQajFvy/fXXX0lu27VrVwZWkjaYOUonW7ZsSXbfGjVqpGMlmdvBgwc1a9YsLVy4UDExMWrWrJnatm2rihUrWrs0m5QzZ04dPnxYhQoVsmg/d+6cSpUqpVu3blmpMtt38+ZNzZgxQ6GhoZKkEiVKqG3btsqdO7eVK7Ndd+7cUbdu3TRnzhxJ0qlTp1SoUCF169ZN+fPnV9++fa1coW2xs7NTWFiY3N3d1aZNG61bt06LFy9WiRIlmDlKRJMmTZLd95dffknHSjKnv/76S82bN9f27dvl4eEhSYqIiNCrr76qH3/8US+++KJ1C7RRjFvK+fv7a9u2bQl+X27fvl3BwcGKiIiwTmGpxMxROqlRo0ayH0ha2bJlNXHiRF2+fFkzZszQX3/9papVq6pUqVKaMGGCIiMjrV2iTXF0dNTVq1cTtF+5ckXZsmWzQkWZw9atW+Xn56eJEyfq5s2bunnzpiZNmiQ/Pz9t3brV2uXZrH79+ikkJESbN2+Wk5OTuT0oKEiLFi2yYmW2yWQySXr0/3TBggXq0aOH6tWrp//9739Wrsw2ubu7J/uBhNq3b6+HDx8qNDRU4eHhCg8PV2hoqOLi4tS+fXtrl2ezGLeUq1KliurUqWPxAezWrVvVoEEDDRo0yIqVpQ4zRxnozp07unjxoh48eGDRXqpUKStVlHk8ePBAS5cu1cyZM7Vx40a9+uqrunz5sq5evarvv/9e77//vrVLtAnNmzfXlStX9Ouvv5r/YIiIiFDjxo3l6empn376ycoV2qaAgAAFBgZqypQpsre3lyTFxsaqc+fO2rFjh44cOWLlCm2Tr6+vFi1apCpVqsjV1VUhISEqVKiQzpw5o3LlyqXo2svnQfzMkaenp7nt559/VqtWrXT37l1mjpCmnJ2dtWPHDpUtW9aiff/+/Xrttdd0584dK1Vm2xi3lIuLi9M777yj8PBwrVmzRjt27FCjRo301VdfqUePHtYuL8X4KDkDXL9+XW3atNHvv/+e6HZ+ISZt//795tPqHB0d9dFHH2ny5MkqUqSIJGnSpEnq3r074ej/GzNmjKpXry5fX1/zD/ZDhw7Jy8tL8+bNs3J1tuvMmTNasmSJORhJkr29vXr16qW5c+dasTLbdv36dYs/9OPdvn3bPEuC/3Pu3DnlzZvXoq1p06YqXrw41zQgzRUoUEAPHz5M0B4bGysfHx8rVJQ5MG4pZ2dnpx9//FHBwcGqVauWDh8+rBEjRqhr167WLi1VOK0uA/Ts2VMRERHavXu3nJ2dtXr1as2ZM0dFixbV8uXLrV2ezQoICFCVKlV07tw5zZgxQ5cuXdLIkSPNwUh6NFNy/fp1K1ZpW/Lnz6/Dhw9r9OjR8vf3V/ny5TVhwgQdOXJEBQoUsHZ5NqtcuXLma40eFxoaqtKlS1uhosyhQoUKWrVqlfl5fCCaPn26AgMDrVWWzdqyZUui32eFCxcmTCbDkiVL9N5776lKlSoqV66cxQMJ/fe//1W3bt0sgve+ffvUo0cPjRkzxoqV2TbGLXkOHz5s8Thx4oQGDx6sS5cu6cMPP1T16tXN2zIbTqvLAPny5dOvv/6qSpUqyc3NTfv27dPLL7+s5cuXa/To0dq2bZu1S7RJw4YNU9u2bZU/f35rl4IsbtGiRerdu7e6deumKlWqSHq0ws7kyZM1cuRIlShRwtyX02D/z7Zt21S/fn19+OGHmj17tjp16qTjx49rx44d2rJli8qXL2/tEm2KnZ2dXFxcNHv2bDVt2tTczlLezzZx4kT1799frVu31nfffac2bdro7Nmz2rt3r7p06aKvv/7a2iXanFy5cunOnTuKiYkxX3Ma/+/4ZeTjhYeHW6NEm5ErVy6LDyhu376d5Lg972MVz87OTiaTSY/HiMefx//bZDJlup9thKMM4ObmpsOHD6tgwYLy9fXVggULVLVqVZ07d04lS5bk/NVEPHz4UMWLF9fKlSst/jBFQsuXL1f9+vWVPXv2Z85ENmrUKIOqylzs7J4+iZ6Zf8int7Nnz2rkyJEKCQlRdHS0ypUrpz59+iggIMDapdkcOzs7jRkzRl9++aV69+6twYMHS3oUjvLly6e4uDjrFmjDihcvrkGDBql58+YW17cNHDhQ4eHh+vbbb61dos2JX0UyOVq1apWOldg+xirlLly4kOy+me1+lYSjDFCxYkV99dVXqlu3rho1aiQPDw+NGDFCEydO1JIlS3T27Flrl2iT8ufPr/Xr1xOOnuHxi7yf9kc+f9gnLSv/kIftiP+/+ueff+rtt99W1apVNW/ePEVFRTFz9Aw5cuRQaGiofH195enpqXXr1ql06dI6ffq0qlSpohs3bli7RABZBAsyZIAePXroypUrkqRBgwapXr16mj9/vhwcHDR79mzrFmfDunTpolGjRmn69OksQ/0Uj3/azCfPqUPgSb6oqCi5ubmZ//008f3wSPxpO1WqVNHu3bvVqFEjvfrqq5o6daqVK7N93t7eCg8Pl6+vr1566SXt2rVLpUuX1rlz58RnvEmLjY3VsmXLzNe6lSxZUo0aNbJYfAZJCw4O1vTp05UvXz5rl2LTRowYIS8vL7Vt29aifebMmbp+/br69OljpcpSh5kjK7hz545OnDihl156SS+88IK1y7FZb7/9tjZs2KCcOXMqICAgwTnS3PQPaens2bMaP368+Y8If39/9ejRQ4ULF7ZyZbbF3t5eV65cMc9UJraQAKcgJu7Jpbzv3LmjFi1aaMOGDbp9+zbj9RTt27dXgQIFNGjQIE2ePFmff/65qlatqn379qlJkyaaMWOGtUu0OWfOnFGDBg30999/q1ixYpKkkydPqkCBAlq1ahU/25Lh8VM4kbSCBQtqwYIFevXVVy3ad+/erWbNmuncuXNWqix1+DjeCnLkyMHqOsng4eFhcdEykmfDhg3asGGDrl27lmAmaebMmVaqyratWbNGjRo1UpkyZVS1alVJj+7sXbJkSa1YsUJvvPGGlSu0HRs3bjTfBX3Tpk1WriZzGTRokHLmzGl+niNHDi1dulSDBg3iZsPP8N1335l/nnXp0kV58uQx30ulU6dOVq7ONnXv3l2FCxfWrl27zP9nb9y4oQ8//FDdu3e3WGkS+DfCwsISnV3Lmzev+cypzISZowzQtGlTVapUKcG04ujRo7V3714tXrzYSpUhqxkyZIiGDh2qChUqKF++fAk+1V+6dKmVKrNtZcuWVd26dTVy5EiL9r59+2rt2rU6cOCAlSoDIEkXL15UgQIFEvxMMwxDly5d0ksvvWSlymyXi4uLdu3alWBxlJCQEFWtWlXR0dFWqizzeOWVV/T7779zK4xnKFq0qAYNGqQPP/zQon3evHkaNGiQ/vzzTytVljrMHGWArVu3mlclelz9+vX1zTffZHxBmUStWrX0yy+/yMPDw6I9KipKjRs31saNG61TmA2bOnWqZs+erZYtW1q7lEwlNDRUP/30U4L2tm3bavz48RlfkA1LyT0rWPY8ccePH9fFixf14MEDc5vJZFLDhg2tWJVt8/PzM5/O+bjw8HD5+flxSmIiHB0ddevWrQTt0dHRcnBwsEJFmc/Ro0etXUKm0KFDB/Xs2VMPHz5UrVq1JD06i6V379769NNPrVxdyhGOMkBSP4iyZ8/+zAuan2ebN2+2+OMh3r179/THH39YoSLb9+DBgwTn/OLZ8ubNq0OHDqlo0aIW7YcOHUrwx9jzrkyZMhZLmz8Nf7Bail+l7siRIwnuByIxXk+T1PdbdHS0nJycrFCR7XvzzTfVsWNHzZgxQ5UqVZL06BqQ//znP9zW4RkiIiK0Z8+eRE9P/+ijj6xUle36/PPPdePGDXXu3Nn8d5uTk5P69Omjfv36Wbm6lCMcZYCAgAAtWrRIAwcOtGj/8ccf5e/vb6WqbNfjn0wfP35cYWFh5uexsbFavXo1N4ZNQvv27bVgwQINGDDA2qVkKh06dFDHjh31559/msPl9u3bNWrUKPXq1cvK1dmWxy+sPXjwoD777DN9/vnnCgwMlCTt3LlT33zzjUaPHm2tEm1Wjx495Ofnpw0bNsjPz0979uzRjRs39Omnn2rMmDHWLs8mxf//M5lMGjBggHLkyGHeFhsbq927d6tMmTJWqs62TZw4Ua1atVJgYKCyZ88u6dE9BN966y1NmDDBytXZrhUrVqhFixaKjo6Wm5ubRSg3mUyEo0SYTCaNGjVKAwYMUGhoqJydnVW0aFE5Ojpau7RU4ZqjDLBixQo1adJEH3zwgcV048KFC7V48WI1btzYugXamMdXwErs29PZ2VmTJk1KsGQkHv3xNXfuXJUqVUqlSpUy/0KMN3bsWCtVZtsMw9D48eP1zTff6PLly5IkHx8fff755+revfszZ0ieV5UqVdLgwYPVoEEDi/bffvtNAwYM0P79+61UmW164YUXtHHjRpUqVUru7u7as2ePihUrpo0bN+rTTz/VwYMHrV2izXn99dclSVu2bFFgYKDFWRgODg4qWLCgPvvsswSzvvg/Z86c0fHjxyU9WoWzSJEiVq7Itr388stq0KCBhg8fbhHGkTx//fWXJOnFF1+0ciWpRzjKIKtWrdLw4cN16NAhOTs7q1SpUho0aJBq1Khh7dJszoULF2QYhgoVKqQ9e/Yob9685m0ODg7y9PTkHg1JiP9DIjEmk4nrtJIh/hx9V1dXK1di+5ydnXXgwIEEN2oODQ1VuXLldPfuXStVZpty5cqlAwcOyM/PT4ULF9b06dP1+uuv6+zZswoICNCdO3esXaLNatOmjSZMmMC9s1JoxowZGjdunE6fPi3p0YXzPXv2VPv27a1cme1ycXHRkSNHWL47BeLi4vTVV1/pm2++MS/04erqqk8//VT9+/d/6g3qbRGn1WWQ4OBgBQcHW7uMTCH+hpzc0DTlWFr53yMUJV+JEiU0YsQITZ8+3fyJ/oMHDzRixIgEgQmPVr4KCQmRn5+fKleurNGjR8vBwUHfffcdf4g9w6xZsyQ9mgU5e/asqlevLmdn52Rd+/a8GjhwoMaOHatu3bpZnPb6ySef6OLFixo6dKiVK7RNdevW1b59+/g/mQL9+/fXjBkzNHLkSPPtMLZt26bBgwfr3r17+vrrr61cYcowcwSbdvr0aW3atCnRiyKfvIYLlrLC1HZGuXr1qj777DPz/aGe/LHIhfKJ27Nnjxo2bCjDMMwr0x0+fFgmk0krVqwwXwSOR9asWaPbt2+rSZMmOn36tBo2bKhTp04pT548+vHHH1W7dm1rl2izwsPD9e6772rTpk0ymUw6ffq0ChUqpLZt2ypXrlys/JqIvHnzauLEiWrevLlF+8KFC9WtWzf9888/VqrMts2YMUNDhw5VmzZtFBAQkOD0dBazSMjHx0dTp05NMDa//vqrOnfurL///ttKlaUO4Sid5M6dW6dOndILL7ygXLlyPfWTrfDw8AysLPP4/vvv9fHHH+uFF16Qt7d3gosiufdMQlltajuj1K9fXxcvXlTXrl0TvT/UW2+9ZaXKbN/t27c1f/58nThxQtKj2aQPPvhALi4uVq4scwgPD3/m7wg8WiHs2rVrmj59ukqUKKGQkBAVKlRIa9asUa9evXTs2DFrl2hzPDw8tHfv3gTXY506dUqVKlVSRESEdQqzcU/7PWkymfiwLBFOTk46fPiwXn75ZYv2kydPqkyZMpnuFGtOq0sn48aNM5+eM27cOH7xpcJXX32lr7/+OsHNc5G0rDa1nVG2bdumP/74g1WvUsHFxUUdO3a0dhk2q0mTJpo9e7bc3NzUpEmTp/bNmTOnSpYsqf/85z9yd3fPoAozh7Vr12rNmjUJZsKLFi2qCxcuWKkq29ayZUtNmTIlwUI83333nVq0aGGlqmwfp/SnXOnSpfXtt99q4sSJFu3ffvutSpcubaWqUo9wlE5atWpl/nfr1q2tV0gmdvPmTb377rvWLiNTmTNnjqZPn24xtV2qVCnlz59fnTt3JhwloUCBAomujIhn49TXp3N3dzd/OPaswHP//n1NnTpV27dv1/LlyzOivEzj9u3bia4cFh4enmmXC84IM2bM0Nq1a1WlShVJj+5zdPHiRX300UcWtylgJdPE/fXXX/Lx8eGsi2f473//qwYNGmj9+vUW17ddunRJv/32m5WrSzlOq8sABw4cUPbs2RUQECDp0TmYs2bNkr+/vwYPHsydqpPQrl07VaxYUf/5z3+sXUqmkdWmtjPK2rVr9c0332jatGkqWLCgtcvJNDj1Ne0dP35cFStW1O3bt61dik1p0KCBypcvr2HDhsnV1VWHDx+Wr6+vmjVrpri4OC1ZssTaJdqcp61e+jhWMk2am5ubDh06xOIMT/Hw4UPVq1dPgwYN0tq1axUaGirp0SnWnTt3lo+Pj5UrTDnCUQaoWLGi+vbtq6ZNm+rPP/+Uv7+/mjRpor179yo4OFjjx4+3dok2acSIERo7dqyCg4MTvSiye/fuVqrMdlWuXFmVK1dOMLXdrVs37d27V7t27bJSZbbnyes8bt++rZiYGOXIkSPB9xrXBSbO19dXnTt35tTXNBQbG6ujR49mylNR0tPRo0dVu3ZtlStXThs3blSjRo107NgxhYeHa/v27SpcuLC1S0QW5Orqar6+DUnLmzevduzYkWXuN0Y4ygDu7u46cOCAChcurFGjRmnjxo1as2aNtm/frmbNmunSpUvWLtEm+fn5JbnNZDLpzz//zMBqMoctW7YoODhYL730UqJT26+99pqVK7Qdc+bMSXbfx0+Txf/hU1VkpIiICE2ePFkhISGKjo5WuXLl1KVLF+XLl8/apSGLiJ8FmTp1qooWLUo4SqZPPvlEjo6OGjlypLVLSRNcc5QBDMMwn4u/fv16vfnmm5IeXefAUppJO3funLVLyHRq1KihU6dOafLkyebVw5o0aZJpp7bTE4Hn33v33Xe1du1aTn1FhnByctIbb7yh0qVLm3+n7t27VxLLKyNtZM+eXYcPHzY//+KLL5Q7d24rVpQ5xMTEaObMmVq/fr3Kly+fYLXSzHZNGzNHGaBWrVoqUKCAgoKC1K5dOx0/flxFihTRli1b1KpVK50/f97aJSILePITL6ROcHCwpk+fzqfRycCpr8goq1evVsuWLRUeHp5g8RSWV0ZaymqzIBnhade3ZcZr2ghHGeDw4cNq0aKFLl68qF69emnQoEGSHl0HcuPGDS1YsMDKFdqmtm3bPnX7zJkzM6iSzCOrnfdrDZxGkXyc+oqMUrRoUdWpU0cDBw6Ul5eXtctBFtatWzfNnTtXRYsWzRKzIEg5wpEV3bt3T/b29gk+bcUjb7/9tsXzhw8f6ujRo4qIiFCtWrX0yy+/WKky28UnXv8e4QiwPW5ubjp48CALLyDdZbVZEKQc1xxlgEuXLslkMplvXrdnzx4tWLBA/v7+3DzxKZYuXZqgLS4uTh9//DG/IJOQ1c77tQZfX18+sHiKXr16adiwYXJxcbG4T8qTTCaTvvnmmwysDFnZO++8o82bN/OzH+lu06ZN1i4BVsbMUQZ47bXX1LFjR7Vs2VJhYWEqVqyYSpYsqdOnT6tbt27cKDGFTp48qZo1a+rKlSvWLsXmPOu+FvzQx7/1+uuva+nSpfLw8OATVmSYO3fu6N1331XevHm5vg1AuiIcZYBcuXJp165dKlasmCZOnKhFixZp+/bt5lWeOC8/ZX777Te1atVK169ft3YpyEJu3rypGTNmWNzArm3btqxUBNiAGTNm6D//+Y+cnJyUJ0+eBDcc5vcogLTCaXUZ4OHDh3J0dJT0aCnv+CVHixcvzuzHUzx5yo5hGLpy5YpWrVrFMsxJaNu2rSZMmCBXV1eL9tu3b6tbt24sYpGErVu3qlGjRnJzc1OFChUkSZMmTdKwYcO0YsUKVa9e3coVAs+3/v37a8iQIerbt6/s7OysXQ6ALIyZowxQuXJlvf766woODladOnW0a9culS5dWrt27dI777yjv/76y9ol2qQnT9mxs7NT3rx5VatWLbVt21bZspHtn2Rvb68rV67I09PTov2ff/6Rt7e3YmJirFSZbQsICFBgYKCmTJkie3t7SVJsbKw6d+6sHTt26MiRI1auEHi+5c6dW3v37uWaIwDpjnCUATZv3qy3335bUVFRatWqlfnT+y+++EInTpxg1TX8a1FRUTIMQ7ly5dLp06eVN29e87bY2FitWLFCffv21eXLl61Ype1ydnbWoUOHVKxYMYv2kydPqkyZMrp7966VKgMgPVqJM2/evPriiy+sXQqALI6P3jNAzZo19c8//ygqKkq5cuUyt3fs2FE5cuSwYmWZw/Xr13Xy5ElJUrFixSz+8McjHh4eMplMMplMevnllxNsN5lMGjJkiBUqyxzKlSun0NDQBOEoNDRUpUuXtlJVAOLFxsZq9OjRWrNmjUqVKpVgQQZW4gSQVpg5gs2Kv05m7ty5iouLk/TotLGPPvpIkyZNIlg+ZsuWLTIMQ7Vq1dLPP/9ssYiAg4ODfH195ePjY8UKbduiRYvUu3dvdevWTVWqVJEk7dq1S5MnT9bIkSNVokQJc99SpUpZq0zgucXKiAAyCuEogyxZskQ//fSTLl68qAcPHlhsO3DggJWqsm2dOnXS+vXr9e2336pq1aqSpG3btql79+564403NGXKFCtXaHsuXLigl156yWIlJzzbsy7wNplMMgxDJpNJsbGxGVQVAADIaJxWlwEmTpyo/v37q3Xr1vr111/Vpk0bnT17Vnv37lWXLl2sXZ7N+vnnn7VkyRLVrFnT3NagQQM5OzvrvffeIxwlYuPGjcqZM6feffddi/bFixfrzp07rPKXhHPnzlm7BAAAYAOYOcoAxYsX16BBg9S8eXO5uroqJCREhQoV0sCBAxUeHq5vv/3W2iXapBw5cmj//v0WpzRJ0rFjx1SpUiXdvn3bSpXZrpdfflnTpk1LcArKli1b1LFjR/O1WwAAAEiIcJQBcuTIodDQUPn6+srT01Pr1q1T6dKldfr0aVWpUkU3btywdok2qXbt2sqTJ4/mzp0rJycnSdLdu3fVqlUrhYeHa/369Vau0PY4OTnpxIkTKliwoEX7+fPnVaJECVZde8zy5ctVv359Zc+eXcuXL39q3/h7kwEAgKyN0+oygLe3t8LDw+Xr66uXXnrJfJ+jc+fOiWyatPHjx6tevXp68cUXzSuGhYSEyNHRUWvXrrVydbbJ09NThw8fThCOQkJClCdPHusUZaMaN26ssLAweXp6qnHjxkn24zojAACeH4SjDFCrVi0tX75cZcuWVZs2bfTJJ59oyZIl2rdvn5o0aWLt8mxWQECATp8+rfnz5+vEiROSpObNm6tFixZydna2cnW2qXnz5urevbtcXV1VvXp1SY9OqevRo4eaNWtm5epsS/wKiE/+GwAAPL84rS4DxMXFKS4uTtmyPcqiP/74o3bs2KGiRYuqU6dOcnBwsHKFtmnEiBHy8vJS27ZtLdpnzpyp69evq0+fPlaqzHY9ePBALVu21OLFi83fb3Fxcfroo480depUvteeYsOGDdqwYYOuXbtmEZZMJpNmzJhhxcoAAEBGIRzBZhUsWFALFizQq6++atG+e/duNWvWjBXGnuLUqVMKCQmRs7OzAgIC5Ovra+2SbNqQIUM0dOhQVahQQfny5UuwFPrSpUutVBkAAMhInFaXTg4fPpzsvtxUMnFhYWHKly9fgva8efPqypUrVqgo8yhYsKAMw1DhwoXNM0hI2tSpUzV79my1bNnS2qUAAAAr4q+mdFKmTBnzjSOfhou9k1agQAFt375dfn5+Fu3bt2+Xj4+PlaqybXfu3FG3bt00Z84cSY9mkAoVKqRu3bopf/786tu3r5UrtE0PHjxIMEMJAACeP4SjdMIpX/9ehw4d1LNnTz18+FC1atWS9Oi6kN69e+vTTz+1cnW2qV+/fgoJCdHmzZtVr149c3tQUJAGDx5MOEpC+/bttWDBAg0YMMDapQAAACsiHKWTx6/xYGGB1Pn8889148YNde7cWQ8ePJD06D4+ffr0Ub9+/axcnW1atmyZFi1apCpVqlhcN1OyZEmdPXvWipXZnl69epn/HRcXp++++07r169XqVKllD17dou+Y8eOzejyAACAFbAgQwZgYYF/Jzo6WqGhoXJ2dlbRokXl6Oho7ZJsVo4cOXT06FEVKlRIrq6uCgkJUaFChRQSEqLq1asrMjLS2iXajNdffz1Z/UwmkzZu3JjO1QAAAFvAzFEGYGGBfydnzpyqWLGitcvIFCpUqKBVq1apW7dukmSePZo+fboCAwOtWZrN2bRpk7VLAAAANoZwlAFYWAAZZfjw4apfv76OHz+umJgYTZgwQcePH9eOHTu0ZcsWa5cHAABg0+ysXcDzIH5hgVmzZunChQu6cOGCZs6cqU8++UQdOnSwdnnIQqpVq6ZDhw4pJiZGAQEBWrt2rTw9PbVz506VL1/e2uUBAADYNK45ygCGYahv376aOHFigoUFBg4caOXqAAAAAEiEowzFwgJID1FRUcnu6+bmlo6VAAAAZG6EIyCTs7Ozs1i2OzGGYXDDYQAAgGdgQQYgk2PVNQAAgLTBzBGQxfzxxx+aNm2azp49qyVLlih//vyaN2+e/Pz8VK1aNWuXBwAAYLNYrQ7IQn7++WfVrVtXzs7OOnjwoO7fvy9JioyM1PDhw61cHQAAgG0jHAFZyFdffaWpU6fq+++/V/bs2c3tVatW1YEDB6xYGQAAgO0jHAFZyMmTJ1W9evUE7e7u7oqIiMj4ggAAADIRwhGQhXh7e+vMmTMJ2rdt26ZChQpZoSIAAIDMg3AEZCEdOnRQjx49tHv3bplMJl2+fFnz58/XZ599po8//tja5QEAANg0lvIGspC+ffsqLi5OtWvX1p07d1S9enU5Ojrqs88+U7du3axdHgAAgE1jKW8gC3rw4IHOnDmj6Oho+fv7K2fOnNYuCQAAwOYRjgAAAABAXHMEAAAAAJIIRwAAAAAgiXAEAAAAAJIIRwAAAAAgiXAEAMgkNm/eLJPJpIiICGuXAgDIoghHAIB/pWbNmurZs6e1ywAA4F8jHAEA0pVhGIqJibF2GVbz8OFDa5cAAEgmwhEAINVat26tLVu2aMKECTKZTDKZTJo9e7ZMJpN+//13lS9fXo6Ojtq2bZvOnj2rt956S15eXsqZM6cqVqyo9evXW+zv/v376tOnjwoUKCBHR0cVKVJEM2bMSPTYd+7cUf369VW1atVknWq3Y8cOlSlTRk5OTqpQoYKWLVsmk8mkQ4cOmfscPXpU9evXV86cOeXl5aWWLVvqn3/+MW+vWbOmunfvrt69eyt37tzy9vbW4MGDLY5jMpk0ZcoUNWrUSC4uLvr6668lSb/++qvKlSsnJycnFSpUSEOGDHmuQyMA2CLCEQAg1SZMmKDAwEB16NBBV65c0ZUrV1SgQAFJUt++fTVy5EiFhoaqVKlSio6OVoMGDbRhwwYdPHhQ9erVU8OGDXXx4kXz/j766CMtXLhQEydOVGhoqKZNm6acOXMmOG5ERITeeOMNxcXFad26dfLw8HhqnVFRUWrYsKECAgJ04MABDRs2TH369Emwz1q1aqls2bLat2+fVq9eratXr+q9996z6Ddnzhy5uLho9+7dGj16tIYOHap169ZZ9Bk8eLDefvttHTlyRG3bttUff/yhjz76SD169NDx48c1bdo0zZ492xycAAA2wgAA4F+oUaOG0aNHD/PzTZs2GZKMZcuWPfO1JUuWNCZNmmQYhmGcPHnSkGSsW7cu0b7x+w0NDTVKlSplNG3a1Lh//36yapwyZYqRJ08e4+7du+a277//3pBkHDx40DAMwxg2bJhRp04di9ddunTJkGScPHnS/F6rVatm0adixYpGnz59zM8lGT179rToU7t2bWP48OEWbfPmzTPy5cuXrPoBABkjmzWDGQAg66pQoYLF8+joaA0ePFirVq3SlStXFBMTo7t375pnjg4dOiR7e3vVqFHjqft94403VKlSJS1atEj29vbJquXkyZMqVaqUnJyczG2VKlWy6BMSEqJNmzYlOlN19uxZvfzyy5KkUqVKWWzLly+frl27ZtH25HsPCQnR9u3bLWaKYmNjde/ePd25c0c5cuRI1vsAAKQvwhEAIF24uLhYPP/ss8+0bt06jRkzRkWKFJGzs7PeeecdPXjwQJLk7OycrP0GBwfr559/1vHjxxUQEJBm9UZHR6thw4YaNWpUgm358uUz/zt79uwW20wmk+Li4izannzv0dHRGjJkiJo0aZJg348HNgCAdRGOAAD/ioODg2JjY5/Zb/v27WrdurXefvttSY8Cw/nz583bAwICFBcXpy1btigoKCjJ/YwcOVI5c+ZU7dq1tXnzZvn7+z/z2MWKFdMPP/yg+/fvy9HRUZK0d+9eiz7lypXTzz//rIIFCypbtrT99ViuXDmdPHlSRYoUSdP9AgDSFgsyAAD+lYIFC2r37t06f/68/vnnnwSzKPGKFi2qX375RYcOHVJISIg++OADi74FCxZUq1at1LZtWy1btkznzp3T5s2b9dNPPyXY15gxY9SiRQvVqlVLJ06ceGaN8cfq2LGjQkNDtWbNGo0ZM0bSo5kfSerSpYvCw8PVvHlz7d27V2fPntWaNWvUpk2bZIW/pxk4cKDmzp2rIUOG6NixYwoNDdWPP/6oL7/88l/tFwCQtghHAIB/5bPPPpO9vb38/f2VN29ei9XnHjd27FjlypVLr776qho2bKi6deuqXLlyFn2mTJmid955R507d1bx4sXVoUMH3b59O9H9jRs3Tu+9955q1aqlU6dOPbVGNzc3rVixQocOHVKZMmXUv39/DRw4UNL/ndbm4+Oj7du3KzY2VnXq1FFAQIB69uwpDw8P2dn9u1+XdevW1cqVK7V27VpVrFhRVapU0bhx4+Tr6/uv9gsASFsmwzAMaxcBAEBGmz9/vtq0aaPIyMhkX+8EAMjauOYIAPBcmDt3rgoVKqT8+fMrJCREffr00XvvvUcwAgCYcVodACDTGz58uHLmzJnoo379+pKksLAwffjhhypRooQ++eQTvfvuu/ruu++sXDkAwJZwWh0AINMLDw9XeHh4otucnZ2VP3/+DK4IAJAZEY4AAAAAQJxWBwAAAACSCEcAAAAAIIlwBAAAAACSCEcAAAAAIIlwBAAAAACSCEcAAAAAIIlwBAAAAACSCEcAAAAAIEn6fx3Sh0UclrxJAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show data imbalance:\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the distribution of player_class with counts\n",
    "value_counts = loaded_df[dataset_config['target']].value_counts()\n",
    "\n",
    "# print the target values\n",
    "print(f\"Target values: {value_counts.index.tolist()}\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "value_counts.plot(kind='bar')\n",
    "\n",
    "# Add counts as text labels on top of bars\n",
    "for i, count in enumerate(value_counts):\n",
    "    plt.text(i, count, str(count), ha='center', va='bottom')\n",
    "\n",
    "plt.title(f\"Distribution of '{dataset_config['target']}' target\")\n",
    "\n",
    "# -> the dataset is clearly balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b31addf5-650e-4db7-9605-49b1548c034e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250521_225505\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #53~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Jan 15 19:18:46 UTC 2\n",
      "CPU Count:          64\n",
      "Memory Avail:       433.03 GB / 503.54 GB (86.0%)\n",
      "Disk Space Avail:   33790.12 GB / 51214.59 GB (66.0%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[WRAPPER] Running stratified downsampling mode for task: clf\n",
      "\u001b[1;36mInfo:\u001b[0m \n",
      "[INFO] Downsampling dataframe: spotfy_genre (original rows: 10000)\n",
      "\u001b[1;33mInfo:\u001b[0m Trying to sample ~300 rows per class (total=3000)\n",
      "\u001b[1;36mInfo:\u001b[0m Final downsampled dataset has 3000 rows. Per class counts: [country: 300, hip-hop: 300, jazz: 300, rock: 300, metal: 300, pop: 300, electronic: 300, r-n-b: 300, classical: 300, indie: 300]\n",
      "\n",
      "Downsampled 3000 rows for spotfy_genre dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Beginning AutoGluon training ... Time limit = 360s\n",
      "AutoGluon will save models to \"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250521_225505\"\n",
      "Train Data Rows:    2400\n",
      "Train Data Columns: 18\n",
      "Label Column:       track_genre\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 10\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    443426.80 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.80 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['album_name', 'track_name']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 71\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('bool', [])         : 1 | ['explicit']\n",
      "\t\t('float', [])        : 9 | ['danceability', 'energy', 'loudness', 'speechiness', 'acousticness', ...]\n",
      "\t\t('int', [])          : 5 | ['popularity', 'duration_ms', 'key', 'mode', 'time_signature']\n",
      "\t\t('object', [])       : 1 | ['artists']\n",
      "\t\t('object', ['text']) : 2 | ['album_name', 'track_name']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    :  1 | ['artists']\n",
      "\t\t('category', ['text_as_category'])  :  2 | ['album_name', 'track_name']\n",
      "\t\t('float', [])                       :  9 | ['danceability', 'energy', 'loudness', 'speechiness', 'acousticness', ...]\n",
      "\t\t('int', [])                         :  4 | ['popularity', 'duration_ms', 'key', 'time_signature']\n",
      "\t\t('int', ['binned', 'text_special']) : 30 | ['album_name.char_count', 'album_name.word_count', 'album_name.capital_ratio', 'album_name.lower_ratio', 'album_name.digit_ratio', ...]\n",
      "\t\t('int', ['bool'])                   :  2 | ['explicit', 'mode']\n",
      "\t\t('int', ['text_ngram'])             : 68 | ['__nlp__.2022', '__nlp__.all', '__nlp__.and', '__nlp__.ao', '__nlp__.ao vivo', ...]\n",
      "\t4.0s = Fit runtime\n",
      "\t18 features in original data used to generate 116 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.64 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 4.04s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 110 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 237.24s of the 355.93s of remaining time.\n",
      "\t0.2529\t = Validation score   (accuracy)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 236.94s of the 355.63s of remaining time.\n",
      "\t0.3108\t = Validation score   (accuracy)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 236.72s of the 355.41s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.7362\t = Validation score   (accuracy)\n",
      "\t117.4s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 96.81s of the 215.50s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.01%)\n",
      "\t0.6325\t = Validation score   (accuracy)\n",
      "\t105.48s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 355.96s of the 106.43s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.571, 'NeuralNetFastAI_BAG_L1': 0.286, 'KNeighborsDist_BAG_L1': 0.143}\n",
      "\t0.7542\t = Validation score   (accuracy)\n",
      "\t0.18s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 108 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 106.20s of the 106.14s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.7538\t = Validation score   (accuracy)\n",
      "\t109.16s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 355.96s of the -6.43s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetFastAI_BAG_L2': 0.933, 'LightGBMXT_BAG_L1': 0.067}\n",
      "\t0.755\t = Validation score   (accuracy)\n",
      "\t0.22s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 366.73s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 438.6 rows/s (300 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250521_225505\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250521_230121\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #53~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Jan 15 19:18:46 UTC 2\n",
      "CPU Count:          64\n",
      "Memory Avail:       431.98 GB / 503.54 GB (85.8%)\n",
      "Disk Space Avail:   33789.88 GB / 51214.59 GB (66.0%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ... Time limit = 360s\n",
      "AutoGluon will save models to \"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250521_230121\"\n",
      "Train Data Rows:    2400\n",
      "Train Data Columns: 15\n",
      "Label Column:       track_genre\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 10\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    442336.23 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.26 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('bool', [])  : 1 | ['explicit']\n",
      "\t\t('float', []) : 9 | ['danceability', 'energy', 'loudness', 'speechiness', 'acousticness', ...]\n",
      "\t\t('int', [])   : 5 | ['popularity', 'duration_ms', 'key', 'mode', 'time_signature']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 9 | ['danceability', 'energy', 'loudness', 'speechiness', 'acousticness', ...]\n",
      "\t\t('int', [])       : 4 | ['popularity', 'duration_ms', 'key', 'time_signature']\n",
      "\t\t('int', ['bool']) : 2 | ['explicit', 'mode']\n",
      "\t0.1s = Fit runtime\n",
      "\t15 features in original data used to generate 15 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.24 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.11s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 110 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 239.87s of the 359.86s of remaining time.\n",
      "\t0.2521\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 239.80s of the 359.79s of remaining time.\n",
      "\t0.3113\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 239.73s of the 359.72s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.5675\t = Validation score   (accuracy)\n",
      "\t105.73s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 131.11s of the 251.10s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.01%)\n",
      "\t0.6162\t = Validation score   (accuracy)\n",
      "\t133.31s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 359.89s of the 114.22s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.667, 'KNeighborsDist_BAG_L1': 0.25, 'NeuralNetFastAI_BAG_L1': 0.083}\n",
      "\t0.6283\t = Validation score   (accuracy)\n",
      "\t0.18s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 108 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 114.00s of the 113.70s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.6271\t = Validation score   (accuracy)\n",
      "\t98.5s\t = Training   runtime\n",
      "\t0.23s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 12.53s of the 12.23s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.01%)\n",
      "\t0.6008\t = Validation score   (accuracy)\n",
      "\t34.92s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 359.89s of the -25.93s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L2': 0.455, 'LightGBMXT_BAG_L1': 0.273, 'NeuralNetFastAI_BAG_L2': 0.182, 'KNeighborsDist_BAG_L1': 0.091}\n",
      "\t0.6379\t = Validation score   (accuracy)\n",
      "\t0.23s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 386.22s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 515.5 rows/s (300 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250521_230121\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250521_230750\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #53~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Jan 15 19:18:46 UTC 2\n",
      "CPU Count:          64\n",
      "Memory Avail:       431.79 GB / 503.54 GB (85.7%)\n",
      "Disk Space Avail:   33789.79 GB / 51214.59 GB (66.0%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ... Time limit = 360s\n",
      "AutoGluon will save models to \"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250521_230750\"\n",
      "Train Data Rows:    2400\n",
      "Train Data Columns: 18\n",
      "Label Column:       track_genre\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 10\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    442127.35 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.81 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['album_name', 'track_name']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 71\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('bool', [])         : 1 | ['explicit']\n",
      "\t\t('float', [])        : 9 | ['danceability', 'energy', 'loudness', 'speechiness', 'acousticness', ...]\n",
      "\t\t('int', [])          : 5 | ['popularity', 'duration_ms', 'key', 'mode', 'time_signature']\n",
      "\t\t('object', [])       : 1 | ['artists']\n",
      "\t\t('object', ['text']) : 2 | ['album_name', 'track_name']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    :  1 | ['artists']\n",
      "\t\t('category', ['text_as_category'])  :  2 | ['album_name', 'track_name']\n",
      "\t\t('float', [])                       :  9 | ['danceability', 'energy', 'loudness', 'speechiness', 'acousticness', ...]\n",
      "\t\t('int', [])                         :  4 | ['popularity', 'duration_ms', 'key', 'time_signature']\n",
      "\t\t('int', ['binned', 'text_special']) : 30 | ['album_name.char_count', 'album_name.word_count', 'album_name.capital_ratio', 'album_name.lower_ratio', 'album_name.digit_ratio', ...]\n",
      "\t\t('int', ['bool'])                   :  2 | ['explicit', 'mode']\n",
      "\t\t('int', ['text_ngram'])             : 67 | ['__nlp__.2022', '__nlp__.all', '__nlp__.and', '__nlp__.ao', '__nlp__.ao vivo', ...]\n",
      "\t3.7s = Fit runtime\n",
      "\t18 features in original data used to generate 115 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.63 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 3.8s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 110 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 237.41s of the 356.17s of remaining time.\n",
      "\t0.2617\t = Validation score   (accuracy)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 237.23s of the 355.99s of remaining time.\n",
      "\t0.3162\t = Validation score   (accuracy)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 237.02s of the 355.78s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.735\t = Validation score   (accuracy)\n",
      "\t112.32s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 121.80s of the 240.56s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.01%)\n",
      "\t0.6704\t = Validation score   (accuracy)\n",
      "\t130.09s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 356.20s of the 106.02s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetFastAI_BAG_L1': 0.5, 'LightGBMXT_BAG_L1': 0.5}\n",
      "\t0.7575\t = Validation score   (accuracy)\n",
      "\t0.16s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 108 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 105.84s of the 105.79s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.7638\t = Validation score   (accuracy)\n",
      "\t112.67s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 356.20s of the -11.31s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.348, 'NeuralNetFastAI_BAG_L2': 0.348, 'KNeighborsUnif_BAG_L1': 0.174, 'NeuralNetFastAI_BAG_L1': 0.13}\n",
      "\t0.7725\t = Validation score   (accuracy)\n",
      "\t0.19s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 371.57s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 479.3 rows/s (300 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250521_230750\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250521_231406\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #53~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Jan 15 19:18:46 UTC 2\n",
      "CPU Count:          64\n",
      "Memory Avail:       432.71 GB / 503.54 GB (85.9%)\n",
      "Disk Space Avail:   33789.49 GB / 51214.59 GB (66.0%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ... Time limit = 360s\n",
      "AutoGluon will save models to \"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250521_231406\"\n",
      "Train Data Rows:    2400\n",
      "Train Data Columns: 15\n",
      "Label Column:       track_genre\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 10\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    443076.49 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.26 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('bool', [])  : 1 | ['explicit']\n",
      "\t\t('float', []) : 9 | ['danceability', 'energy', 'loudness', 'speechiness', 'acousticness', ...]\n",
      "\t\t('int', [])   : 5 | ['popularity', 'duration_ms', 'key', 'mode', 'time_signature']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 9 | ['danceability', 'energy', 'loudness', 'speechiness', 'acousticness', ...]\n",
      "\t\t('int', [])       : 4 | ['popularity', 'duration_ms', 'key', 'time_signature']\n",
      "\t\t('int', ['bool']) : 2 | ['explicit', 'mode']\n",
      "\t0.1s = Fit runtime\n",
      "\t15 features in original data used to generate 15 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.24 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.1s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 110 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 239.87s of the 359.87s of remaining time.\n",
      "\t0.2629\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 239.80s of the 359.80s of remaining time.\n",
      "\t0.3175\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 239.74s of the 359.74s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.5792\t = Validation score   (accuracy)\n",
      "\t106.8s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 129.20s of the 249.20s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.01%)\n",
      "\t0.6362\t = Validation score   (accuracy)\n",
      "\t136.13s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 359.90s of the 108.63s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\n",
      "\t0.6362\t = Validation score   (accuracy)\n",
      "\t0.19s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 108 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 108.41s of the 108.36s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.6438\t = Validation score   (accuracy)\n",
      "\t101.76s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 359.90s of the 2.31s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetFastAI_BAG_L2': 0.818, 'LightGBMXT_BAG_L1': 0.091, 'KNeighborsUnif_BAG_L1': 0.045, 'NeuralNetFastAI_BAG_L1': 0.045}\n",
      "\t0.6462\t = Validation score   (accuracy)\n",
      "\t0.22s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 357.96s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 586.6 rows/s (300 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250521_231406\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250521_232007\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #53~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Jan 15 19:18:46 UTC 2\n",
      "CPU Count:          64\n",
      "Memory Avail:       433.68 GB / 503.54 GB (86.1%)\n",
      "Disk Space Avail:   33789.34 GB / 51214.59 GB (66.0%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ... Time limit = 360s\n",
      "AutoGluon will save models to \"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250521_232007\"\n",
      "Train Data Rows:    2400\n",
      "Train Data Columns: 18\n",
      "Label Column:       track_genre\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 10\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    444059.86 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.81 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['album_name', 'track_name']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 72\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('bool', [])         : 1 | ['explicit']\n",
      "\t\t('float', [])        : 9 | ['danceability', 'energy', 'loudness', 'speechiness', 'acousticness', ...]\n",
      "\t\t('int', [])          : 5 | ['popularity', 'duration_ms', 'key', 'mode', 'time_signature']\n",
      "\t\t('object', [])       : 1 | ['artists']\n",
      "\t\t('object', ['text']) : 2 | ['album_name', 'track_name']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    :  1 | ['artists']\n",
      "\t\t('category', ['text_as_category'])  :  2 | ['album_name', 'track_name']\n",
      "\t\t('float', [])                       :  9 | ['danceability', 'energy', 'loudness', 'speechiness', 'acousticness', ...]\n",
      "\t\t('int', [])                         :  4 | ['popularity', 'duration_ms', 'key', 'time_signature']\n",
      "\t\t('int', ['binned', 'text_special']) : 30 | ['album_name.char_count', 'album_name.word_count', 'album_name.capital_ratio', 'album_name.lower_ratio', 'album_name.digit_ratio', ...]\n",
      "\t\t('int', ['bool'])                   :  2 | ['explicit', 'mode']\n",
      "\t\t('int', ['text_ngram'])             : 69 | ['__nlp__.2022', '__nlp__.all', '__nlp__.and', '__nlp__.ao', '__nlp__.ao vivo', ...]\n",
      "\t3.8s = Fit runtime\n",
      "\t18 features in original data used to generate 117 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.64 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 3.84s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 110 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 237.38s of the 356.14s of remaining time.\n",
      "\t0.2604\t = Validation score   (accuracy)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 237.24s of the 355.99s of remaining time.\n",
      "\t0.3083\t = Validation score   (accuracy)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 237.06s of the 355.81s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.7417\t = Validation score   (accuracy)\n",
      "\t111.37s\t = Training   runtime\n",
      "\t0.23s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 121.74s of the 240.49s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.01%)\n",
      "\t0.6729\t = Validation score   (accuracy)\n",
      "\t130.14s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 356.16s of the 105.97s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.471, 'NeuralNetFastAI_BAG_L1': 0.353, 'KNeighborsUnif_BAG_L1': 0.176}\n",
      "\t0.7725\t = Validation score   (accuracy)\n",
      "\t0.17s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 108 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 105.77s of the 105.72s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.7588\t = Validation score   (accuracy)\n",
      "\t107.15s\t = Training   runtime\n",
      "\t0.23s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 356.16s of the -5.80s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.385, 'NeuralNetFastAI_BAG_L1': 0.308, 'KNeighborsUnif_BAG_L1': 0.154, 'NeuralNetFastAI_BAG_L2': 0.154}\n",
      "\t0.7754\t = Validation score   (accuracy)\n",
      "\t0.21s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 366.07s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 461.9 rows/s (300 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250521_232007\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250521_232618\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #53~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Jan 15 19:18:46 UTC 2\n",
      "CPU Count:          64\n",
      "Memory Avail:       433.74 GB / 503.54 GB (86.1%)\n",
      "Disk Space Avail:   33789.07 GB / 51214.59 GB (66.0%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ... Time limit = 360s\n",
      "AutoGluon will save models to \"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250521_232618\"\n",
      "Train Data Rows:    2400\n",
      "Train Data Columns: 15\n",
      "Label Column:       track_genre\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 10\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    444147.00 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.26 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('bool', [])  : 1 | ['explicit']\n",
      "\t\t('float', []) : 9 | ['danceability', 'energy', 'loudness', 'speechiness', 'acousticness', ...]\n",
      "\t\t('int', [])   : 5 | ['popularity', 'duration_ms', 'key', 'mode', 'time_signature']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 9 | ['danceability', 'energy', 'loudness', 'speechiness', 'acousticness', ...]\n",
      "\t\t('int', [])       : 4 | ['popularity', 'duration_ms', 'key', 'time_signature']\n",
      "\t\t('int', ['bool']) : 2 | ['explicit', 'mode']\n",
      "\t0.1s = Fit runtime\n",
      "\t15 features in original data used to generate 15 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.24 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.1s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 110 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 239.87s of the 359.87s of remaining time.\n",
      "\t0.2604\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 239.79s of the 359.79s of remaining time.\n",
      "\t0.3083\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 239.73s of the 359.73s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.5754\t = Validation score   (accuracy)\n",
      "\t106.99s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 128.87s of the 248.88s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.01%)\n",
      "\t0.6417\t = Validation score   (accuracy)\n",
      "\t136.32s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 359.90s of the 108.17s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.895, 'KNeighborsDist_BAG_L1': 0.105}\n",
      "\t0.6429\t = Validation score   (accuracy)\n",
      "\t0.16s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 108 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 107.98s of the 107.93s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.6288\t = Validation score   (accuracy)\n",
      "\t102.08s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 359.90s of the 1.66s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.895, 'KNeighborsDist_BAG_L1': 0.105}\n",
      "\t0.6429\t = Validation score   (accuracy)\n",
      "\t0.21s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 358.63s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1700.8 rows/s (300 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250521_232618\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250521_233218\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #53~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Jan 15 19:18:46 UTC 2\n",
      "CPU Count:          64\n",
      "Memory Avail:       430.43 GB / 503.54 GB (85.5%)\n",
      "Disk Space Avail:   33788.94 GB / 51214.59 GB (66.0%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ... Time limit = 360s\n",
      "AutoGluon will save models to \"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250521_233218\"\n",
      "Train Data Rows:    2400\n",
      "Train Data Columns: 18\n",
      "Label Column:       track_genre\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 10\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    440906.15 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.81 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['album_name', 'track_name']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 66\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('bool', [])         : 1 | ['explicit']\n",
      "\t\t('float', [])        : 9 | ['danceability', 'energy', 'loudness', 'speechiness', 'acousticness', ...]\n",
      "\t\t('int', [])          : 5 | ['popularity', 'duration_ms', 'key', 'mode', 'time_signature']\n",
      "\t\t('object', [])       : 1 | ['artists']\n",
      "\t\t('object', ['text']) : 2 | ['album_name', 'track_name']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    :  1 | ['artists']\n",
      "\t\t('category', ['text_as_category'])  :  2 | ['album_name', 'track_name']\n",
      "\t\t('float', [])                       :  9 | ['danceability', 'energy', 'loudness', 'speechiness', 'acousticness', ...]\n",
      "\t\t('int', [])                         :  4 | ['popularity', 'duration_ms', 'key', 'time_signature']\n",
      "\t\t('int', ['binned', 'text_special']) : 32 | ['album_name.char_count', 'album_name.word_count', 'album_name.capital_ratio', 'album_name.lower_ratio', 'album_name.digit_ratio', ...]\n",
      "\t\t('int', ['bool'])                   :  2 | ['explicit', 'mode']\n",
      "\t\t('int', ['text_ngram'])             : 63 | ['__nlp__.2022', '__nlp__.all', '__nlp__.and', '__nlp__.ao', '__nlp__.ao vivo', ...]\n",
      "\t3.7s = Fit runtime\n",
      "\t18 features in original data used to generate 113 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.62 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 3.7s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 110 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 237.47s of the 356.28s of remaining time.\n",
      "\t0.2483\t = Validation score   (accuracy)\n",
      "\t0.03s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 237.27s of the 356.07s of remaining time.\n",
      "\t0.315\t = Validation score   (accuracy)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 237.09s of the 355.89s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.735\t = Validation score   (accuracy)\n",
      "\t112.88s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 120.22s of the 239.02s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.01%)\n",
      "\t0.6671\t = Validation score   (accuracy)\n",
      "\t129.11s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 356.30s of the 105.61s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.5, 'NeuralNetFastAI_BAG_L1': 0.333, 'KNeighborsDist_BAG_L1': 0.125, 'KNeighborsUnif_BAG_L1': 0.042}\n",
      "\t0.7629\t = Validation score   (accuracy)\n",
      "\t0.17s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 108 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 105.41s of the 105.36s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.765\t = Validation score   (accuracy)\n",
      "\t110.73s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 356.30s of the -9.65s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetFastAI_BAG_L2': 0.429, 'LightGBMXT_BAG_L1': 0.357, 'NeuralNetFastAI_BAG_L1': 0.214}\n",
      "\t0.7783\t = Validation score   (accuracy)\n",
      "\t0.22s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 369.93s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 495.7 rows/s (300 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250521_233218\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250521_233832\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #53~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Jan 15 19:18:46 UTC 2\n",
      "CPU Count:          64\n",
      "Memory Avail:       432.31 GB / 503.54 GB (85.9%)\n",
      "Disk Space Avail:   33788.63 GB / 51214.59 GB (66.0%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ... Time limit = 360s\n",
      "AutoGluon will save models to \"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250521_233832\"\n",
      "Train Data Rows:    2400\n",
      "Train Data Columns: 15\n",
      "Label Column:       track_genre\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 10\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    442693.74 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.26 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('bool', [])  : 1 | ['explicit']\n",
      "\t\t('float', []) : 9 | ['danceability', 'energy', 'loudness', 'speechiness', 'acousticness', ...]\n",
      "\t\t('int', [])   : 5 | ['popularity', 'duration_ms', 'key', 'mode', 'time_signature']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 9 | ['danceability', 'energy', 'loudness', 'speechiness', 'acousticness', ...]\n",
      "\t\t('int', [])       : 4 | ['popularity', 'duration_ms', 'key', 'time_signature']\n",
      "\t\t('int', ['bool']) : 2 | ['explicit', 'mode']\n",
      "\t0.1s = Fit runtime\n",
      "\t15 features in original data used to generate 15 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.24 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.1s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 110 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 239.87s of the 359.87s of remaining time.\n",
      "\t0.2487\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 239.79s of the 359.79s of remaining time.\n",
      "\t0.3137\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 239.71s of the 359.71s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.5842\t = Validation score   (accuracy)\n",
      "\t107.76s\t = Training   runtime\n",
      "\t0.27s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 128.15s of the 248.15s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.01%)\n",
      "\t0.6271\t = Validation score   (accuracy)\n",
      "\t135.98s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 359.90s of the 107.88s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\n",
      "\t0.6271\t = Validation score   (accuracy)\n",
      "\t0.16s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 108 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 107.70s of the 107.65s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.6342\t = Validation score   (accuracy)\n",
      "\t103.64s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 359.90s of the -0.30s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetFastAI_BAG_L2': 0.545, 'LightGBMXT_BAG_L1': 0.364, 'KNeighborsDist_BAG_L1': 0.091}\n",
      "\t0.6396\t = Validation score   (accuracy)\n",
      "\t0.22s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 360.57s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 514.7 rows/s (300 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250521_233832\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250521_234436\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #53~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Jan 15 19:18:46 UTC 2\n",
      "CPU Count:          64\n",
      "Memory Avail:       432.87 GB / 503.54 GB (86.0%)\n",
      "Disk Space Avail:   33788.50 GB / 51214.59 GB (66.0%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ... Time limit = 360s\n",
      "AutoGluon will save models to \"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250521_234436\"\n",
      "Train Data Rows:    2400\n",
      "Train Data Columns: 18\n",
      "Label Column:       track_genre\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 10\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    443231.34 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.81 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['album_name', 'track_name']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 72\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('bool', [])         : 1 | ['explicit']\n",
      "\t\t('float', [])        : 9 | ['danceability', 'energy', 'loudness', 'speechiness', 'acousticness', ...]\n",
      "\t\t('int', [])          : 5 | ['popularity', 'duration_ms', 'key', 'mode', 'time_signature']\n",
      "\t\t('object', [])       : 1 | ['artists']\n",
      "\t\t('object', ['text']) : 2 | ['album_name', 'track_name']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    :  1 | ['artists']\n",
      "\t\t('category', ['text_as_category'])  :  2 | ['album_name', 'track_name']\n",
      "\t\t('float', [])                       :  9 | ['danceability', 'energy', 'loudness', 'speechiness', 'acousticness', ...]\n",
      "\t\t('int', [])                         :  4 | ['popularity', 'duration_ms', 'key', 'time_signature']\n",
      "\t\t('int', ['binned', 'text_special']) : 30 | ['album_name.char_count', 'album_name.word_count', 'album_name.capital_ratio', 'album_name.lower_ratio', 'album_name.digit_ratio', ...]\n",
      "\t\t('int', ['bool'])                   :  2 | ['explicit', 'mode']\n",
      "\t\t('int', ['text_ngram'])             : 68 | ['__nlp__.2022', '__nlp__.all', '__nlp__.and', '__nlp__.ao', '__nlp__.are', ...]\n",
      "\t4.9s = Fit runtime\n",
      "\t18 features in original data used to generate 116 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.64 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 4.95s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 110 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 236.64s of the 355.02s of remaining time.\n",
      "\t0.2571\t = Validation score   (accuracy)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 236.47s of the 354.86s of remaining time.\n",
      "\t0.3254\t = Validation score   (accuracy)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 236.32s of the 354.70s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.7442\t = Validation score   (accuracy)\n",
      "\t111.69s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 120.70s of the 239.09s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.01%)\n",
      "\t0.6608\t = Validation score   (accuracy)\n",
      "\t130.19s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 355.05s of the 104.62s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.5, 'NeuralNetFastAI_BAG_L1': 0.417, 'KNeighborsUnif_BAG_L1': 0.083}\n",
      "\t0.7692\t = Validation score   (accuracy)\n",
      "\t0.17s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 108 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 104.41s of the 104.36s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.765\t = Validation score   (accuracy)\n",
      "\t109.3s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 355.05s of the -9.17s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetFastAI_BAG_L1': 0.333, 'LightGBMXT_BAG_L1': 0.292, 'NeuralNetFastAI_BAG_L2': 0.25, 'KNeighborsUnif_BAG_L1': 0.125}\n",
      "\t0.7733\t = Validation score   (accuracy)\n",
      "\t0.19s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 369.43s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 459.5 rows/s (300 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250521_234436\")\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250521_235050\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #53~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Jan 15 19:18:46 UTC 2\n",
      "CPU Count:          64\n",
      "Memory Avail:       432.20 GB / 503.54 GB (85.8%)\n",
      "Disk Space Avail:   33788.11 GB / 51214.59 GB (66.0%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ... Time limit = 360s\n",
      "AutoGluon will save models to \"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250521_235050\"\n",
      "Train Data Rows:    2400\n",
      "Train Data Columns: 15\n",
      "Label Column:       track_genre\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 10\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    442559.74 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.26 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('bool', [])  : 1 | ['explicit']\n",
      "\t\t('float', []) : 9 | ['danceability', 'energy', 'loudness', 'speechiness', 'acousticness', ...]\n",
      "\t\t('int', [])   : 5 | ['popularity', 'duration_ms', 'key', 'mode', 'time_signature']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 9 | ['danceability', 'energy', 'loudness', 'speechiness', 'acousticness', ...]\n",
      "\t\t('int', [])       : 4 | ['popularity', 'duration_ms', 'key', 'time_signature']\n",
      "\t\t('int', ['bool']) : 2 | ['explicit', 'mode']\n",
      "\t0.1s = Fit runtime\n",
      "\t15 features in original data used to generate 15 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.24 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.11s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 110 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 239.87s of the 359.86s of remaining time.\n",
      "\t0.2587\t = Validation score   (accuracy)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 239.80s of the 359.79s of remaining time.\n",
      "\t0.3254\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 239.73s of the 359.73s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.5775\t = Validation score   (accuracy)\n",
      "\t107.05s\t = Training   runtime\n",
      "\t0.23s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 128.78s of the 248.77s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.01%)\n",
      "\t0.6246\t = Validation score   (accuracy)\n",
      "\t136.27s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 359.89s of the 108.28s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.7, 'KNeighborsDist_BAG_L1': 0.2, 'NeuralNetFastAI_BAG_L1': 0.1}\n",
      "\t0.6392\t = Validation score   (accuracy)\n",
      "\t0.16s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 108 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 108.08s of the 108.04s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.6412\t = Validation score   (accuracy)\n",
      "\t103.45s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 359.89s of the 0.36s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetFastAI_BAG_L2': 0.905, 'KNeighborsDist_BAG_L1': 0.048, 'LightGBMXT_BAG_L1': 0.048}\n",
      "\t0.645\t = Validation score   (accuracy)\n",
      "\t0.19s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 359.89s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 503.8 rows/s (300 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250521_235050\")\n"
     ]
    }
   ],
   "source": [
    "from baseline_eval import evaluate_baseline, plot_model_performance_summary\n",
    "results = evaluate_baseline(\n",
    "    df=loaded_df,\n",
    "    model='AGTabular',\n",
    "    df_name=dataset_config['dataset_name'],\n",
    "    label_col=dataset_config['target'],\n",
    "    task_type=dataset_config['task'],\n",
    "    textual_cols=textual_cols,\n",
    "    k_folds=5,\n",
    "    seed=0,\n",
    "    max_samples=3000,\n",
    "    output_path=f\"../../baseline_results/{dataset_config['task']}/{dataset_config['dataset_name']}.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77c9f990-010d-4797-b1c3-4ddb5947a84b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving plot to ../../baseline_results/plots/clf/score\n",
      "Saving plot to ../../baseline_results/plots/clf/loss\n",
      "Saving plot to ../../baseline_results/plots/clf/roc_auc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score':                                     mean       std\n",
       " model                                             \n",
       " AutoGluon_Tabular_without_text  0.635667  0.013049\n",
       " AutoGluon_Tabular_with_text     0.734667  0.005821,\n",
       " 'loss':                                     mean       std\n",
       " model                                             \n",
       " AutoGluon_Tabular_with_text     0.870805  0.045257\n",
       " AutoGluon_Tabular_without_text  1.182835  0.095833,\n",
       " 'roc_auc':                                     mean       std\n",
       " model                                             \n",
       " AutoGluon_Tabular_without_text  0.922357  0.006047\n",
       " AutoGluon_Tabular_with_text     0.955882  0.003983}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs = pd.read_csv(f\"../../baseline_results/{dataset_config['task']}/{dataset_config['dataset_name']}.csv\")\n",
    "plot_model_performance_summary(name=dataset_config['dataset_name'],task=dataset_config['task'], df=rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a2d5c0-88e3-4ead-9223-9a03d72e6b6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
