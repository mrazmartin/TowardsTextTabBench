{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0200d09",
   "metadata": {},
   "source": [
    "### Let's start with downloading the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4d0c4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "# to reach the dataloader_functions module\n",
    "module_path = os.path.abspath(os.path.join( \"..\"))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from dataloader_functions.download_data import download_raw_data\n",
    "current_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b8103e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO update this section per dataset\n",
    "dataset_config = {\n",
    "    'dataset_name': 'job_frauds',\n",
    "    'source': 'kaggle', # ['kaggle', 'local', 'openml', 'hf']\n",
    "    'remote_path': 'shivamb/real-or-fake-fake-jobposting-prediction',\n",
    "    'files': ['fake_job_postings.csv'],\n",
    "    'rename_files': ['fake_job_postings.csv'],\n",
    "    'task': 'clf', # ['reg', 'clf']\n",
    "    'target': 'fraudulent',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4336bfef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36mInfo:\u001b[0m Dataset already downloaded in \u001b[1;35m/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/../../datasets_files/raw/classification/job_frauds\u001b[0m.\n",
      "Downloaded job_frauds dataset to /home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/../../datasets_files/raw/classification/job_frauds\n"
     ]
    }
   ],
   "source": [
    "if dataset_config['task'] == 'clf':\n",
    "    dataset_subfolder = os.path.join('raw', 'classification', dataset_config['dataset_name']) \n",
    "elif dataset_config['task'] == 'reg':\n",
    "    dataset_subfolder = os.path.join('raw', 'regression', dataset_config['dataset_name'])\n",
    "else:\n",
    "    raise ValueError(f\"Unknown task: {dataset_config['task']}\")\n",
    "\n",
    "# this path needs to be modified based on the location of the notebook\n",
    "download_path = os.path.join(current_dir, '..', '..', 'datasets_files', dataset_subfolder)\n",
    "\n",
    "if download_raw_data(\n",
    "    dataset_config=dataset_config,\n",
    "    download_path=download_path,\n",
    "    force_download=False,\n",
    "    remove_unlisted=True,\n",
    ") is not None:\n",
    "    print(f\"Downloaded {dataset_config['dataset_name']} dataset to {download_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d886637",
   "metadata": {},
   "source": [
    "### Now we need to preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48bcaebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader_functions.load_and_pp_raw_data import _drop_empty_columns, _drop_single_value_columns\n",
    "from dataloader_functions.utils.data_2_df import read_any_to_df\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "current_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0861820c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading /home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/../../datasets_files/raw/classification/job_frauds/fake_job_postings.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>title</th>\n",
       "      <th>location</th>\n",
       "      <th>department</th>\n",
       "      <th>salary_range</th>\n",
       "      <th>company_profile</th>\n",
       "      <th>description</th>\n",
       "      <th>requirements</th>\n",
       "      <th>benefits</th>\n",
       "      <th>telecommuting</th>\n",
       "      <th>has_company_logo</th>\n",
       "      <th>has_questions</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>required_experience</th>\n",
       "      <th>required_education</th>\n",
       "      <th>industry</th>\n",
       "      <th>function</th>\n",
       "      <th>fraudulent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Marketing Intern</td>\n",
       "      <td>US, NY, New York</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We're Food52, and we've created a groundbreaki...</td>\n",
       "      <td>Food52, a fast-growing, James Beard Award-winn...</td>\n",
       "      <td>Experience with content management systems a m...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Other</td>\n",
       "      <td>Internship</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Customer Service - Cloud Video Production</td>\n",
       "      <td>NZ, , Auckland</td>\n",
       "      <td>Success</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90 Seconds, the worlds Cloud Video Production ...</td>\n",
       "      <td>Organised - Focused - Vibrant - Awesome!Do you...</td>\n",
       "      <td>What we expect from you:Your key responsibilit...</td>\n",
       "      <td>What you will get from usThrough being part of...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Marketing and Advertising</td>\n",
       "      <td>Customer Service</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Commissioning Machinery Assistant (CMA)</td>\n",
       "      <td>US, IA, Wever</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Valor Services provides Workforce Solutions th...</td>\n",
       "      <td>Our client, located in Houston, is actively se...</td>\n",
       "      <td>Implement pre-commissioning and commissioning ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   job_id                                      title          location  \\\n",
       "0       1                           Marketing Intern  US, NY, New York   \n",
       "1       2  Customer Service - Cloud Video Production    NZ, , Auckland   \n",
       "2       3    Commissioning Machinery Assistant (CMA)     US, IA, Wever   \n",
       "\n",
       "  department salary_range                                    company_profile  \\\n",
       "0  Marketing          NaN  We're Food52, and we've created a groundbreaki...   \n",
       "1    Success          NaN  90 Seconds, the worlds Cloud Video Production ...   \n",
       "2        NaN          NaN  Valor Services provides Workforce Solutions th...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Food52, a fast-growing, James Beard Award-winn...   \n",
       "1  Organised - Focused - Vibrant - Awesome!Do you...   \n",
       "2  Our client, located in Houston, is actively se...   \n",
       "\n",
       "                                        requirements  \\\n",
       "0  Experience with content management systems a m...   \n",
       "1  What we expect from you:Your key responsibilit...   \n",
       "2  Implement pre-commissioning and commissioning ...   \n",
       "\n",
       "                                            benefits  telecommuting  \\\n",
       "0                                                NaN              0   \n",
       "1  What you will get from usThrough being part of...              0   \n",
       "2                                                NaN              0   \n",
       "\n",
       "   has_company_logo  has_questions employment_type required_experience  \\\n",
       "0                 1              0           Other          Internship   \n",
       "1                 1              0       Full-time      Not Applicable   \n",
       "2                 1              0             NaN                 NaN   \n",
       "\n",
       "  required_education                   industry          function  fraudulent  \n",
       "0                NaN                        NaN         Marketing           0  \n",
       "1                NaN  Marketing and Advertising  Customer Service           0  \n",
       "2                NaN                        NaN               NaN           0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dataset_files_df = []\n",
    "\n",
    "if dataset_config['rename_files'] is None or len(dataset_config['rename_files']) == 0:\n",
    "    dataset_config['rename_files'] = dataset_config['files']\n",
    "\n",
    "for file in dataset_config['rename_files']:\n",
    "\n",
    "    file_location = os.path.join(download_path, file)\n",
    "\n",
    "    print(f\"Loading {file_location}\")\n",
    "\n",
    "    dataset_files_df.append(read_any_to_df(file_location))\n",
    "\n",
    "# example of the loaded df data:\n",
    "pd.set_option('display.max_columns', None)\n",
    "dataset_files_df[0].head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d099b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped: Index(['department', 'salary_range'], dtype='object')\n",
      "Dataframe shape before/afrer cleaning: (17880, 18) / (17880, 16)\n"
     ]
    }
   ],
   "source": [
    "## Run some basic data cleaning\n",
    "\n",
    "dataset_files_gen_cleaned = []\n",
    "missing_ratio_threshold = 0.5 # TODO the threshold can be changed\n",
    "\n",
    "for df_file in dataset_files_df:\n",
    "    df_size = df_file.shape\n",
    "    # 1. Drop columns with more than 50% missing values\n",
    "    df_file = _drop_empty_columns(df_file, threshold=missing_ratio_threshold)   \n",
    "    # 2. Drop columns with only one unique value\n",
    "    df_file = _drop_single_value_columns(df_file)\n",
    "    # 3. remove duplicates\n",
    "    df_file = df_file.drop_duplicates()\n",
    "    # 4. remove rows with missing target values\n",
    "    df_file = df_file[df_file[dataset_config['target']].notna()]\n",
    "    # 5. drop unnamed columns\n",
    "    df_file = df_file.loc[:, ~df_file.columns.str.contains('^Unnamed')]\n",
    "\n",
    "    dataset_files_gen_cleaned.append(df_file)\n",
    "\n",
    "    print(f\"Dataframe shape before/afrer cleaning: {df_size} / {df_file.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0a2a11a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe shape before/afrer by-hand cleaning: (17880, 16) / (17880, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>location</th>\n",
       "      <th>company_profile</th>\n",
       "      <th>description</th>\n",
       "      <th>requirements</th>\n",
       "      <th>benefits</th>\n",
       "      <th>telecommuting</th>\n",
       "      <th>has_company_logo</th>\n",
       "      <th>has_questions</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>required_experience</th>\n",
       "      <th>required_education</th>\n",
       "      <th>industry</th>\n",
       "      <th>function</th>\n",
       "      <th>fraudulent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Marketing Intern</td>\n",
       "      <td>US, NY, New York</td>\n",
       "      <td>We're Food52, and we've created a groundbreaki...</td>\n",
       "      <td>Food52, a fast-growing, James Beard Award-winn...</td>\n",
       "      <td>Experience with content management systems a m...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Other</td>\n",
       "      <td>Internship</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Customer Service - Cloud Video Production</td>\n",
       "      <td>NZ, , Auckland</td>\n",
       "      <td>90 Seconds, the worlds Cloud Video Production ...</td>\n",
       "      <td>Organised - Focused - Vibrant - Awesome!Do you...</td>\n",
       "      <td>What we expect from you:Your key responsibilit...</td>\n",
       "      <td>What you will get from usThrough being part of...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Marketing and Advertising</td>\n",
       "      <td>Customer Service</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Commissioning Machinery Assistant (CMA)</td>\n",
       "      <td>US, IA, Wever</td>\n",
       "      <td>Valor Services provides Workforce Solutions th...</td>\n",
       "      <td>Our client, located in Houston, is actively se...</td>\n",
       "      <td>Implement pre-commissioning and commissioning ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       title          location  \\\n",
       "0                           Marketing Intern  US, NY, New York   \n",
       "1  Customer Service - Cloud Video Production    NZ, , Auckland   \n",
       "2    Commissioning Machinery Assistant (CMA)     US, IA, Wever   \n",
       "\n",
       "                                     company_profile  \\\n",
       "0  We're Food52, and we've created a groundbreaki...   \n",
       "1  90 Seconds, the worlds Cloud Video Production ...   \n",
       "2  Valor Services provides Workforce Solutions th...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Food52, a fast-growing, James Beard Award-winn...   \n",
       "1  Organised - Focused - Vibrant - Awesome!Do you...   \n",
       "2  Our client, located in Houston, is actively se...   \n",
       "\n",
       "                                        requirements  \\\n",
       "0  Experience with content management systems a m...   \n",
       "1  What we expect from you:Your key responsibilit...   \n",
       "2  Implement pre-commissioning and commissioning ...   \n",
       "\n",
       "                                            benefits  telecommuting  \\\n",
       "0                                                NaN              0   \n",
       "1  What you will get from usThrough being part of...              0   \n",
       "2                                                NaN              0   \n",
       "\n",
       "   has_company_logo  has_questions employment_type required_experience  \\\n",
       "0                 1              0           Other          Internship   \n",
       "1                 1              0       Full-time      Not Applicable   \n",
       "2                 1              0             NaN                 NaN   \n",
       "\n",
       "  required_education                   industry          function  fraudulent  \n",
       "0                NaN                        NaN         Marketing           0  \n",
       "1                NaN  Marketing and Advertising  Customer Service           0  \n",
       "2                NaN                        NaN               NaN           0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## TODO: Now run custom data cleaning -> remove non-essential columns\n",
    "\n",
    "cols_to_drop = ['job_id']\n",
    "\n",
    "dataset_files_cleaned = []\n",
    "\n",
    "# assuming for multiple files we still want to drop the same columns\n",
    "for df_file in dataset_files_gen_cleaned:\n",
    "    df_size = df_file.shape\n",
    "    for col in cols_to_drop:\n",
    "        if col in df_file.columns:\n",
    "            df_file.drop(col, axis=1, inplace=True)\n",
    "        else:\n",
    "            print(f\"Column {col} not found in dataframe\")\n",
    "\n",
    "    dataset_files_cleaned.append(df_file)    \n",
    "    print(f\"Dataframe shape before/afrer by-hand cleaning: {df_size} / {df_file.shape}\")\n",
    "\n",
    "dataset_files_cleaned[0].head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d90a681b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe shape before custom cleaning: (17880, 15)\n",
      "Dataframe shape after custom clearning: (17880, 15)\n"
     ]
    }
   ],
   "source": [
    "# TODO: some custom data cleaning\n",
    "\n",
    "import copy \n",
    "tmp_df = copy.deepcopy(dataset_files_cleaned)\n",
    "dataset_files_by_hand_cleaned = []\n",
    "\n",
    "for df_file in dataset_files_cleaned:\n",
    "    print(f\"Dataframe shape before custom cleaning: {df_file.shape}\")\n",
    "    # TODO: add custom data cleaning here\n",
    "    # e.g. remove columns with too many unique values\n",
    "    print(f\"Dataframe shape after custom clearning: {df_file.shape}\")\n",
    "\n",
    "    dataset_files_by_hand_cleaned.append(df_file)\n",
    "\n",
    "# reset the dataframe list to the version before custom cleaning -> next cells work wuth dataset_files_by_hand_cleaned\n",
    "dataset_files_cleaned = tmp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581b17e1",
   "metadata": {},
   "source": [
    "### Now it is time to visualize our changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1500c210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>location</th>\n",
       "      <th>company_profile</th>\n",
       "      <th>description</th>\n",
       "      <th>requirements</th>\n",
       "      <th>benefits</th>\n",
       "      <th>telecommuting</th>\n",
       "      <th>has_company_logo</th>\n",
       "      <th>has_questions</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>required_experience</th>\n",
       "      <th>required_education</th>\n",
       "      <th>industry</th>\n",
       "      <th>function</th>\n",
       "      <th>fraudulent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Marketing Intern</td>\n",
       "      <td>US, NY, New York</td>\n",
       "      <td>We're Food52, and we've created a groundbreaki...</td>\n",
       "      <td>Food52, a fast-growing, James Beard Award-winn...</td>\n",
       "      <td>Experience with content management systems a m...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Other</td>\n",
       "      <td>Internship</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Customer Service - Cloud Video Production</td>\n",
       "      <td>NZ, , Auckland</td>\n",
       "      <td>90 Seconds, the worlds Cloud Video Production ...</td>\n",
       "      <td>Organised - Focused - Vibrant - Awesome!Do you...</td>\n",
       "      <td>What we expect from you:Your key responsibilit...</td>\n",
       "      <td>What you will get from usThrough being part of...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Marketing and Advertising</td>\n",
       "      <td>Customer Service</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Commissioning Machinery Assistant (CMA)</td>\n",
       "      <td>US, IA, Wever</td>\n",
       "      <td>Valor Services provides Workforce Solutions th...</td>\n",
       "      <td>Our client, located in Houston, is actively se...</td>\n",
       "      <td>Implement pre-commissioning and commissioning ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       title          location  \\\n",
       "0                           Marketing Intern  US, NY, New York   \n",
       "1  Customer Service - Cloud Video Production    NZ, , Auckland   \n",
       "2    Commissioning Machinery Assistant (CMA)     US, IA, Wever   \n",
       "\n",
       "                                     company_profile  \\\n",
       "0  We're Food52, and we've created a groundbreaki...   \n",
       "1  90 Seconds, the worlds Cloud Video Production ...   \n",
       "2  Valor Services provides Workforce Solutions th...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Food52, a fast-growing, James Beard Award-winn...   \n",
       "1  Organised - Focused - Vibrant - Awesome!Do you...   \n",
       "2  Our client, located in Houston, is actively se...   \n",
       "\n",
       "                                        requirements  \\\n",
       "0  Experience with content management systems a m...   \n",
       "1  What we expect from you:Your key responsibilit...   \n",
       "2  Implement pre-commissioning and commissioning ...   \n",
       "\n",
       "                                            benefits  telecommuting  \\\n",
       "0                                                NaN              0   \n",
       "1  What you will get from usThrough being part of...              0   \n",
       "2                                                NaN              0   \n",
       "\n",
       "   has_company_logo  has_questions employment_type required_experience  \\\n",
       "0                 1              0           Other          Internship   \n",
       "1                 1              0       Full-time      Not Applicable   \n",
       "2                 1              0             NaN                 NaN   \n",
       "\n",
       "  required_education                   industry          function  fraudulent  \n",
       "0                NaN                        NaN         Marketing           0  \n",
       "1                NaN  Marketing and Advertising  Customer Service           0  \n",
       "2                NaN                        NaN               NaN           0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "dataset_files_by_hand_cleaned[0].head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f71269d",
   "metadata": {},
   "source": [
    "Let's figure out which columns should be viewed as categorical / numerical / textual\n",
    "\n",
    "we can start with a simple heuristic:\n",
    "1. numerical is everything which\n",
    "    - keeps most of its character length after non-numeral strip\n",
    "    - has about the same number of unique values after the strip\n",
    "    + for the purpose of keeping \"semantic information\", hand picked columns can be viewed also as non-numerical, that is not the default benchmark approach though\n",
    "\n",
    "2. categorical is everthing non numerical, which can be then divided into N (where N << Num instances) unique categories\n",
    "\n",
    "3. textual is everything else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "436f9ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold for categorical vs textual: 894\n",
      "Numerical columns (4): ['telecommuting', 'has_company_logo', 'has_questions', 'fraudulent']\n",
      "Categorical columns (5): ['employment_type', 'required_experience', 'required_education', 'industry', 'function']\n",
      "Textual columns (6): ['title', 'location', 'company_profile', 'description', 'requirements', 'benefits']\n",
      "\n",
      "Threshold for categorical vs textual: 50\n",
      "Numerical columns (4): ['telecommuting', 'has_company_logo', 'has_questions', 'fraudulent']\n",
      "Categorical columns (4): ['employment_type', 'required_experience', 'required_education', 'function']\n",
      "Textual columns (7): ['title', 'location', 'company_profile', 'description', 'requirements', 'benefits', 'industry']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def is_mostly_numeric(series, length_threshold=0.5, unique_threshold=0.8):\n",
    "    \"\"\"Check if column is mostly numeric after stripping non-numeric chars.\"\"\"\n",
    "    stripped = series.astype(str).str.replace(r\"[^\\d\\.\\-]\", \"\", regex=True)\n",
    "    \n",
    "    original_len = series.astype(str).str.len().replace(0, 1)  # avoid div by zero\n",
    "    length_ratio = (stripped.str.len() / original_len).mean()\n",
    "\n",
    "    unique_ratio = stripped.nunique(dropna=False) / max(series.nunique(dropna=False), 1)\n",
    "\n",
    "    return length_ratio > length_threshold and unique_ratio > unique_threshold\n",
    "\n",
    "def classify_columns(df, unique_ratio_threshold=None, explicit_nunique_threshold=None):\n",
    "    \"\"\"\n",
    "    Classify dataframe columns into numerical, categorical, textual.\n",
    "    - numerical: true numerics or digit-heavy strings.\n",
    "    - categorical: low-cardinality discrete values.\n",
    "    - textual: high-cardinality free-text fields.\n",
    "\n",
    "    Params:\n",
    "    - unique_ratio_threshold: Ratio (e.g., 0.05 = 5% of dataset size)\n",
    "    - explicit_nunique_threshold: Absolute number (overrides ratio if set)\n",
    "    \"\"\"\n",
    "    n_rows = len(df)\n",
    "\n",
    "    # Determine threshold\n",
    "    if explicit_nunique_threshold is not None:\n",
    "        nunique_threshold = explicit_nunique_threshold\n",
    "    elif unique_ratio_threshold is not None:\n",
    "        nunique_threshold = int(unique_ratio_threshold * n_rows)\n",
    "    else:\n",
    "        nunique_threshold = int(0.05 * n_rows)  # default 5%\n",
    "\n",
    "    nunique_threshold = max(10, nunique_threshold)  # safeguard for small datasets\n",
    "    print(f\"Threshold for categorical vs textual: {nunique_threshold}\")\n",
    "\n",
    "    numerical_cols = []\n",
    "    categorical_cols = []\n",
    "    textual_cols = []\n",
    "\n",
    "    for col in df.columns:\n",
    "        series = df[col]\n",
    "\n",
    "        if pd.api.types.is_numeric_dtype(series):\n",
    "            numerical_cols.append(col)\n",
    "        \n",
    "        elif pd.api.types.is_string_dtype(series) or pd.api.types.is_object_dtype(series):\n",
    "            if is_mostly_numeric(series):\n",
    "                numerical_cols.append(col)\n",
    "            else:\n",
    "                nunique = series.nunique(dropna=False)\n",
    "                if nunique <= nunique_threshold:\n",
    "                    categorical_cols.append(col)\n",
    "                else:\n",
    "                    textual_cols.append(col)\n",
    "        else:\n",
    "            print(f\"⚠️ Unhandled column type: '{col}' (dtype={series.dtype})\")\n",
    "\n",
    "    print(f\"Numerical columns ({len(numerical_cols)}): {numerical_cols}\")\n",
    "    print(f\"Categorical columns ({len(categorical_cols)}): {categorical_cols}\")\n",
    "    print(f\"Textual columns ({len(textual_cols)}): {textual_cols}\")\n",
    "\n",
    "    return numerical_cols, categorical_cols, textual_cols\n",
    "\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "for df_file in dataset_files_by_hand_cleaned:\n",
    "    # Ratio-based (5% of rows)\n",
    "    numerical_cols, categorical_cols, textual_cols = classify_columns(df_file, unique_ratio_threshold=0.05)\n",
    "    print(\"\")\n",
    "    # OR explicit value (e.g., anything <= 50 is categorical)\n",
    "    numerical_cols, categorical_cols, textual_cols = classify_columns(df_file, explicit_nunique_threshold=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6499589b",
   "metadata": {},
   "source": [
    "Now let's just try to visualize the kept features, their example values, and their cat/num/text allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "afffbdb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column Name</th>\n",
       "      <th>Example Value</th>\n",
       "      <th>Type</th>\n",
       "      <th># Categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>title</td>\n",
       "      <td>Marketing Intern</td>\n",
       "      <td>textual</td>\n",
       "      <td>11231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>location</td>\n",
       "      <td>US, NY, New York</td>\n",
       "      <td>textual</td>\n",
       "      <td>3105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>company_profile</td>\n",
       "      <td>We're Food52, and we've created a groundbreaki...</td>\n",
       "      <td>textual</td>\n",
       "      <td>1709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>description</td>\n",
       "      <td>Food52, a fast-growing, James Beard Award-winn...</td>\n",
       "      <td>textual</td>\n",
       "      <td>14801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>requirements</td>\n",
       "      <td>Experience with content management systems a m...</td>\n",
       "      <td>textual</td>\n",
       "      <td>11967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>benefits</td>\n",
       "      <td>What you will get from usThrough being part of...</td>\n",
       "      <td>textual</td>\n",
       "      <td>6204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>telecommuting</td>\n",
       "      <td>0</td>\n",
       "      <td>numerical</td>\n",
       "      <td>~ 2 ~</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>has_company_logo</td>\n",
       "      <td>1</td>\n",
       "      <td>numerical</td>\n",
       "      <td>~ 2 ~</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>has_questions</td>\n",
       "      <td>0</td>\n",
       "      <td>numerical</td>\n",
       "      <td>~ 2 ~</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>employment_type</td>\n",
       "      <td>Other</td>\n",
       "      <td>categorical</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>required_experience</td>\n",
       "      <td>Internship</td>\n",
       "      <td>categorical</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>required_education</td>\n",
       "      <td>Bachelor's Degree</td>\n",
       "      <td>categorical</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>industry</td>\n",
       "      <td>Marketing and Advertising</td>\n",
       "      <td>textual</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>function</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>categorical</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>fraudulent</td>\n",
       "      <td>0</td>\n",
       "      <td>numerical</td>\n",
       "      <td>~ 2 ~</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Column Name                                      Example Value  \\\n",
       "0                 title                                   Marketing Intern   \n",
       "1              location                                   US, NY, New York   \n",
       "2       company_profile  We're Food52, and we've created a groundbreaki...   \n",
       "3           description  Food52, a fast-growing, James Beard Award-winn...   \n",
       "4          requirements  Experience with content management systems a m...   \n",
       "5              benefits  What you will get from usThrough being part of...   \n",
       "6         telecommuting                                                  0   \n",
       "7      has_company_logo                                                  1   \n",
       "8         has_questions                                                  0   \n",
       "9       employment_type                                              Other   \n",
       "10  required_experience                                         Internship   \n",
       "11   required_education                                  Bachelor's Degree   \n",
       "12             industry                          Marketing and Advertising   \n",
       "13             function                                          Marketing   \n",
       "14           fraudulent                                                  0   \n",
       "\n",
       "           Type # Categories  \n",
       "0       textual        11231  \n",
       "1       textual         3105  \n",
       "2       textual         1709  \n",
       "3       textual        14801  \n",
       "4       textual        11967  \n",
       "5       textual         6204  \n",
       "6     numerical        ~ 2 ~  \n",
       "7     numerical        ~ 2 ~  \n",
       "8     numerical        ~ 2 ~  \n",
       "9   categorical            5  \n",
       "10  categorical            7  \n",
       "11  categorical           13  \n",
       "12      textual          131  \n",
       "13  categorical           37  \n",
       "14    numerical        ~ 2 ~  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary = []\n",
    "for col in df_file.columns:\n",
    "    if col in categorical_cols:\n",
    "        col_type = \"categorical\"\n",
    "        num_categories = df_file[col].nunique(dropna=True)\n",
    "        num_categories_display = int(num_categories)\n",
    "    elif col in textual_cols:\n",
    "        col_type = \"textual\"\n",
    "        num_categories = df_file[col].nunique(dropna=True)\n",
    "        num_categories_display = int(num_categories)\n",
    "    elif col in numerical_cols:\n",
    "        col_type = \"numerical\"\n",
    "        num_categories = df_file[col].nunique(dropna=True)\n",
    "        num_categories_display = '~ ' + str(num_categories) + ' ~'\n",
    "    else:\n",
    "        col_type = \"unknown\"\n",
    "        num_categories_display = '--'\n",
    "\n",
    "    example = df_file[col].dropna().iloc[0] if df_file[col].dropna().size > 0 else None\n",
    "    summary.append({\n",
    "        'Column Name': col,\n",
    "        'Example Value': str(example),\n",
    "        'Type': col_type,\n",
    "        '# Categories': num_categories_display\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary)\n",
    "\n",
    "# TODO: by hand changes of the type and category count -> e.g. for 'Location':\n",
    "#    # Post-processing: override the type and category count for 'Location'\n",
    "#    # summary_df.loc[summary_df['Column Name'] == 'Location', 'Type'] = 'textual'\n",
    "#    # num_categories = df_file['Location'].nunique(dropna=True)\n",
    "#    # summary_df.loc[summary_df['Column Name'] == 'Location', '# Categories'] = int(num_categories)\n",
    "\n",
    "display(summary_df)  # Or print(summary_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ef8954",
   "metadata": {},
   "source": [
    "### Saving the processed data and loading it back up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2fe5eab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/../../datasets_files/raw/classification/job_frauds/fake_job_postings_processed.pkl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Handle rename_files fallback\n",
    "if dataset_config['rename_files'] is None or len(dataset_config['rename_files']) == 0:\n",
    "    dataset_config['rename_files'] = dataset_config['files']\n",
    "\n",
    "for i, df_file in enumerate(dataset_files_by_hand_cleaned):\n",
    "    df_with_meta = df_file.copy()\n",
    "\n",
    "    # Get corresponding file name\n",
    "    file_name = dataset_config['rename_files'][i]\n",
    "    file_base = os.path.splitext(file_name)[0]\n",
    "\n",
    "    # Try assigning multi-index header from summary\n",
    "    try:\n",
    "        df_with_meta.columns = pd.MultiIndex.from_frame(\n",
    "            summary_df[['Column Name', 'Type', '# Categories']]\n",
    "        )\n",
    "        local_summary = summary_df.copy()\n",
    "    except ValueError:\n",
    "        local_summary = summary_df.copy()\n",
    "        if dataset_config['target'] in local_summary['Column Name'].values:\n",
    "            local_summary = local_summary[local_summary['Column Name'] != dataset_config['target']]\n",
    "            df_with_meta.columns = pd.MultiIndex.from_frame(\n",
    "                local_summary[['Column Name', 'Type', '# Categories']]\n",
    "            )\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "    # Construct and save everything together\n",
    "    output_filename = f\"{file_base}_processed.pkl\"\n",
    "    output_path = os.path.join(download_path, output_filename)\n",
    "\n",
    "    save_bundle = {\n",
    "        'data': df_with_meta,\n",
    "        'summary': local_summary,\n",
    "        'config': dataset_config\n",
    "    }\n",
    "\n",
    "    pd.to_pickle(save_bundle, output_path)\n",
    "    print(f\"Saved: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c7bcd87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== FAKE_JOB_POSTINGS ===\n",
      "Loaded config keys: ['dataset_name', 'source', 'remote_path', 'files', 'rename_files', 'task', 'target']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column Name</th>\n",
       "      <th>Type</th>\n",
       "      <th># Categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>title</td>\n",
       "      <td>textual</td>\n",
       "      <td>11231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>location</td>\n",
       "      <td>textual</td>\n",
       "      <td>3105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>company_profile</td>\n",
       "      <td>textual</td>\n",
       "      <td>1709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>description</td>\n",
       "      <td>textual</td>\n",
       "      <td>14801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>requirements</td>\n",
       "      <td>textual</td>\n",
       "      <td>11967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>benefits</td>\n",
       "      <td>textual</td>\n",
       "      <td>6204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>telecommuting</td>\n",
       "      <td>numerical</td>\n",
       "      <td>~ 2 ~</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>has_company_logo</td>\n",
       "      <td>numerical</td>\n",
       "      <td>~ 2 ~</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>has_questions</td>\n",
       "      <td>numerical</td>\n",
       "      <td>~ 2 ~</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>employment_type</td>\n",
       "      <td>categorical</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>required_experience</td>\n",
       "      <td>categorical</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>required_education</td>\n",
       "      <td>categorical</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>industry</td>\n",
       "      <td>textual</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>function</td>\n",
       "      <td>categorical</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>fraudulent</td>\n",
       "      <td>numerical</td>\n",
       "      <td>~ 2 ~</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Column Name         Type # Categories\n",
       "0                 title      textual        11231\n",
       "1              location      textual         3105\n",
       "2       company_profile      textual         1709\n",
       "3           description      textual        14801\n",
       "4          requirements      textual        11967\n",
       "5              benefits      textual         6204\n",
       "6         telecommuting    numerical        ~ 2 ~\n",
       "7      has_company_logo    numerical        ~ 2 ~\n",
       "8         has_questions    numerical        ~ 2 ~\n",
       "9       employment_type  categorical            5\n",
       "10  required_experience  categorical            7\n",
       "11   required_education  categorical           13\n",
       "12             industry      textual          131\n",
       "13             function  categorical           37\n",
       "14           fraudulent    numerical        ~ 2 ~"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Column Name</th>\n",
       "      <th>title</th>\n",
       "      <th>location</th>\n",
       "      <th>company_profile</th>\n",
       "      <th>description</th>\n",
       "      <th>requirements</th>\n",
       "      <th>benefits</th>\n",
       "      <th>telecommuting</th>\n",
       "      <th>has_company_logo</th>\n",
       "      <th>has_questions</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>required_experience</th>\n",
       "      <th>required_education</th>\n",
       "      <th>industry</th>\n",
       "      <th>function</th>\n",
       "      <th>fraudulent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Marketing Intern</td>\n",
       "      <td>US, NY, New York</td>\n",
       "      <td>We're Food52, and we've created a groundbreaki...</td>\n",
       "      <td>Food52, a fast-growing, James Beard Award-winn...</td>\n",
       "      <td>Experience with content management systems a m...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Other</td>\n",
       "      <td>Internship</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Customer Service - Cloud Video Production</td>\n",
       "      <td>NZ, , Auckland</td>\n",
       "      <td>90 Seconds, the worlds Cloud Video Production ...</td>\n",
       "      <td>Organised - Focused - Vibrant - Awesome!Do you...</td>\n",
       "      <td>What we expect from you:Your key responsibilit...</td>\n",
       "      <td>What you will get from usThrough being part of...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Marketing and Advertising</td>\n",
       "      <td>Customer Service</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Commissioning Machinery Assistant (CMA)</td>\n",
       "      <td>US, IA, Wever</td>\n",
       "      <td>Valor Services provides Workforce Solutions th...</td>\n",
       "      <td>Our client, located in Houston, is actively se...</td>\n",
       "      <td>Implement pre-commissioning and commissioning ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Column Name                                      title          location  \\\n",
       "0                                     Marketing Intern  US, NY, New York   \n",
       "1            Customer Service - Cloud Video Production    NZ, , Auckland   \n",
       "2              Commissioning Machinery Assistant (CMA)     US, IA, Wever   \n",
       "\n",
       "Column Name                                    company_profile  \\\n",
       "0            We're Food52, and we've created a groundbreaki...   \n",
       "1            90 Seconds, the worlds Cloud Video Production ...   \n",
       "2            Valor Services provides Workforce Solutions th...   \n",
       "\n",
       "Column Name                                        description  \\\n",
       "0            Food52, a fast-growing, James Beard Award-winn...   \n",
       "1            Organised - Focused - Vibrant - Awesome!Do you...   \n",
       "2            Our client, located in Houston, is actively se...   \n",
       "\n",
       "Column Name                                       requirements  \\\n",
       "0            Experience with content management systems a m...   \n",
       "1            What we expect from you:Your key responsibilit...   \n",
       "2            Implement pre-commissioning and commissioning ...   \n",
       "\n",
       "Column Name                                           benefits  telecommuting  \\\n",
       "0                                                          NaN              0   \n",
       "1            What you will get from usThrough being part of...              0   \n",
       "2                                                          NaN              0   \n",
       "\n",
       "Column Name  has_company_logo  has_questions employment_type  \\\n",
       "0                           1              0           Other   \n",
       "1                           1              0       Full-time   \n",
       "2                           1              0             NaN   \n",
       "\n",
       "Column Name required_experience required_education                   industry  \\\n",
       "0                    Internship                NaN                        NaN   \n",
       "1                Not Applicable                NaN  Marketing and Advertising   \n",
       "2                           NaN                NaN                        NaN   \n",
       "\n",
       "Column Name          function  fraudulent  \n",
       "0                   Marketing           0  \n",
       "1            Customer Service           0  \n",
       "2                         NaN           0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Loop through processed files in rename_files\n",
    "for file_name in dataset_config['rename_files']:\n",
    "    # Remove .csv or .tsv extension to get the base name\n",
    "    file_base = os.path.splitext(file_name)[0]\n",
    "    processed_filename = f\"{file_base}_processed.pkl\"\n",
    "    processed_path = os.path.join(download_path, processed_filename)\n",
    "\n",
    "    # Load the bundled dictionary (data + summary + config)\n",
    "    bundle = pd.read_pickle(processed_path)\n",
    "\n",
    "    # Extract components\n",
    "    loaded_df = bundle['data']\n",
    "    summary_df = bundle['summary']\n",
    "    loaded_config = bundle['config']\n",
    "\n",
    "    print(f\"\\n=== {file_base.upper()} ===\")\n",
    "    print(f\"Loaded config keys: {list(loaded_config.keys())}\")\n",
    "\n",
    "    # Show metadata\n",
    "    meta_df = pd.DataFrame(loaded_df.columns.tolist(), columns=['Column Name', 'Type', '# Categories'])\n",
    "    display(meta_df)\n",
    "\n",
    "    # Flatten for modeling\n",
    "    loaded_df.columns = loaded_df.columns.get_level_values(0)\n",
    "    display(loaded_df.head(n=3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef581451",
   "metadata": {},
   "source": [
    "### Bonus insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4fe3eb34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, \"Distribution of 'fraudulent' target\")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show data imbalance:\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the distribution of player_class with counts\n",
    "value_counts = loaded_df[dataset_config['target']].value_counts()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "value_counts.plot(kind='bar')\n",
    "\n",
    "# Add counts as text labels on top of bars\n",
    "for i, count in enumerate(value_counts):\n",
    "    plt.text(i, count, str(count), ha='center', va='bottom')\n",
    "\n",
    "plt.title(f\"Distribution of '{dataset_config['target']}' target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3c4c4ad-5267-4c11-a9ec-914ff18f5bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250522_160042\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #53~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Jan 15 19:18:46 UTC 2\n",
      "CPU Count:          64\n",
      "Memory Avail:       434.64 GB / 503.54 GB (86.3%)\n",
      "Disk Space Avail:   33781.69 GB / 51214.59 GB (66.0%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=0, num_bag_folds=8, num_bag_sets=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[WRAPPER] Running stratified downsampling mode for task: clf\n",
      "\u001b[1;36mInfo:\u001b[0m \n",
      "[INFO] Downsampling dataframe: job_frauds (original rows: 17880)\n",
      "\u001b[1;33mInfo:\u001b[0m Trying to sample ~1500 rows per class (total=3000)\n",
      "\u001b[1;32mInfo:\u001b[0m [INFO] Class 1 has only 866 instances. Keeping all.\n",
      "\u001b[1;36mInfo:\u001b[0m Final downsampled dataset has 3000 rows. Per class counts: [0: 2134, 1: 866]\n",
      "\n",
      "Downsampled 3000 rows for job_frauds dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Beginning AutoGluon training ... Time limit = 360s\n",
      "AutoGluon will save models to \"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250522_160042\"\n",
      "Train Data Rows:    2400\n",
      "Train Data Columns: 14\n",
      "Label Column:       fraudulent\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    445112.77 MB\n",
      "\tTrain Data (Original)  Memory Usage: 10.07 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['title', 'location', 'company_profile', 'description', 'requirements', 'benefits']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 6629\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])          : 3 | ['telecommuting', 'has_company_logo', 'has_questions']\n",
      "\t\t('object', [])       : 5 | ['employment_type', 'required_experience', 'required_education', 'industry', 'function']\n",
      "\t\t('object', ['text']) : 6 | ['title', 'location', 'company_profile', 'description', 'requirements', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    :    5 | ['employment_type', 'required_experience', 'required_education', 'industry', 'function']\n",
      "\t\t('category', ['text_as_category'])  :    6 | ['title', 'location', 'company_profile', 'description', 'requirements', ...]\n",
      "\t\t('int', ['binned', 'text_special']) :  154 | ['title.char_count', 'title.word_count', 'title.capital_ratio', 'title.lower_ratio', 'title.digit_ratio', ...]\n",
      "\t\t('int', ['bool'])                   :    3 | ['telecommuting', 'has_company_logo', 'has_questions']\n",
      "\t\t('int', ['text_ngram'])             : 5914 | ['__nlp__.00', '__nlp__.000', '__nlp__.000 people', '__nlp__.000 people in', '__nlp__.000 per', ...]\n",
      "\t66.3s = Fit runtime\n",
      "\t14 features in original data used to generate 6082 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 27.47 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 67.66s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 110 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 292.34s of the 292.32s of remaining time.\n",
      "\t0.8692\t = Validation score   (accuracy)\n",
      "\t3.0s\t = Training   runtime\n",
      "\t1.59s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 281.90s of the 281.88s of remaining time.\n",
      "\t0.8762\t = Validation score   (accuracy)\n",
      "\t2.99s\t = Training   runtime\n",
      "\t1.49s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 271.71s of the 271.69s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.29%)\n",
      "\t0.9646\t = Validation score   (accuracy)\n",
      "\t169.48s\t = Training   runtime\n",
      "\t0.38s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 74.04s of the 74.02s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.29%)\n",
      "\t0.9325\t = Validation score   (accuracy)\n",
      "\t78.33s\t = Training   runtime\n",
      "\t0.32s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 292.34s of the -16.51s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\n",
      "\t0.9646\t = Validation score   (accuracy)\n",
      "\t0.13s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 377.09s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 790.7 rows/s (300 batch size)\n",
      "Disabling decision threshold calibration for metric `accuracy` due to having fewer than 10000 rows of validation data for calibration, to avoid overfitting (2400 rows).\n",
      "\t`accuracy` is generally not improved through threshold calibration. Force calibration via specifying `calibrate_decision_threshold=True`.\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250522_160042\")\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250522_160704\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #53~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Jan 15 19:18:46 UTC 2\n",
      "CPU Count:          64\n",
      "Memory Avail:       432.24 GB / 503.54 GB (85.8%)\n",
      "Disk Space Avail:   33778.89 GB / 51214.59 GB (66.0%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=0, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ... Time limit = 360s\n",
      "AutoGluon will save models to \"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250522_160704\"\n",
      "Train Data Rows:    2400\n",
      "Train Data Columns: 7\n",
      "Label Column:       fraudulent\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    442607.20 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.56 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])    : 3 | ['telecommuting', 'has_company_logo', 'has_questions']\n",
      "\t\t('object', []) : 4 | ['employment_type', 'required_experience', 'required_education', 'function']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 4 | ['employment_type', 'required_experience', 'required_education', 'function']\n",
      "\t\t('int', ['bool']) : 3 | ['telecommuting', 'has_company_logo', 'has_questions']\n",
      "\t0.1s = Fit runtime\n",
      "\t7 features in original data used to generate 7 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.02 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.15s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 110 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 359.85s of the 359.82s of remaining time.\n",
      "\tNo valid features to train KNeighborsUnif_BAG_L1... Skipping this model.\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 359.65s of the 359.62s of remaining time.\n",
      "\tNo valid features to train KNeighborsDist_BAG_L1... Skipping this model.\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 359.48s of the 359.45s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.8542\t = Validation score   (accuracy)\n",
      "\t49.5s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 307.26s of the 307.24s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.8575\t = Validation score   (accuracy)\n",
      "\t51.0s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 253.53s of the 253.51s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.8496\t = Validation score   (accuracy)\n",
      "\t1.24s\t = Training   runtime\n",
      "\t0.3s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 251.83s of the 251.80s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.8508\t = Validation score   (accuracy)\n",
      "\t1.12s\t = Training   runtime\n",
      "\t0.3s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 250.26s of the 250.24s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.09%)\n",
      "\t0.8458\t = Validation score   (accuracy)\n",
      "\t73.33s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 174.08s of the 174.06s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.8504\t = Validation score   (accuracy)\n",
      "\t1.16s\t = Training   runtime\n",
      "\t0.3s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 172.44s of the 172.42s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.8512\t = Validation score   (accuracy)\n",
      "\t1.12s\t = Training   runtime\n",
      "\t0.31s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 170.74s of the 170.71s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.8625\t = Validation score   (accuracy)\n",
      "\t101.25s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 66.92s of the 66.90s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.8592\t = Validation score   (accuracy)\n",
      "\t39.07s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 25.12s of the 25.09s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\tTime limit exceeded... Skipping NeuralNetTorch_BAG_L1.\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 15.06s of the 15.03s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.8471\t = Validation score   (accuracy)\n",
      "\t40.18s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 359.85s of the -28.15s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetFastAI_BAG_L1': 0.64, 'XGBoost_BAG_L1': 0.16, 'RandomForestGini_BAG_L1': 0.08, 'CatBoost_BAG_L1': 0.08, 'ExtraTreesEntr_BAG_L1': 0.04}\n",
      "\t0.8646\t = Validation score   (accuracy)\n",
      "\t0.2s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 388.42s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 613.4 rows/s (300 batch size)\n",
      "Disabling decision threshold calibration for metric `accuracy` due to having fewer than 10000 rows of validation data for calibration, to avoid overfitting (2400 rows).\n",
      "\t`accuracy` is generally not improved through threshold calibration. Force calibration via specifying `calibrate_decision_threshold=True`.\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250522_160704\")\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250522_161339\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #53~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Jan 15 19:18:46 UTC 2\n",
      "CPU Count:          64\n",
      "Memory Avail:       429.55 GB / 503.54 GB (85.3%)\n",
      "Disk Space Avail:   33778.55 GB / 51214.59 GB (66.0%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=0, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ... Time limit = 360s\n",
      "AutoGluon will save models to \"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250522_161339\"\n",
      "Train Data Rows:    2400\n",
      "Train Data Columns: 14\n",
      "Label Column:       fraudulent\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    439880.68 MB\n",
      "\tTrain Data (Original)  Memory Usage: 13.73 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['title', 'location', 'company_profile', 'description', 'requirements', 'benefits']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 6780\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])          : 3 | ['telecommuting', 'has_company_logo', 'has_questions']\n",
      "\t\t('object', [])       : 5 | ['employment_type', 'required_experience', 'required_education', 'industry', 'function']\n",
      "\t\t('object', ['text']) : 6 | ['title', 'location', 'company_profile', 'description', 'requirements', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    :    5 | ['employment_type', 'required_experience', 'required_education', 'industry', 'function']\n",
      "\t\t('category', ['text_as_category'])  :    6 | ['title', 'location', 'company_profile', 'description', 'requirements', ...]\n",
      "\t\t('int', ['binned', 'text_special']) :  150 | ['title.char_count', 'title.word_count', 'title.capital_ratio', 'title.lower_ratio', 'title.digit_ratio', ...]\n",
      "\t\t('int', ['bool'])                   :    3 | ['telecommuting', 'has_company_logo', 'has_questions']\n",
      "\t\t('int', ['text_ngram'])             : 5873 | ['__nlp__.00', '__nlp__.000', '__nlp__.000 people', '__nlp__.000 people in', '__nlp__.000 per', ...]\n",
      "\t67.1s = Fit runtime\n",
      "\t14 features in original data used to generate 6037 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 27.27 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 68.32s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 110 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 291.68s of the 291.65s of remaining time.\n",
      "\t0.8621\t = Validation score   (accuracy)\n",
      "\t3.04s\t = Training   runtime\n",
      "\t1.51s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 281.49s of the 281.46s of remaining time.\n",
      "\t0.8721\t = Validation score   (accuracy)\n",
      "\t3.01s\t = Training   runtime\n",
      "\t1.49s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 271.03s of the 271.01s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.29%)\n",
      "\t0.9583\t = Validation score   (accuracy)\n",
      "\t114.33s\t = Training   runtime\n",
      "\t0.34s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 144.54s of the 144.52s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.29%)\n",
      "\t0.9613\t = Validation score   (accuracy)\n",
      "\t121.54s\t = Training   runtime\n",
      "\t0.35s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 11.46s of the 11.44s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.9442\t = Validation score   (accuracy)\n",
      "\t7.23s\t = Training   runtime\n",
      "\t5.93s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 291.68s of the -7.34s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBM_BAG_L1': 1.0}\n",
      "\t0.9613\t = Validation score   (accuracy)\n",
      "\t0.11s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 367.82s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 866.0 rows/s (300 batch size)\n",
      "Disabling decision threshold calibration for metric `accuracy` due to having fewer than 10000 rows of validation data for calibration, to avoid overfitting (2400 rows).\n",
      "\t`accuracy` is generally not improved through threshold calibration. Force calibration via specifying `calibrate_decision_threshold=True`.\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250522_161339\")\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250522_161951\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #53~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Jan 15 19:18:46 UTC 2\n",
      "CPU Count:          64\n",
      "Memory Avail:       429.48 GB / 503.54 GB (85.3%)\n",
      "Disk Space Avail:   33778.13 GB / 51214.59 GB (66.0%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=0, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ... Time limit = 360s\n",
      "AutoGluon will save models to \"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250522_161951\"\n",
      "Train Data Rows:    2400\n",
      "Train Data Columns: 7\n",
      "Label Column:       fraudulent\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    439794.95 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.56 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])    : 3 | ['telecommuting', 'has_company_logo', 'has_questions']\n",
      "\t\t('object', []) : 4 | ['employment_type', 'required_experience', 'required_education', 'function']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 4 | ['employment_type', 'required_experience', 'required_education', 'function']\n",
      "\t\t('int', ['bool']) : 3 | ['telecommuting', 'has_company_logo', 'has_questions']\n",
      "\t0.1s = Fit runtime\n",
      "\t7 features in original data used to generate 7 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.02 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.12s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 110 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 359.88s of the 359.86s of remaining time.\n",
      "\tNo valid features to train KNeighborsUnif_BAG_L1... Skipping this model.\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 359.65s of the 359.63s of remaining time.\n",
      "\tNo valid features to train KNeighborsDist_BAG_L1... Skipping this model.\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 359.43s of the 359.41s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.85\t = Validation score   (accuracy)\n",
      "\t46.4s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 309.27s of the 309.25s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.8629\t = Validation score   (accuracy)\n",
      "\t48.72s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 257.12s of the 257.10s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.8529\t = Validation score   (accuracy)\n",
      "\t1.11s\t = Training   runtime\n",
      "\t0.29s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 255.61s of the 255.59s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.8546\t = Validation score   (accuracy)\n",
      "\t1.04s\t = Training   runtime\n",
      "\t0.28s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 254.17s of the 254.15s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.09%)\n",
      "\t0.8379\t = Validation score   (accuracy)\n",
      "\t67.79s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 183.00s of the 182.97s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.8533\t = Validation score   (accuracy)\n",
      "\t1.12s\t = Training   runtime\n",
      "\t0.3s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 181.44s of the 181.42s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.8512\t = Validation score   (accuracy)\n",
      "\t1.03s\t = Training   runtime\n",
      "\t0.29s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 179.98s of the 179.96s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.8558\t = Validation score   (accuracy)\n",
      "\t103.13s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 73.47s of the 73.45s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.8596\t = Validation score   (accuracy)\n",
      "\t42.44s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 27.50s of the 27.48s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\tTime limit exceeded... Skipping NeuralNetTorch_BAG_L1.\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 17.22s of the 17.20s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.8517\t = Validation score   (accuracy)\n",
      "\t41.57s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 359.88s of the -27.38s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBM_BAG_L1': 1.0}\n",
      "\t0.8629\t = Validation score   (accuracy)\n",
      "\t0.21s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 387.65s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 4918.8 rows/s (300 batch size)\n",
      "Disabling decision threshold calibration for metric `accuracy` due to having fewer than 10000 rows of validation data for calibration, to avoid overfitting (2400 rows).\n",
      "\t`accuracy` is generally not improved through threshold calibration. Force calibration via specifying `calibrate_decision_threshold=True`.\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250522_161951\")\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250522_162619\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #53~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Jan 15 19:18:46 UTC 2\n",
      "CPU Count:          64\n",
      "Memory Avail:       430.82 GB / 503.54 GB (85.6%)\n",
      "Disk Space Avail:   33777.74 GB / 51214.59 GB (66.0%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=0, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ... Time limit = 360s\n",
      "AutoGluon will save models to \"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250522_162619\"\n",
      "Train Data Rows:    2400\n",
      "Train Data Columns: 14\n",
      "Label Column:       fraudulent\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    441166.98 MB\n",
      "\tTrain Data (Original)  Memory Usage: 14.51 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['title', 'location', 'company_profile', 'description', 'requirements', 'benefits']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 6733\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])          : 3 | ['telecommuting', 'has_company_logo', 'has_questions']\n",
      "\t\t('object', [])       : 5 | ['employment_type', 'required_experience', 'required_education', 'industry', 'function']\n",
      "\t\t('object', ['text']) : 6 | ['title', 'location', 'company_profile', 'description', 'requirements', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    :    5 | ['employment_type', 'required_experience', 'required_education', 'industry', 'function']\n",
      "\t\t('category', ['text_as_category'])  :    6 | ['title', 'location', 'company_profile', 'description', 'requirements', ...]\n",
      "\t\t('int', ['binned', 'text_special']) :  152 | ['title.char_count', 'title.word_count', 'title.capital_ratio', 'title.lower_ratio', 'title.digit_ratio', ...]\n",
      "\t\t('int', ['bool'])                   :    3 | ['telecommuting', 'has_company_logo', 'has_questions']\n",
      "\t\t('int', ['text_ngram'])             : 5993 | ['__nlp__.00', '__nlp__.000', '__nlp__.000 people', '__nlp__.000 people in', '__nlp__.000 per', ...]\n",
      "\t68.1s = Fit runtime\n",
      "\t14 features in original data used to generate 6159 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 27.83 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 69.6s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 110 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 290.40s of the 290.38s of remaining time.\n",
      "\t0.8817\t = Validation score   (accuracy)\n",
      "\t3.22s\t = Training   runtime\n",
      "\t1.54s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 279.47s of the 279.45s of remaining time.\n",
      "\t0.8888\t = Validation score   (accuracy)\n",
      "\t3.21s\t = Training   runtime\n",
      "\t1.58s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 268.59s of the 268.56s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.29%)\n",
      "\t0.9646\t = Validation score   (accuracy)\n",
      "\t115.45s\t = Training   runtime\n",
      "\t0.34s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 140.30s of the 140.27s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.29%)\n",
      "\t0.9629\t = Validation score   (accuracy)\n",
      "\t122.61s\t = Training   runtime\n",
      "\t0.34s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 5.56s of the 5.54s of remaining time.\n",
      "\tWarning: Model has no time left to train, skipping model... (Time Left = -2.5s)\n",
      "\tTime limit exceeded... Skipping RandomForestGini_BAG_L1.\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 290.40s of the -3.62s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\n",
      "\t0.9646\t = Validation score   (accuracy)\n",
      "\t0.09s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 364.05s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 873.4 rows/s (300 batch size)\n",
      "Disabling decision threshold calibration for metric `accuracy` due to having fewer than 10000 rows of validation data for calibration, to avoid overfitting (2400 rows).\n",
      "\t`accuracy` is generally not improved through threshold calibration. Force calibration via specifying `calibrate_decision_threshold=True`.\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250522_162619\")\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250522_163227\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #53~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Jan 15 19:18:46 UTC 2\n",
      "CPU Count:          64\n",
      "Memory Avail:       430.48 GB / 503.54 GB (85.5%)\n",
      "Disk Space Avail:   33777.26 GB / 51214.59 GB (66.0%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=0, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ... Time limit = 360s\n",
      "AutoGluon will save models to \"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250522_163227\"\n",
      "Train Data Rows:    2400\n",
      "Train Data Columns: 7\n",
      "Label Column:       fraudulent\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    440809.79 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.56 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])    : 3 | ['telecommuting', 'has_company_logo', 'has_questions']\n",
      "\t\t('object', []) : 4 | ['employment_type', 'required_experience', 'required_education', 'function']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 4 | ['employment_type', 'required_experience', 'required_education', 'function']\n",
      "\t\t('int', ['bool']) : 3 | ['telecommuting', 'has_company_logo', 'has_questions']\n",
      "\t0.1s = Fit runtime\n",
      "\t7 features in original data used to generate 7 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.02 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.11s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 110 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 359.89s of the 359.87s of remaining time.\n",
      "\tNo valid features to train KNeighborsUnif_BAG_L1... Skipping this model.\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 359.60s of the 359.58s of remaining time.\n",
      "\tNo valid features to train KNeighborsDist_BAG_L1... Skipping this model.\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 359.38s of the 359.36s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.8592\t = Validation score   (accuracy)\n",
      "\t45.67s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 310.04s of the 310.02s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.8621\t = Validation score   (accuracy)\n",
      "\t48.47s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 258.19s of the 258.17s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.8479\t = Validation score   (accuracy)\n",
      "\t1.06s\t = Training   runtime\n",
      "\t0.29s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 256.72s of the 256.70s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.8467\t = Validation score   (accuracy)\n",
      "\t1.02s\t = Training   runtime\n",
      "\t0.29s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 255.26s of the 255.24s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.09%)\n",
      "\t0.8442\t = Validation score   (accuracy)\n",
      "\t70.06s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 181.85s of the 181.83s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.8471\t = Validation score   (accuracy)\n",
      "\t1.1s\t = Training   runtime\n",
      "\t0.29s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 180.31s of the 180.29s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.8475\t = Validation score   (accuracy)\n",
      "\t1.06s\t = Training   runtime\n",
      "\t0.29s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 178.82s of the 178.80s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.8579\t = Validation score   (accuracy)\n",
      "\t103.41s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 72.02s of the 72.00s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.8658\t = Validation score   (accuracy)\n",
      "\t42.03s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 26.42s of the 26.40s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\tTime limit exceeded... Skipping NeuralNetTorch_BAG_L1.\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 16.26s of the 16.24s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.8554\t = Validation score   (accuracy)\n",
      "\t41.05s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 359.89s of the -27.74s of remaining time.\n",
      "\tEnsemble Weights: {'XGBoost_BAG_L1': 1.0}\n",
      "\t0.8658\t = Validation score   (accuracy)\n",
      "\t0.19s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 387.97s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1602.6 rows/s (300 batch size)\n",
      "Disabling decision threshold calibration for metric `accuracy` due to having fewer than 10000 rows of validation data for calibration, to avoid overfitting (2400 rows).\n",
      "\t`accuracy` is generally not improved through threshold calibration. Force calibration via specifying `calibrate_decision_threshold=True`.\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250522_163227\")\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250522_163856\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #53~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Jan 15 19:18:46 UTC 2\n",
      "CPU Count:          64\n",
      "Memory Avail:       433.81 GB / 503.54 GB (86.2%)\n",
      "Disk Space Avail:   33776.94 GB / 51214.59 GB (66.0%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=0, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ... Time limit = 360s\n",
      "AutoGluon will save models to \"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250522_163856\"\n",
      "Train Data Rows:    2400\n",
      "Train Data Columns: 14\n",
      "Label Column:       fraudulent\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    444299.60 MB\n",
      "\tTrain Data (Original)  Memory Usage: 14.35 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['title', 'location', 'company_profile', 'description', 'requirements', 'benefits']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 6508\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])          : 3 | ['telecommuting', 'has_company_logo', 'has_questions']\n",
      "\t\t('object', [])       : 5 | ['employment_type', 'required_experience', 'required_education', 'industry', 'function']\n",
      "\t\t('object', ['text']) : 6 | ['title', 'location', 'company_profile', 'description', 'requirements', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    :    5 | ['employment_type', 'required_experience', 'required_education', 'industry', 'function']\n",
      "\t\t('category', ['text_as_category'])  :    6 | ['title', 'location', 'company_profile', 'description', 'requirements', ...]\n",
      "\t\t('int', ['binned', 'text_special']) :  150 | ['title.char_count', 'title.word_count', 'title.capital_ratio', 'title.lower_ratio', 'title.digit_ratio', ...]\n",
      "\t\t('int', ['bool'])                   :    3 | ['telecommuting', 'has_company_logo', 'has_questions']\n",
      "\t\t('int', ['text_ngram'])             : 5771 | ['__nlp__.00', '__nlp__.000', '__nlp__.000 people', '__nlp__.000 people in', '__nlp__.000 per', ...]\n",
      "\t66.5s = Fit runtime\n",
      "\t14 features in original data used to generate 5935 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 26.81 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 67.73s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 110 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 292.27s of the 292.25s of remaining time.\n",
      "\t0.8612\t = Validation score   (accuracy)\n",
      "\t2.93s\t = Training   runtime\n",
      "\t1.5s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 282.25s of the 282.23s of remaining time.\n",
      "\t0.8696\t = Validation score   (accuracy)\n",
      "\t3.01s\t = Training   runtime\n",
      "\t1.46s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 271.95s of the 271.93s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.28%)\n",
      "\t0.9642\t = Validation score   (accuracy)\n",
      "\t123.14s\t = Training   runtime\n",
      "\t0.34s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 136.79s of the 136.76s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.28%)\n",
      "\t0.96\t = Validation score   (accuracy)\n",
      "\t122.97s\t = Training   runtime\n",
      "\t0.33s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 292.27s of the 1.27s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\n",
      "\t0.9642\t = Validation score   (accuracy)\n",
      "\t0.09s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 359.21s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 890.7 rows/s (300 batch size)\n",
      "Disabling decision threshold calibration for metric `accuracy` due to having fewer than 10000 rows of validation data for calibration, to avoid overfitting (2400 rows).\n",
      "\t`accuracy` is generally not improved through threshold calibration. Force calibration via specifying `calibrate_decision_threshold=True`.\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250522_163856\")\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250522_164459\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #53~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Jan 15 19:18:46 UTC 2\n",
      "CPU Count:          64\n",
      "Memory Avail:       434.31 GB / 503.54 GB (86.3%)\n",
      "Disk Space Avail:   33774.93 GB / 51214.59 GB (65.9%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=0, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ... Time limit = 360s\n",
      "AutoGluon will save models to \"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250522_164459\"\n",
      "Train Data Rows:    2400\n",
      "Train Data Columns: 7\n",
      "Label Column:       fraudulent\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    444750.65 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.57 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])    : 3 | ['telecommuting', 'has_company_logo', 'has_questions']\n",
      "\t\t('object', []) : 4 | ['employment_type', 'required_experience', 'required_education', 'function']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 4 | ['employment_type', 'required_experience', 'required_education', 'function']\n",
      "\t\t('int', ['bool']) : 3 | ['telecommuting', 'has_company_logo', 'has_questions']\n",
      "\t0.1s = Fit runtime\n",
      "\t7 features in original data used to generate 7 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.02 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.11s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 110 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 359.89s of the 359.87s of remaining time.\n",
      "\tNo valid features to train KNeighborsUnif_BAG_L1... Skipping this model.\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 359.65s of the 359.63s of remaining time.\n",
      "\tNo valid features to train KNeighborsDist_BAG_L1... Skipping this model.\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 359.43s of the 359.41s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.8517\t = Validation score   (accuracy)\n",
      "\t45.1s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 310.54s of the 310.52s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.8567\t = Validation score   (accuracy)\n",
      "\t48.2s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 258.85s of the 258.83s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.8571\t = Validation score   (accuracy)\n",
      "\t1.12s\t = Training   runtime\n",
      "\t0.29s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 257.31s of the 257.28s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.8554\t = Validation score   (accuracy)\n",
      "\t1.04s\t = Training   runtime\n",
      "\t0.29s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 255.85s of the 255.83s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.09%)\n",
      "\t0.8413\t = Validation score   (accuracy)\n",
      "\t72.84s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 179.61s of the 179.59s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.8592\t = Validation score   (accuracy)\n",
      "\t1.12s\t = Training   runtime\n",
      "\t0.3s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 178.06s of the 178.04s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.8592\t = Validation score   (accuracy)\n",
      "\t1.01s\t = Training   runtime\n",
      "\t0.31s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 176.62s of the 176.60s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.8562\t = Validation score   (accuracy)\n",
      "\t103.06s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 70.06s of the 70.04s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.8567\t = Validation score   (accuracy)\n",
      "\t40.0s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 26.58s of the 26.55s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\tTime limit exceeded... Skipping NeuralNetTorch_BAG_L1.\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 16.44s of the 16.42s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.8529\t = Validation score   (accuracy)\n",
      "\t40.92s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 359.89s of the -27.42s of remaining time.\n",
      "\tEnsemble Weights: {'RandomForestEntr_BAG_L1': 0.263, 'ExtraTreesGini_BAG_L1': 0.211, 'NeuralNetFastAI_BAG_L1': 0.211, 'RandomForestGini_BAG_L1': 0.158, 'XGBoost_BAG_L1': 0.158}\n",
      "\t0.8654\t = Validation score   (accuracy)\n",
      "\t0.21s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 387.68s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 700.9 rows/s (300 batch size)\n",
      "Disabling decision threshold calibration for metric `accuracy` due to having fewer than 10000 rows of validation data for calibration, to avoid overfitting (2400 rows).\n",
      "\t`accuracy` is generally not improved through threshold calibration. Force calibration via specifying `calibrate_decision_threshold=True`.\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250522_164459\")\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250522_165129\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #53~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Jan 15 19:18:46 UTC 2\n",
      "CPU Count:          64\n",
      "Memory Avail:       434.31 GB / 503.54 GB (86.3%)\n",
      "Disk Space Avail:   33778.35 GB / 51214.59 GB (66.0%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=0, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ... Time limit = 360s\n",
      "AutoGluon will save models to \"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250522_165129\"\n",
      "Train Data Rows:    2400\n",
      "Train Data Columns: 14\n",
      "Label Column:       fraudulent\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    444746.57 MB\n",
      "\tTrain Data (Original)  Memory Usage: 14.61 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['title', 'location', 'company_profile', 'description', 'requirements', 'benefits']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 6632\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])          : 3 | ['telecommuting', 'has_company_logo', 'has_questions']\n",
      "\t\t('object', [])       : 5 | ['employment_type', 'required_experience', 'required_education', 'industry', 'function']\n",
      "\t\t('object', ['text']) : 6 | ['title', 'location', 'company_profile', 'description', 'requirements', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    :    5 | ['employment_type', 'required_experience', 'required_education', 'industry', 'function']\n",
      "\t\t('category', ['text_as_category'])  :    6 | ['title', 'location', 'company_profile', 'description', 'requirements', ...]\n",
      "\t\t('int', ['binned', 'text_special']) :  150 | ['title.char_count', 'title.word_count', 'title.capital_ratio', 'title.lower_ratio', 'title.digit_ratio', ...]\n",
      "\t\t('int', ['bool'])                   :    3 | ['telecommuting', 'has_company_logo', 'has_questions']\n",
      "\t\t('int', ['text_ngram'])             : 5899 | ['__nlp__.00', '__nlp__.000', '__nlp__.000 people', '__nlp__.000 people in', '__nlp__.000 per', ...]\n",
      "\t68.2s = Fit runtime\n",
      "\t14 features in original data used to generate 6063 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 27.39 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 69.4s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 110 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 290.60s of the 290.58s of remaining time.\n",
      "\t0.8717\t = Validation score   (accuracy)\n",
      "\t3.22s\t = Training   runtime\n",
      "\t1.48s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 279.86s of the 279.84s of remaining time.\n",
      "\t0.8796\t = Validation score   (accuracy)\n",
      "\t3.13s\t = Training   runtime\n",
      "\t1.51s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 269.19s of the 269.17s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.29%)\n",
      "\t0.9667\t = Validation score   (accuracy)\n",
      "\t122.85s\t = Training   runtime\n",
      "\t0.35s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 133.85s of the 133.83s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.29%)\n",
      "\t0.9663\t = Validation score   (accuracy)\n",
      "\t126.73s\t = Training   runtime\n",
      "\t0.37s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 290.60s of the -5.46s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\n",
      "\t0.9667\t = Validation score   (accuracy)\n",
      "\t0.09s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 365.89s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 864.6 rows/s (300 batch size)\n",
      "Disabling decision threshold calibration for metric `accuracy` due to having fewer than 10000 rows of validation data for calibration, to avoid overfitting (2400 rows).\n",
      "\t`accuracy` is generally not improved through threshold calibration. Force calibration via specifying `calibrate_decision_threshold=True`.\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250522_165129\")\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250522_165739\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #53~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Jan 15 19:18:46 UTC 2\n",
      "CPU Count:          64\n",
      "Memory Avail:       413.99 GB / 503.54 GB (82.2%)\n",
      "Disk Space Avail:   33777.93 GB / 51214.59 GB (66.0%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=0, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ... Time limit = 360s\n",
      "AutoGluon will save models to \"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250522_165739\"\n",
      "Train Data Rows:    2400\n",
      "Train Data Columns: 7\n",
      "Label Column:       fraudulent\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    423918.32 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.57 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])    : 3 | ['telecommuting', 'has_company_logo', 'has_questions']\n",
      "\t\t('object', []) : 4 | ['employment_type', 'required_experience', 'required_education', 'function']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 4 | ['employment_type', 'required_experience', 'required_education', 'function']\n",
      "\t\t('int', ['bool']) : 3 | ['telecommuting', 'has_company_logo', 'has_questions']\n",
      "\t0.1s = Fit runtime\n",
      "\t7 features in original data used to generate 7 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.02 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.12s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 110 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 359.88s of the 359.86s of remaining time.\n",
      "\tNo valid features to train KNeighborsUnif_BAG_L1... Skipping this model.\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 359.65s of the 359.62s of remaining time.\n",
      "\tNo valid features to train KNeighborsDist_BAG_L1... Skipping this model.\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 359.42s of the 359.40s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.845\t = Validation score   (accuracy)\n",
      "\t45.7s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 309.90s of the 309.88s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.8554\t = Validation score   (accuracy)\n",
      "\t52.98s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 253.36s of the 253.34s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.8529\t = Validation score   (accuracy)\n",
      "\t1.11s\t = Training   runtime\n",
      "\t0.3s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 251.62s of the 251.60s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.8512\t = Validation score   (accuracy)\n",
      "\t1.02s\t = Training   runtime\n",
      "\t0.28s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 250.20s of the 250.18s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.09%)\n",
      "\t0.8329\t = Validation score   (accuracy)\n",
      "\t72.01s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 174.70s of the 174.68s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.8517\t = Validation score   (accuracy)\n",
      "\t1.08s\t = Training   runtime\n",
      "\t0.3s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 173.18s of the 173.16s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.8533\t = Validation score   (accuracy)\n",
      "\t1.03s\t = Training   runtime\n",
      "\t0.29s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 171.73s of the 171.70s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.8517\t = Validation score   (accuracy)\n",
      "\t104.39s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 63.89s of the 63.87s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.8521\t = Validation score   (accuracy)\n",
      "\t41.25s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 19.12s of the 19.10s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\tTime limit exceeded... Skipping NeuralNetTorch_BAG_L1.\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 8.89s of the 8.87s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.8229\t = Validation score   (accuracy)\n",
      "\t35.06s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 359.88s of the -29.14s of remaining time.\n",
      "\tEnsemble Weights: {'ExtraTreesGini_BAG_L1': 0.45, 'LightGBM_BAG_L1': 0.15, 'RandomForestGini_BAG_L1': 0.15, 'XGBoost_BAG_L1': 0.15, 'ExtraTreesEntr_BAG_L1': 0.05, 'NeuralNetFastAI_BAG_L1': 0.05}\n",
      "\t0.8612\t = Validation score   (accuracy)\n",
      "\t0.19s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 389.38s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 607.3 rows/s (300 batch size)\n",
      "Disabling decision threshold calibration for metric `accuracy` due to having fewer than 10000 rows of validation data for calibration, to avoid overfitting (2400 rows).\n",
      "\t`accuracy` is generally not improved through threshold calibration. Force calibration via specifying `calibrate_decision_threshold=True`.\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250522_165739\")\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from baseline_eval import evaluate_baseline, plot_model_performance_summary\n",
    "results = evaluate_baseline(\n",
    "    df=loaded_df,\n",
    "    model='AGTabular',\n",
    "    df_name=dataset_config['dataset_name'],\n",
    "    label_col= dataset_config['target'],\n",
    "    task_type=dataset_config['task'],\n",
    "    textual_cols=textual_cols,\n",
    "    k_folds=5,\n",
    "    seed=0,\n",
    "    max_samples=3000,\n",
    "    output_path=f\"../../baseline_results/{dataset_config['task']}/{dataset_config['dataset_name']}.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "babbcca6-7b55-4a36-8e88-dc87bba04459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving plot to ../../baseline_results/plots/clf/score\n",
      "Saving plot to ../../baseline_results/plots/clf/loss\n",
      "Saving plot to ../../baseline_results/plots/clf/roc_auc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score':                                     mean       std\n",
       " model                                             \n",
       " AutoGluon_Tabular_without_text  0.847667  0.013774\n",
       " AutoGluon_Tabular_with_text     0.959667  0.008531,\n",
       " 'loss':                                     mean       std\n",
       " model                                             \n",
       " AutoGluon_Tabular_with_text     0.103008  0.017187\n",
       " AutoGluon_Tabular_without_text  0.328079  0.020636,\n",
       " 'roc_auc':                                     mean       std\n",
       " model                                             \n",
       " AutoGluon_Tabular_without_text  0.916161  0.010380\n",
       " AutoGluon_Tabular_with_text     0.992808  0.002044}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs = pd.read_csv(f\"../../baseline_results/{dataset_config['task']}/{dataset_config['dataset_name']}.csv\")\n",
    "plot_model_performance_summary(name=dataset_config['dataset_name'],task=dataset_config['task'], df=rs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
