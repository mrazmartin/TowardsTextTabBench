{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0200d09",
   "metadata": {},
   "source": [
    "### Let's start with downloading the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4d0c4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "# to reach the dataloader_functions module\n",
    "module_path = os.path.abspath(os.path.join( \"..\"))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from dataloader_functions.download_data import download_raw_data\n",
    "current_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b8103e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO update this section per dataset\n",
    "dataset_config = {\n",
    "    'dataset_name': 'osha_accidents',\n",
    "    'source': 'kaggle', # ['kaggle', 'local', 'openml', 'hf']\n",
    "    'remote_path': 'ruqaiyaship/osha-accident-and-injury-data-1517',\n",
    "    'files': ['OSHA HSE DATA_ALL ABSTRACTS 15-17_FINAL.csv'],\n",
    "    'rename_files': ['osha_data.csv'],\n",
    "    'task': 'clf', # ['reg', 'clf']\n",
    "    'target': 'Task Assigned',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4336bfef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;36mInfo:\u001b[0m Dataset already downloaded in \u001b[1;35m/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/../../datasets_files/raw/classification/osha_accidents\u001b[0m.\n",
      "Downloaded osha_accidents dataset to /home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/../../datasets_files/raw/classification/osha_accidents\n"
     ]
    }
   ],
   "source": [
    "if dataset_config['task'] == 'clf':\n",
    "    dataset_subfolder = os.path.join('raw', 'classification', dataset_config['dataset_name']) \n",
    "elif dataset_config['task'] == 'reg':\n",
    "    dataset_subfolder = os.path.join('raw', 'regression', dataset_config['dataset_name'])\n",
    "else:\n",
    "    raise ValueError(f\"Unknown task: {dataset_config['task']}\")\n",
    "\n",
    "# this path needs to be modified based on the location of the notebook\n",
    "download_path = os.path.join(current_dir, '..', '..', 'datasets_files', dataset_subfolder)\n",
    "\n",
    "if download_raw_data(\n",
    "    dataset_config=dataset_config,\n",
    "    download_path=download_path,\n",
    "    force_download=False,\n",
    "    remove_unlisted=True,\n",
    ") is not None:\n",
    "    print(f\"Downloaded {dataset_config['dataset_name']} dataset to {download_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d886637",
   "metadata": {},
   "source": [
    "### Now we need to preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48bcaebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader_functions.load_and_pp_raw_data import _drop_empty_columns, _drop_single_value_columns\n",
    "from dataloader_functions.utils.data_2_df import read_any_to_df\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "current_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0861820c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading /home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/../../datasets_files/raw/classification/osha_accidents/osha_data.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary_nr</th>\n",
       "      <th>Event Date</th>\n",
       "      <th>Abstract Text</th>\n",
       "      <th>Event Description</th>\n",
       "      <th>Event Keywords</th>\n",
       "      <th>con_end</th>\n",
       "      <th>Construction End Use</th>\n",
       "      <th>build_stor</th>\n",
       "      <th>Building Stories</th>\n",
       "      <th>proj_cost</th>\n",
       "      <th>Project Cost</th>\n",
       "      <th>proj_type</th>\n",
       "      <th>Project Type</th>\n",
       "      <th>Degree of Injury</th>\n",
       "      <th>nature_of_inj</th>\n",
       "      <th>Nature of Injury</th>\n",
       "      <th>part_of_body</th>\n",
       "      <th>Part of Body</th>\n",
       "      <th>event_type</th>\n",
       "      <th>Event type</th>\n",
       "      <th>evn_factor</th>\n",
       "      <th>Environmental Factor</th>\n",
       "      <th>hum_factor</th>\n",
       "      <th>Human Factor</th>\n",
       "      <th>task_assigned</th>\n",
       "      <th>Task Assigned</th>\n",
       "      <th>hazsub</th>\n",
       "      <th>fat_cause</th>\n",
       "      <th>fall_ht</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>220982664</td>\n",
       "      <td>8/10/2017</td>\n",
       "      <td>At 9:00 a.m. on August 10, 2017, an employee w...</td>\n",
       "      <td>EMPLOYEE'S FINGERS AMPUTATED WHILE OPERATING A...</td>\n",
       "      <td>FINGER,MECHANICAL POWER PRESS,AMPUTATION,GUARD</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>Nonfatal</td>\n",
       "      <td>1</td>\n",
       "      <td>Amputation, Crushing</td>\n",
       "      <td>10</td>\n",
       "      <td>Fingers</td>\n",
       "      <td>2</td>\n",
       "      <td>Caught in or between</td>\n",
       "      <td>2</td>\n",
       "      <td>Catch Point/Puncture Action</td>\n",
       "      <td>14</td>\n",
       "      <td>Other</td>\n",
       "      <td>1</td>\n",
       "      <td>Regularly Assigned</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>220973937</td>\n",
       "      <td>7/17/2017</td>\n",
       "      <td>At 9:45 a.m. on July 17, 2017, an employee was...</td>\n",
       "      <td>EMPLOYEE'S FINGER IS CAUGHT IN DRILL AND IS AM...</td>\n",
       "      <td>CAUGHT IN,DRIVE SHAFT,RESIDENTIAL CONSTRUCTION...</td>\n",
       "      <td>H</td>\n",
       "      <td>Other building</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>B</td>\n",
       "      <td>Alteration or rehabilitation</td>\n",
       "      <td>Nonfatal</td>\n",
       "      <td>9</td>\n",
       "      <td>Dislocation</td>\n",
       "      <td>10</td>\n",
       "      <td>Fingers</td>\n",
       "      <td>2</td>\n",
       "      <td>Caught in or between</td>\n",
       "      <td>18</td>\n",
       "      <td>Other</td>\n",
       "      <td>10</td>\n",
       "      <td>Position Inappropriate For Task</td>\n",
       "      <td>1</td>\n",
       "      <td>Regularly Assigned</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>220967632</td>\n",
       "      <td>6/30/2017</td>\n",
       "      <td>At 7:30 a.m. on June 30, 2017, an employee was...</td>\n",
       "      <td>EMPLOYEE IS HOSPITALIZED AFTER BEING INJURED I...</td>\n",
       "      <td>AMPUTATED,EXPLOSION,FIREWORKS</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>Nonfatal</td>\n",
       "      <td>5</td>\n",
       "      <td>Fire Burn</td>\n",
       "      <td>12</td>\n",
       "      <td>Hand</td>\n",
       "      <td>14</td>\n",
       "      <td>Other</td>\n",
       "      <td>18</td>\n",
       "      <td>Other</td>\n",
       "      <td>4</td>\n",
       "      <td>Malfunction In Securing/Warning Op</td>\n",
       "      <td>2</td>\n",
       "      <td>Not Regularly Assigned</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   summary_nr Event Date                                      Abstract Text  \\\n",
       "0   220982664  8/10/2017  At 9:00 a.m. on August 10, 2017, an employee w...   \n",
       "1   220973937  7/17/2017  At 9:45 a.m. on July 17, 2017, an employee was...   \n",
       "2   220967632  6/30/2017  At 7:30 a.m. on June 30, 2017, an employee was...   \n",
       "\n",
       "                                   Event Description  \\\n",
       "0  EMPLOYEE'S FINGERS AMPUTATED WHILE OPERATING A...   \n",
       "1  EMPLOYEE'S FINGER IS CAUGHT IN DRILL AND IS AM...   \n",
       "2  EMPLOYEE IS HOSPITALIZED AFTER BEING INJURED I...   \n",
       "\n",
       "                                      Event Keywords con_end  \\\n",
       "0     FINGER,MECHANICAL POWER PRESS,AMPUTATION,GUARD       0   \n",
       "1  CAUGHT IN,DRIVE SHAFT,RESIDENTIAL CONSTRUCTION...       H   \n",
       "2                      AMPUTATED,EXPLOSION,FIREWORKS       0   \n",
       "\n",
       "  Construction End Use  build_stor Building Stories proj_cost Project Cost  \\\n",
       "0                                0                          0                \n",
       "1       Other building           1                1         0                \n",
       "2                                0                          0                \n",
       "\n",
       "  proj_type                  Project Type Degree of Injury  nature_of_inj  \\\n",
       "0         0                                       Nonfatal              1   \n",
       "1         B  Alteration or rehabilitation         Nonfatal              9   \n",
       "2         0                                       Nonfatal              5   \n",
       "\n",
       "       Nature of Injury  part_of_body Part of Body  event_type  \\\n",
       "0  Amputation, Crushing            10      Fingers           2   \n",
       "1           Dislocation            10      Fingers           2   \n",
       "2             Fire Burn            12         Hand          14   \n",
       "\n",
       "             Event type  evn_factor         Environmental Factor  hum_factor  \\\n",
       "0  Caught in or between           2  Catch Point/Puncture Action          14   \n",
       "1  Caught in or between          18                        Other          10   \n",
       "2                 Other          18                        Other           4   \n",
       "\n",
       "                         Human Factor  task_assigned           Task Assigned  \\\n",
       "0                               Other              1      Regularly Assigned   \n",
       "1     Position Inappropriate For Task              1      Regularly Assigned   \n",
       "2  Malfunction In Securing/Warning Op              2  Not Regularly Assigned   \n",
       "\n",
       "  hazsub  fat_cause  fall_ht  \n",
       "0      0          0        0  \n",
       "1      0          0        0  \n",
       "2      0          0        0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dataset_files_df = []\n",
    "\n",
    "if dataset_config['rename_files'] is None or len(dataset_config['rename_files']) == 0:\n",
    "    dataset_config['rename_files'] = dataset_config['files']\n",
    "\n",
    "for file in dataset_config['rename_files']:\n",
    "\n",
    "    file_location = os.path.join(download_path, file)\n",
    "\n",
    "    print(f\"Loading {file_location}\")\n",
    "\n",
    "    dataset_files_df.append(read_any_to_df(file_location))\n",
    "\n",
    "# example of the loaded df data:\n",
    "pd.set_option('display.max_columns', None)\n",
    "dataset_files_df[0].head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d099b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped: Index([], dtype='object')\n",
      "Dataframe shape before/afrer cleaning: (4847, 29) / (4847, 28)\n"
     ]
    }
   ],
   "source": [
    "## Run some basic data cleaning\n",
    "\n",
    "dataset_files_gen_cleaned = []\n",
    "missing_ratio_threshold = 0.5 # TODO the threshold can be changed\n",
    "\n",
    "for df_file in dataset_files_df:\n",
    "    df_size = df_file.shape\n",
    "    # 1. Drop columns with more than 50% missing values\n",
    "    df_file = _drop_empty_columns(df_file, threshold=missing_ratio_threshold)   \n",
    "    # 2. Drop columns with only one unique value\n",
    "    df_file = _drop_single_value_columns(df_file)\n",
    "    # 3. remove duplicates\n",
    "    df_file = df_file.drop_duplicates()\n",
    "    # 4. remove rows with missing target values\n",
    "    df_file = df_file[df_file[dataset_config['target']].notna()]\n",
    "    # 5. drop unnamed columns\n",
    "    df_file = df_file.loc[:, ~df_file.columns.str.contains('^Unnamed')]\n",
    "\n",
    "    dataset_files_gen_cleaned.append(df_file)\n",
    "\n",
    "    print(f\"Dataframe shape before/afrer cleaning: {df_size} / {df_file.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0a2a11a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe shape before/afrer by-hand cleaning: (4847, 28) / (4847, 19)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Event Date</th>\n",
       "      <th>Abstract Text</th>\n",
       "      <th>Event Description</th>\n",
       "      <th>Event Keywords</th>\n",
       "      <th>con_end</th>\n",
       "      <th>Construction End Use</th>\n",
       "      <th>build_stor</th>\n",
       "      <th>Building Stories</th>\n",
       "      <th>Project Cost</th>\n",
       "      <th>Project Type</th>\n",
       "      <th>Degree of Injury</th>\n",
       "      <th>Nature of Injury</th>\n",
       "      <th>Part of Body</th>\n",
       "      <th>Event type</th>\n",
       "      <th>Environmental Factor</th>\n",
       "      <th>Human Factor</th>\n",
       "      <th>Task Assigned</th>\n",
       "      <th>hazsub</th>\n",
       "      <th>fat_cause</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8/10/2017</td>\n",
       "      <td>At 9:00 a.m. on August 10, 2017, an employee w...</td>\n",
       "      <td>EMPLOYEE'S FINGERS AMPUTATED WHILE OPERATING A...</td>\n",
       "      <td>FINGER,MECHANICAL POWER PRESS,AMPUTATION,GUARD</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Nonfatal</td>\n",
       "      <td>Amputation, Crushing</td>\n",
       "      <td>Fingers</td>\n",
       "      <td>Caught in or between</td>\n",
       "      <td>Catch Point/Puncture Action</td>\n",
       "      <td>Other</td>\n",
       "      <td>Regularly Assigned</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7/17/2017</td>\n",
       "      <td>At 9:45 a.m. on July 17, 2017, an employee was...</td>\n",
       "      <td>EMPLOYEE'S FINGER IS CAUGHT IN DRILL AND IS AM...</td>\n",
       "      <td>CAUGHT IN,DRIVE SHAFT,RESIDENTIAL CONSTRUCTION...</td>\n",
       "      <td>H</td>\n",
       "      <td>Other building</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>Alteration or rehabilitation</td>\n",
       "      <td>Nonfatal</td>\n",
       "      <td>Dislocation</td>\n",
       "      <td>Fingers</td>\n",
       "      <td>Caught in or between</td>\n",
       "      <td>Other</td>\n",
       "      <td>Position Inappropriate For Task</td>\n",
       "      <td>Regularly Assigned</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6/30/2017</td>\n",
       "      <td>At 7:30 a.m. on June 30, 2017, an employee was...</td>\n",
       "      <td>EMPLOYEE IS HOSPITALIZED AFTER BEING INJURED I...</td>\n",
       "      <td>AMPUTATED,EXPLOSION,FIREWORKS</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Nonfatal</td>\n",
       "      <td>Fire Burn</td>\n",
       "      <td>Hand</td>\n",
       "      <td>Other</td>\n",
       "      <td>Other</td>\n",
       "      <td>Malfunction In Securing/Warning Op</td>\n",
       "      <td>Not Regularly Assigned</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Event Date                                      Abstract Text  \\\n",
       "0  8/10/2017  At 9:00 a.m. on August 10, 2017, an employee w...   \n",
       "1  7/17/2017  At 9:45 a.m. on July 17, 2017, an employee was...   \n",
       "2  6/30/2017  At 7:30 a.m. on June 30, 2017, an employee was...   \n",
       "\n",
       "                                   Event Description  \\\n",
       "0  EMPLOYEE'S FINGERS AMPUTATED WHILE OPERATING A...   \n",
       "1  EMPLOYEE'S FINGER IS CAUGHT IN DRILL AND IS AM...   \n",
       "2  EMPLOYEE IS HOSPITALIZED AFTER BEING INJURED I...   \n",
       "\n",
       "                                      Event Keywords con_end  \\\n",
       "0     FINGER,MECHANICAL POWER PRESS,AMPUTATION,GUARD       0   \n",
       "1  CAUGHT IN,DRIVE SHAFT,RESIDENTIAL CONSTRUCTION...       H   \n",
       "2                      AMPUTATED,EXPLOSION,FIREWORKS       0   \n",
       "\n",
       "  Construction End Use  build_stor Building Stories Project Cost  \\\n",
       "0                                0                                 \n",
       "1       Other building           1                1                \n",
       "2                                0                                 \n",
       "\n",
       "                   Project Type Degree of Injury      Nature of Injury  \\\n",
       "0                                       Nonfatal  Amputation, Crushing   \n",
       "1  Alteration or rehabilitation         Nonfatal           Dislocation   \n",
       "2                                       Nonfatal             Fire Burn   \n",
       "\n",
       "  Part of Body            Event type         Environmental Factor  \\\n",
       "0      Fingers  Caught in or between  Catch Point/Puncture Action   \n",
       "1      Fingers  Caught in or between                        Other   \n",
       "2         Hand                 Other                        Other   \n",
       "\n",
       "                         Human Factor           Task Assigned hazsub  \\\n",
       "0                               Other      Regularly Assigned      0   \n",
       "1     Position Inappropriate For Task      Regularly Assigned      0   \n",
       "2  Malfunction In Securing/Warning Op  Not Regularly Assigned      0   \n",
       "\n",
       "   fat_cause  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## TODO: Now run custom data cleaning -> remove non-essential columns\n",
    "\n",
    "cols_to_drop = ['summary_nr','proj_cost',\n",
    "    'proj_type', 'nature_of_inj', 'part_of_body', 'event_type',\n",
    "    'evn_factor', 'hum_factor','task_assigned']\n",
    "\n",
    "dataset_files_cleaned = []\n",
    "\n",
    "# assuming for multiple files we still want to drop the same columns\n",
    "for df_file in dataset_files_gen_cleaned:\n",
    "    df_size = df_file.shape\n",
    "    for col in cols_to_drop:\n",
    "        if col in df_file.columns:\n",
    "            df_file.drop(col, axis=1, inplace=True)\n",
    "        else:\n",
    "            print(f\"Column {col} not found in dataframe\")\n",
    "\n",
    "    dataset_files_cleaned.append(df_file)    \n",
    "    print(f\"Dataframe shape before/afrer by-hand cleaning: {df_size} / {df_file.shape}\")\n",
    "\n",
    "dataset_files_cleaned[0].head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d90a681b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe shape before custom cleaning: (4847, 19)\n",
      "Dataframe shape after custom cleaning: (4847, 19)\n"
     ]
    }
   ],
   "source": [
    "# TODO: some custom data cleaning\n",
    "\n",
    "import copy \n",
    "import pandas as pd\n",
    "\n",
    "tmp_df = copy.deepcopy(dataset_files_cleaned)\n",
    "dataset_files_by_hand_cleaned = []\n",
    "\n",
    "for df_file in dataset_files_cleaned:\n",
    "    print(f\"Dataframe shape before custom cleaning: {df_file.shape}\")\n",
    "    \n",
    "    # 1. Convert 'Event Date' to timestamp (safe handling for NaT)\n",
    "    df_file['Event Date'] = pd.to_datetime(df_file['Event Date'], format='%m/%d/%Y', errors='coerce')\n",
    "    df_file['Event Date'] = df_file['Event Date'].apply(lambda x: x.timestamp() if pd.notnull(x) else float('nan'))\n",
    "\n",
    "    print(f\"Dataframe shape after custom cleaning: {df_file.shape}\")\n",
    "\n",
    "    dataset_files_by_hand_cleaned.append(df_file)\n",
    "\n",
    "# reset the dataframe list to the version before custom cleaning -> next cells work with dataset_files_by_hand_cleaned\n",
    "dataset_files_cleaned = tmp_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581b17e1",
   "metadata": {},
   "source": [
    "### Now it is time to visualize our changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1500c210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Event Date</th>\n",
       "      <th>Abstract Text</th>\n",
       "      <th>Event Description</th>\n",
       "      <th>Event Keywords</th>\n",
       "      <th>con_end</th>\n",
       "      <th>Construction End Use</th>\n",
       "      <th>build_stor</th>\n",
       "      <th>Building Stories</th>\n",
       "      <th>Project Cost</th>\n",
       "      <th>Project Type</th>\n",
       "      <th>Degree of Injury</th>\n",
       "      <th>Nature of Injury</th>\n",
       "      <th>Part of Body</th>\n",
       "      <th>Event type</th>\n",
       "      <th>Environmental Factor</th>\n",
       "      <th>Human Factor</th>\n",
       "      <th>Task Assigned</th>\n",
       "      <th>hazsub</th>\n",
       "      <th>fat_cause</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.502323e+09</td>\n",
       "      <td>At 9:00 a.m. on August 10, 2017, an employee w...</td>\n",
       "      <td>EMPLOYEE'S FINGERS AMPUTATED WHILE OPERATING A...</td>\n",
       "      <td>FINGER,MECHANICAL POWER PRESS,AMPUTATION,GUARD</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Nonfatal</td>\n",
       "      <td>Amputation, Crushing</td>\n",
       "      <td>Fingers</td>\n",
       "      <td>Caught in or between</td>\n",
       "      <td>Catch Point/Puncture Action</td>\n",
       "      <td>Other</td>\n",
       "      <td>Regularly Assigned</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.500250e+09</td>\n",
       "      <td>At 9:45 a.m. on July 17, 2017, an employee was...</td>\n",
       "      <td>EMPLOYEE'S FINGER IS CAUGHT IN DRILL AND IS AM...</td>\n",
       "      <td>CAUGHT IN,DRIVE SHAFT,RESIDENTIAL CONSTRUCTION...</td>\n",
       "      <td>H</td>\n",
       "      <td>Other building</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>Alteration or rehabilitation</td>\n",
       "      <td>Nonfatal</td>\n",
       "      <td>Dislocation</td>\n",
       "      <td>Fingers</td>\n",
       "      <td>Caught in or between</td>\n",
       "      <td>Other</td>\n",
       "      <td>Position Inappropriate For Task</td>\n",
       "      <td>Regularly Assigned</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.498781e+09</td>\n",
       "      <td>At 7:30 a.m. on June 30, 2017, an employee was...</td>\n",
       "      <td>EMPLOYEE IS HOSPITALIZED AFTER BEING INJURED I...</td>\n",
       "      <td>AMPUTATED,EXPLOSION,FIREWORKS</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Nonfatal</td>\n",
       "      <td>Fire Burn</td>\n",
       "      <td>Hand</td>\n",
       "      <td>Other</td>\n",
       "      <td>Other</td>\n",
       "      <td>Malfunction In Securing/Warning Op</td>\n",
       "      <td>Not Regularly Assigned</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Event Date                                      Abstract Text  \\\n",
       "0  1.502323e+09  At 9:00 a.m. on August 10, 2017, an employee w...   \n",
       "1  1.500250e+09  At 9:45 a.m. on July 17, 2017, an employee was...   \n",
       "2  1.498781e+09  At 7:30 a.m. on June 30, 2017, an employee was...   \n",
       "\n",
       "                                   Event Description  \\\n",
       "0  EMPLOYEE'S FINGERS AMPUTATED WHILE OPERATING A...   \n",
       "1  EMPLOYEE'S FINGER IS CAUGHT IN DRILL AND IS AM...   \n",
       "2  EMPLOYEE IS HOSPITALIZED AFTER BEING INJURED I...   \n",
       "\n",
       "                                      Event Keywords con_end  \\\n",
       "0     FINGER,MECHANICAL POWER PRESS,AMPUTATION,GUARD       0   \n",
       "1  CAUGHT IN,DRIVE SHAFT,RESIDENTIAL CONSTRUCTION...       H   \n",
       "2                      AMPUTATED,EXPLOSION,FIREWORKS       0   \n",
       "\n",
       "  Construction End Use  build_stor Building Stories Project Cost  \\\n",
       "0                                0                                 \n",
       "1       Other building           1                1                \n",
       "2                                0                                 \n",
       "\n",
       "                   Project Type Degree of Injury      Nature of Injury  \\\n",
       "0                                       Nonfatal  Amputation, Crushing   \n",
       "1  Alteration or rehabilitation         Nonfatal           Dislocation   \n",
       "2                                       Nonfatal             Fire Burn   \n",
       "\n",
       "  Part of Body            Event type         Environmental Factor  \\\n",
       "0      Fingers  Caught in or between  Catch Point/Puncture Action   \n",
       "1      Fingers  Caught in or between                        Other   \n",
       "2         Hand                 Other                        Other   \n",
       "\n",
       "                         Human Factor           Task Assigned hazsub  \\\n",
       "0                               Other      Regularly Assigned      0   \n",
       "1     Position Inappropriate For Task      Regularly Assigned      0   \n",
       "2  Malfunction In Securing/Warning Op  Not Regularly Assigned      0   \n",
       "\n",
       "   fat_cause  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "dataset_files_by_hand_cleaned[0].head(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f71269d",
   "metadata": {},
   "source": [
    "Let's figure out which columns should be viewed as categorical / numerical / textual\n",
    "\n",
    "we can start with a simple heuristic:\n",
    "1. numerical is everything which\n",
    "    - keeps most of its character length after non-numeral strip\n",
    "    - has about the same number of unique values after the strip\n",
    "    + for the purpose of keeping \"semantic information\", hand picked columns can be viewed also as non-numerical, that is not the default benchmark approach though\n",
    "\n",
    "2. categorical is everthing non numerical, which can be then divided into N (where N << Num instances) unique categories\n",
    "\n",
    "3. textual is everything else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "436f9ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Threshold for categorical vs textual: 50\n",
      "Numerical columns (2): ['Event Date', 'hazsub']\n",
      "Categorical columns (14): ['con_end', 'Construction End Use', 'build_stor', 'Building Stories', 'Project Cost', 'Project Type', 'Degree of Injury', 'Nature of Injury', 'Part of Body', 'Event type', 'Environmental Factor', 'Human Factor', 'Task Assigned', 'fat_cause']\n",
      "Textual columns (3): ['Abstract Text', 'Event Description', 'Event Keywords']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def is_mostly_numeric(series, length_threshold=0.5, unique_threshold=0.8):\n",
    "    \"\"\"Check if column is mostly numeric after stripping non-numeric chars.\"\"\"\n",
    "    stripped = series.astype(str).str.replace(r\"[^\\d\\.\\-]\", \"\", regex=True)\n",
    "    \n",
    "    original_len = series.astype(str).str.len().replace(0, 1)  # avoid div by zero\n",
    "    length_ratio = (stripped.str.len() / original_len).mean()\n",
    "\n",
    "    unique_ratio = stripped.nunique(dropna=False) / max(series.nunique(dropna=False), 1)\n",
    "\n",
    "    return length_ratio > length_threshold and unique_ratio > unique_threshold\n",
    "\n",
    "def classify_columns(df, unique_ratio_threshold=None, explicit_nunique_threshold=None):\n",
    "    \"\"\"\n",
    "    Classify dataframe columns into numerical, categorical, textual.\n",
    "    - Binary categorical (2 unique values) is considered categorical.\n",
    "    \"\"\"\n",
    "    n_rows = len(df)\n",
    "\n",
    "    # Determine threshold for categorical vs textual\n",
    "    if explicit_nunique_threshold is not None:\n",
    "        nunique_threshold = explicit_nunique_threshold\n",
    "    elif unique_ratio_threshold is not None:\n",
    "        nunique_threshold = int(unique_ratio_threshold * n_rows)\n",
    "    else:\n",
    "        nunique_threshold = int(0.05 * n_rows)  # default 5%\n",
    "\n",
    "    nunique_threshold = max(10, nunique_threshold)  # safeguard\n",
    "    print(f\"Threshold for categorical vs textual: {nunique_threshold}\")\n",
    "\n",
    "    numerical_cols = []\n",
    "    categorical_cols = []\n",
    "    textual_cols = []\n",
    "\n",
    "    for col in df.columns:\n",
    "        series = df[col]\n",
    "        nunique = series.nunique(dropna=False)\n",
    "\n",
    "        if pd.api.types.is_numeric_dtype(series):\n",
    "            if nunique <= nunique_threshold:\n",
    "                categorical_cols.append(col)\n",
    "            else:\n",
    "                numerical_cols.append(col)\n",
    "        \n",
    "        elif pd.api.types.is_string_dtype(series) or pd.api.types.is_object_dtype(series):\n",
    "            if is_mostly_numeric(series):\n",
    "                numerical_cols.append(col)\n",
    "            else:\n",
    "                if nunique <= nunique_threshold:\n",
    "                    categorical_cols.append(col)\n",
    "                else:\n",
    "                    textual_cols.append(col)\n",
    "        else:\n",
    "            print(f\"⚠️ Unhandled column type: '{col}' (dtype={series.dtype})\")\n",
    "\n",
    "    print(f\"Numerical columns ({len(numerical_cols)}): {numerical_cols}\")\n",
    "    print(f\"Categorical columns ({len(categorical_cols)}): {categorical_cols}\")\n",
    "    print(f\"Textual columns ({len(textual_cols)}): {textual_cols}\")\n",
    "\n",
    "    return numerical_cols, categorical_cols, textual_cols\n",
    "\n",
    "# Example usage:\n",
    "for df_file in dataset_files_by_hand_cleaned:\n",
    "    # Ratio-based (5% of rows)\n",
    "    # umerical_cols, categorical_cols, textual_cols = classify_columns(df_file, unique_ratio_threshold=0.05)\n",
    "    print(\"\")\n",
    "    # OR explicit value (e.g., anything <= 50 is categorical)\n",
    "    numerical_cols, categorical_cols, textual_cols = classify_columns(df_file, explicit_nunique_threshold=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6499589b",
   "metadata": {},
   "source": [
    "Now let's just try to visualize the kept features, their example values, and their cat/num/text allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "afffbdb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column Name</th>\n",
       "      <th>Example Value</th>\n",
       "      <th>Type</th>\n",
       "      <th># Categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Event Date</td>\n",
       "      <td>1502323200.0</td>\n",
       "      <td>numerical</td>\n",
       "      <td>~ 671 ~</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abstract Text</td>\n",
       "      <td>At 9:00 a.m. on August 10, 2017, an employee w...</td>\n",
       "      <td>textual</td>\n",
       "      <td>4829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Event Description</td>\n",
       "      <td>EMPLOYEE'S FINGERS AMPUTATED WHILE OPERATING A...</td>\n",
       "      <td>textual</td>\n",
       "      <td>4320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Event Keywords</td>\n",
       "      <td>FINGER,MECHANICAL POWER PRESS,AMPUTATION,GUARD</td>\n",
       "      <td>textual</td>\n",
       "      <td>4427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>con_end</td>\n",
       "      <td>0</td>\n",
       "      <td>categorical</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Construction End Use</td>\n",
       "      <td></td>\n",
       "      <td>categorical</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>build_stor</td>\n",
       "      <td>0</td>\n",
       "      <td>categorical</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Building Stories</td>\n",
       "      <td></td>\n",
       "      <td>categorical</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Project Cost</td>\n",
       "      <td></td>\n",
       "      <td>categorical</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Project Type</td>\n",
       "      <td></td>\n",
       "      <td>categorical</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Degree of Injury</td>\n",
       "      <td>Nonfatal</td>\n",
       "      <td>categorical</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Nature of Injury</td>\n",
       "      <td>Amputation, Crushing</td>\n",
       "      <td>categorical</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Part of Body</td>\n",
       "      <td>Fingers</td>\n",
       "      <td>categorical</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Event type</td>\n",
       "      <td>Caught in or between</td>\n",
       "      <td>categorical</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Environmental Factor</td>\n",
       "      <td>Catch Point/Puncture Action</td>\n",
       "      <td>categorical</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Human Factor</td>\n",
       "      <td>Other</td>\n",
       "      <td>categorical</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Task Assigned</td>\n",
       "      <td>Regularly Assigned</td>\n",
       "      <td>categorical</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>hazsub</td>\n",
       "      <td>0</td>\n",
       "      <td>numerical</td>\n",
       "      <td>~ 31 ~</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>fat_cause</td>\n",
       "      <td>0</td>\n",
       "      <td>categorical</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Column Name                                      Example Value  \\\n",
       "0             Event Date                                       1502323200.0   \n",
       "1          Abstract Text  At 9:00 a.m. on August 10, 2017, an employee w...   \n",
       "2      Event Description  EMPLOYEE'S FINGERS AMPUTATED WHILE OPERATING A...   \n",
       "3         Event Keywords     FINGER,MECHANICAL POWER PRESS,AMPUTATION,GUARD   \n",
       "4                con_end                                                  0   \n",
       "5   Construction End Use                                                      \n",
       "6             build_stor                                                  0   \n",
       "7       Building Stories                                                      \n",
       "8           Project Cost                                                      \n",
       "9           Project Type                                                      \n",
       "10      Degree of Injury                                           Nonfatal   \n",
       "11      Nature of Injury                               Amputation, Crushing   \n",
       "12          Part of Body                                            Fingers   \n",
       "13            Event type                               Caught in or between   \n",
       "14  Environmental Factor                        Catch Point/Puncture Action   \n",
       "15          Human Factor                                              Other   \n",
       "16         Task Assigned                                 Regularly Assigned   \n",
       "17                hazsub                                                  0   \n",
       "18             fat_cause                                                  0   \n",
       "\n",
       "           Type # Categories  \n",
       "0     numerical      ~ 671 ~  \n",
       "1       textual         4829  \n",
       "2       textual         4320  \n",
       "3       textual         4427  \n",
       "4   categorical           18  \n",
       "5   categorical           18  \n",
       "6   categorical           25  \n",
       "7   categorical           25  \n",
       "8   categorical            8  \n",
       "9   categorical            6  \n",
       "10  categorical            2  \n",
       "11  categorical           19  \n",
       "12  categorical           29  \n",
       "13  categorical           14  \n",
       "14  categorical           17  \n",
       "15  categorical           18  \n",
       "16  categorical            2  \n",
       "17    numerical       ~ 31 ~  \n",
       "18  categorical           30  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary = []\n",
    "for col in df_file.columns:\n",
    "    if col in categorical_cols:\n",
    "        col_type = \"categorical\"\n",
    "        num_categories = df_file[col].nunique(dropna=True)\n",
    "        num_categories_display = int(num_categories)\n",
    "    elif col in textual_cols:\n",
    "        col_type = \"textual\"\n",
    "        num_categories = df_file[col].nunique(dropna=True)\n",
    "        num_categories_display = int(num_categories)\n",
    "    elif col in numerical_cols:\n",
    "        col_type = \"numerical\"\n",
    "        num_categories = df_file[col].nunique(dropna=True)\n",
    "        num_categories_display = '~ ' + str(num_categories) + ' ~'\n",
    "    else:\n",
    "        col_type = \"unknown\"\n",
    "        num_categories_display = '--'\n",
    "\n",
    "    example = df_file[col].dropna().iloc[0] if df_file[col].dropna().size > 0 else None\n",
    "    summary.append({\n",
    "        'Column Name': col,\n",
    "        'Example Value': str(example),\n",
    "        'Type': col_type,\n",
    "        '# Categories': num_categories_display\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary)\n",
    "\n",
    "# TODO: by hand changes of the type and category count -> e.g. for 'Location':\n",
    "#    # Post-processing: override the type and category count for 'Location'\n",
    "#    # summary_df.loc[summary_df['Column Name'] == 'Location', 'Type'] = 'textual'\n",
    "#    # num_categories = df_file['Location'].nunique(dropna=True)\n",
    "#    # summary_df.loc[summary_df['Column Name'] == 'Location', '# Categories'] = int(num_categories)\n",
    "\n",
    "display(summary_df)  # Or print(summary_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ef8954",
   "metadata": {},
   "source": [
    "### Saving the processed data and loading it back up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2fe5eab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: /home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/../../datasets_files/raw/classification/osha_accidents/osha_data_processed.pkl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Handle rename_files fallback\n",
    "if dataset_config['rename_files'] is None or len(dataset_config['rename_files']) == 0:\n",
    "    dataset_config['rename_files'] = dataset_config['files']\n",
    "\n",
    "for i, df_file in enumerate(dataset_files_by_hand_cleaned):\n",
    "    df_with_meta = df_file.copy()\n",
    "\n",
    "    # Get corresponding file name\n",
    "    file_name = dataset_config['rename_files'][i]\n",
    "    file_base = os.path.splitext(file_name)[0]\n",
    "\n",
    "    # Try assigning multi-index header from summary\n",
    "    try:\n",
    "        df_with_meta.columns = pd.MultiIndex.from_frame(\n",
    "            summary_df[['Column Name', 'Type', '# Categories']]\n",
    "        )\n",
    "        local_summary = summary_df.copy()\n",
    "    except ValueError:\n",
    "        local_summary = summary_df.copy()\n",
    "        if dataset_config['target'] in local_summary['Column Name'].values:\n",
    "            local_summary = local_summary[local_summary['Column Name'] != dataset_config['target']]\n",
    "            df_with_meta.columns = pd.MultiIndex.from_frame(\n",
    "                local_summary[['Column Name', 'Type', '# Categories']]\n",
    "            )\n",
    "        else:\n",
    "            raise\n",
    "\n",
    "    # Construct and save everything together\n",
    "    output_filename = f\"{file_base}_processed.pkl\"\n",
    "    output_path = os.path.join(download_path, output_filename)\n",
    "\n",
    "    save_bundle = {\n",
    "        'data': df_with_meta,\n",
    "        'summary': local_summary,\n",
    "        'config': dataset_config\n",
    "    }\n",
    "\n",
    "    pd.to_pickle(save_bundle, output_path)\n",
    "    print(f\"Saved: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c7bcd87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== OSHA_DATA ===\n",
      "Loaded config keys: ['dataset_name', 'source', 'remote_path', 'files', 'rename_files', 'task', 'target']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column Name</th>\n",
       "      <th>Type</th>\n",
       "      <th># Categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Event Date</td>\n",
       "      <td>numerical</td>\n",
       "      <td>~ 671 ~</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abstract Text</td>\n",
       "      <td>textual</td>\n",
       "      <td>4829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Event Description</td>\n",
       "      <td>textual</td>\n",
       "      <td>4320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Event Keywords</td>\n",
       "      <td>textual</td>\n",
       "      <td>4427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>con_end</td>\n",
       "      <td>categorical</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Construction End Use</td>\n",
       "      <td>categorical</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>build_stor</td>\n",
       "      <td>categorical</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Building Stories</td>\n",
       "      <td>categorical</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Project Cost</td>\n",
       "      <td>categorical</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Project Type</td>\n",
       "      <td>categorical</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Degree of Injury</td>\n",
       "      <td>categorical</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Nature of Injury</td>\n",
       "      <td>categorical</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Part of Body</td>\n",
       "      <td>categorical</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Event type</td>\n",
       "      <td>categorical</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Environmental Factor</td>\n",
       "      <td>categorical</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Human Factor</td>\n",
       "      <td>categorical</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Task Assigned</td>\n",
       "      <td>categorical</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>hazsub</td>\n",
       "      <td>numerical</td>\n",
       "      <td>~ 31 ~</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>fat_cause</td>\n",
       "      <td>categorical</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Column Name         Type # Categories\n",
       "0             Event Date    numerical      ~ 671 ~\n",
       "1          Abstract Text      textual         4829\n",
       "2      Event Description      textual         4320\n",
       "3         Event Keywords      textual         4427\n",
       "4                con_end  categorical           18\n",
       "5   Construction End Use  categorical           18\n",
       "6             build_stor  categorical           25\n",
       "7       Building Stories  categorical           25\n",
       "8           Project Cost  categorical            8\n",
       "9           Project Type  categorical            6\n",
       "10      Degree of Injury  categorical            2\n",
       "11      Nature of Injury  categorical           19\n",
       "12          Part of Body  categorical           29\n",
       "13            Event type  categorical           14\n",
       "14  Environmental Factor  categorical           17\n",
       "15          Human Factor  categorical           18\n",
       "16         Task Assigned  categorical            2\n",
       "17                hazsub    numerical       ~ 31 ~\n",
       "18             fat_cause  categorical           30"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Column Name</th>\n",
       "      <th>Event Date</th>\n",
       "      <th>Abstract Text</th>\n",
       "      <th>Event Description</th>\n",
       "      <th>Event Keywords</th>\n",
       "      <th>con_end</th>\n",
       "      <th>Construction End Use</th>\n",
       "      <th>build_stor</th>\n",
       "      <th>Building Stories</th>\n",
       "      <th>Project Cost</th>\n",
       "      <th>Project Type</th>\n",
       "      <th>Degree of Injury</th>\n",
       "      <th>Nature of Injury</th>\n",
       "      <th>Part of Body</th>\n",
       "      <th>Event type</th>\n",
       "      <th>Environmental Factor</th>\n",
       "      <th>Human Factor</th>\n",
       "      <th>Task Assigned</th>\n",
       "      <th>hazsub</th>\n",
       "      <th>fat_cause</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.502323e+09</td>\n",
       "      <td>At 9:00 a.m. on August 10, 2017, an employee w...</td>\n",
       "      <td>EMPLOYEE'S FINGERS AMPUTATED WHILE OPERATING A...</td>\n",
       "      <td>FINGER,MECHANICAL POWER PRESS,AMPUTATION,GUARD</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Nonfatal</td>\n",
       "      <td>Amputation, Crushing</td>\n",
       "      <td>Fingers</td>\n",
       "      <td>Caught in or between</td>\n",
       "      <td>Catch Point/Puncture Action</td>\n",
       "      <td>Other</td>\n",
       "      <td>Regularly Assigned</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.500250e+09</td>\n",
       "      <td>At 9:45 a.m. on July 17, 2017, an employee was...</td>\n",
       "      <td>EMPLOYEE'S FINGER IS CAUGHT IN DRILL AND IS AM...</td>\n",
       "      <td>CAUGHT IN,DRIVE SHAFT,RESIDENTIAL CONSTRUCTION...</td>\n",
       "      <td>H</td>\n",
       "      <td>Other building</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>Alteration or rehabilitation</td>\n",
       "      <td>Nonfatal</td>\n",
       "      <td>Dislocation</td>\n",
       "      <td>Fingers</td>\n",
       "      <td>Caught in or between</td>\n",
       "      <td>Other</td>\n",
       "      <td>Position Inappropriate For Task</td>\n",
       "      <td>Regularly Assigned</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.498781e+09</td>\n",
       "      <td>At 7:30 a.m. on June 30, 2017, an employee was...</td>\n",
       "      <td>EMPLOYEE IS HOSPITALIZED AFTER BEING INJURED I...</td>\n",
       "      <td>AMPUTATED,EXPLOSION,FIREWORKS</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Nonfatal</td>\n",
       "      <td>Fire Burn</td>\n",
       "      <td>Hand</td>\n",
       "      <td>Other</td>\n",
       "      <td>Other</td>\n",
       "      <td>Malfunction In Securing/Warning Op</td>\n",
       "      <td>Not Regularly Assigned</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Column Name    Event Date                                      Abstract Text  \\\n",
       "0            1.502323e+09  At 9:00 a.m. on August 10, 2017, an employee w...   \n",
       "1            1.500250e+09  At 9:45 a.m. on July 17, 2017, an employee was...   \n",
       "2            1.498781e+09  At 7:30 a.m. on June 30, 2017, an employee was...   \n",
       "\n",
       "Column Name                                  Event Description  \\\n",
       "0            EMPLOYEE'S FINGERS AMPUTATED WHILE OPERATING A...   \n",
       "1            EMPLOYEE'S FINGER IS CAUGHT IN DRILL AND IS AM...   \n",
       "2            EMPLOYEE IS HOSPITALIZED AFTER BEING INJURED I...   \n",
       "\n",
       "Column Name                                     Event Keywords con_end  \\\n",
       "0               FINGER,MECHANICAL POWER PRESS,AMPUTATION,GUARD       0   \n",
       "1            CAUGHT IN,DRIVE SHAFT,RESIDENTIAL CONSTRUCTION...       H   \n",
       "2                                AMPUTATED,EXPLOSION,FIREWORKS       0   \n",
       "\n",
       "Column Name Construction End Use  build_stor Building Stories Project Cost  \\\n",
       "0                                          0                                 \n",
       "1                 Other building           1                1                \n",
       "2                                          0                                 \n",
       "\n",
       "Column Name                  Project Type Degree of Injury  \\\n",
       "0                                                 Nonfatal   \n",
       "1            Alteration or rehabilitation         Nonfatal   \n",
       "2                                                 Nonfatal   \n",
       "\n",
       "Column Name      Nature of Injury Part of Body            Event type  \\\n",
       "0            Amputation, Crushing      Fingers  Caught in or between   \n",
       "1                     Dislocation      Fingers  Caught in or between   \n",
       "2                       Fire Burn         Hand                 Other   \n",
       "\n",
       "Column Name         Environmental Factor                        Human Factor  \\\n",
       "0            Catch Point/Puncture Action                               Other   \n",
       "1                                  Other     Position Inappropriate For Task   \n",
       "2                                  Other  Malfunction In Securing/Warning Op   \n",
       "\n",
       "Column Name           Task Assigned hazsub  fat_cause  \n",
       "0                Regularly Assigned      0          0  \n",
       "1                Regularly Assigned      0          0  \n",
       "2            Not Regularly Assigned      0          0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Loop through processed files in rename_files\n",
    "for file_name in dataset_config['rename_files']:\n",
    "    # Remove .csv or .tsv extension to get the base name\n",
    "    file_base = os.path.splitext(file_name)[0]\n",
    "    processed_filename = f\"{file_base}_processed.pkl\"\n",
    "    processed_path = os.path.join(download_path, processed_filename)\n",
    "\n",
    "    # Load the bundled dictionary (data + summary + config)\n",
    "    bundle = pd.read_pickle(processed_path)\n",
    "\n",
    "    # Extract components\n",
    "    loaded_df = bundle['data']\n",
    "    summary_df = bundle['summary']\n",
    "    loaded_config = bundle['config']\n",
    "\n",
    "    print(f\"\\n=== {file_base.upper()} ===\")\n",
    "    print(f\"Loaded config keys: {list(loaded_config.keys())}\")\n",
    "\n",
    "    # Show metadata\n",
    "    meta_df = pd.DataFrame(loaded_df.columns.tolist(), columns=['Column Name', 'Type', '# Categories'])\n",
    "    display(meta_df)\n",
    "\n",
    "    # Flatten for modeling\n",
    "    loaded_df.columns = loaded_df.columns.get_level_values(0)\n",
    "    display(loaded_df.head(n=3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c132c993",
   "metadata": {},
   "source": [
    "### Bonus insights (Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5eee1012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, \"Distribution of 'Task Assigned' target\")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show data imbalance:\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the distribution of player_class with counts\n",
    "value_counts = loaded_df[dataset_config['target']].value_counts()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "value_counts.plot(kind='bar')\n",
    "\n",
    "# Add counts as text labels on top of bars\n",
    "for i, count in enumerate(value_counts):\n",
    "    plt.text(i, count, str(count), ha='center', va='bottom')\n",
    "\n",
    "plt.title(f\"Distribution of '{dataset_config['target']}' target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72f971d4-6944-4758-9a78-c6f51e69b2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250522_145959\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #53~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Jan 15 19:18:46 UTC 2\n",
      "CPU Count:          64\n",
      "Memory Avail:       445.99 GB / 503.54 GB (88.6%)\n",
      "Disk Space Avail:   33781.46 GB / 51214.59 GB (66.0%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=0, num_bag_folds=8, num_bag_sets=1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[WRAPPER] Running stratified downsampling mode for task: clf\n",
      "\u001b[1;36mInfo:\u001b[0m \n",
      "[INFO] Downsampling dataframe: osha_accidents (original rows: 4847)\n",
      "\u001b[1;33mInfo:\u001b[0m Trying to sample ~1500 rows per class (total=3000)\n",
      "\u001b[1;36mInfo:\u001b[0m Final downsampled dataset has 3000 rows. Per class counts: [Regularly Assigned: 1500, Not Regularly Assigned: 1500]\n",
      "\n",
      "Downsampled 3000 rows for osha_accidents dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Beginning AutoGluon training ... Time limit = 360s\n",
      "AutoGluon will save models to \"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250522_145959\"\n",
      "Train Data Rows:    2400\n",
      "Train Data Columns: 18\n",
      "Label Column:       Task Assigned\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = Regularly Assigned, class 0 = Not Regularly Assigned\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (Regularly Assigned) vs negative (Not Regularly Assigned) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    456117.79 MB\n",
      "\tTrain Data (Original)  Memory Usage: 3.43 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['Abstract Text', 'Event Description', 'Event Keywords']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 1588\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['Construction End Use']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('object', []) : 1 | ['Construction End Use']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])        :  1 | ['Event Date']\n",
      "\t\t('int', [])          :  2 | ['build_stor', 'fat_cause']\n",
      "\t\t('object', [])       : 11 | ['con_end', 'Building Stories', 'Project Cost', 'Project Type', 'Degree of Injury', ...]\n",
      "\t\t('object', ['text']) :  3 | ['Abstract Text', 'Event Description', 'Event Keywords']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    :   10 | ['con_end', 'Building Stories', 'Project Cost', 'Project Type', 'Nature of Injury', ...]\n",
      "\t\t('category', ['text_as_category'])  :    3 | ['Abstract Text', 'Event Description', 'Event Keywords']\n",
      "\t\t('float', [])                       :    1 | ['Event Date']\n",
      "\t\t('int', [])                         :    2 | ['build_stor', 'fat_cause']\n",
      "\t\t('int', ['binned', 'text_special']) :   40 | ['Abstract Text.char_count', 'Abstract Text.word_count', 'Abstract Text.capital_ratio', 'Abstract Text.lower_ratio', 'Abstract Text.digit_ratio', ...]\n",
      "\t\t('int', ['bool'])                   :    1 | ['Degree of Injury']\n",
      "\t\t('int', ['text_ngram'])             : 1568 | ['__nlp__.00', '__nlp__.00 on', '__nlp__.00 on april', '__nlp__.00 on august', '__nlp__.00 on december', ...]\n",
      "\t37.5s = Fit runtime\n",
      "\t17 features in original data used to generate 1625 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 7.36 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 37.86s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 110 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 322.13s of the 322.11s of remaining time.\n",
      "\t0.5025\t = Validation score   (accuracy)\n",
      "\t0.34s\t = Training   runtime\n",
      "\t0.68s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 320.44s of the 320.41s of remaining time.\n",
      "\t0.4975\t = Validation score   (accuracy)\n",
      "\t0.34s\t = Training   runtime\n",
      "\t0.5s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 318.97s of the 318.94s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.08%)\n",
      "\t0.5996\t = Validation score   (accuracy)\n",
      "\t93.08s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 191.74s of the 191.72s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.08%)\n",
      "\t0.5933\t = Validation score   (accuracy)\n",
      "\t88.1s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 99.94s of the 99.92s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.5537\t = Validation score   (accuracy)\n",
      "\t3.76s\t = Training   runtime\n",
      "\t1.5s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 93.96s of the 93.94s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.5667\t = Validation score   (accuracy)\n",
      "\t2.75s\t = Training   runtime\n",
      "\t1.54s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 88.92s of the 88.90s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.42%)\n",
      "\t0.5867\t = Validation score   (accuracy)\n",
      "\t66.31s\t = Training   runtime\n",
      "\t1.89s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 18.71s of the 18.69s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.5613\t = Validation score   (accuracy)\n",
      "\t2.85s\t = Training   runtime\n",
      "\t1.47s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 13.64s of the 13.62s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.5696\t = Validation score   (accuracy)\n",
      "\t2.61s\t = Training   runtime\n",
      "\t1.48s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 8.79s of the 8.77s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.02%)\n",
      "\tTime limit exceeded... Skipping NeuralNetFastAI_BAG_L1.\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 322.14s of the -32.97s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\n",
      "\t0.5996\t = Validation score   (accuracy)\n",
      "\t0.21s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 393.32s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1508.8 rows/s (300 batch size)\n",
      "Disabling decision threshold calibration for metric `accuracy` due to having fewer than 10000 rows of validation data for calibration, to avoid overfitting (2400 rows).\n",
      "\t`accuracy` is generally not improved through threshold calibration. Force calibration via specifying `calibrate_decision_threshold=True`.\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250522_145959\")\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250522_150637\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #53~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Jan 15 19:18:46 UTC 2\n",
      "CPU Count:          64\n",
      "Memory Avail:       442.37 GB / 503.54 GB (87.9%)\n",
      "Disk Space Avail:   33781.26 GB / 51214.59 GB (66.0%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=0, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ... Time limit = 360s\n",
      "AutoGluon will save models to \"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250522_150637\"\n",
      "Train Data Rows:    2400\n",
      "Train Data Columns: 15\n",
      "Label Column:       Task Assigned\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = Regularly Assigned, class 0 = Not Regularly Assigned\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (Regularly Assigned) vs negative (Not Regularly Assigned) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    452958.51 MB\n",
      "\tTrain Data (Original)  Memory Usage: 1.87 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['Construction End Use']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('object', []) : 1 | ['Construction End Use']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  :  1 | ['Event Date']\n",
      "\t\t('int', [])    :  2 | ['build_stor', 'fat_cause']\n",
      "\t\t('object', []) : 11 | ['con_end', 'Building Stories', 'Project Cost', 'Project Type', 'Degree of Injury', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 10 | ['con_end', 'Building Stories', 'Project Cost', 'Project Type', 'Nature of Injury', ...]\n",
      "\t\t('float', [])     :  1 | ['Event Date']\n",
      "\t\t('int', [])       :  2 | ['build_stor', 'fat_cause']\n",
      "\t\t('int', ['bool']) :  1 | ['Degree of Injury']\n",
      "\t0.6s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.09 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.63s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 110 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 359.37s of the 359.35s of remaining time.\n",
      "\t0.5004\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 359.28s of the 359.26s of remaining time.\n",
      "\t0.5042\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 359.20s of the 359.18s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.5883\t = Validation score   (accuracy)\n",
      "\t40.32s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 316.27s of the 316.25s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.58\t = Validation score   (accuracy)\n",
      "\t45.99s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 267.69s of the 267.67s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.5496\t = Validation score   (accuracy)\n",
      "\t1.28s\t = Training   runtime\n",
      "\t0.34s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 265.74s of the 265.71s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.5437\t = Validation score   (accuracy)\n",
      "\t1.26s\t = Training   runtime\n",
      "\t0.34s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 263.67s of the 263.64s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.09%)\n",
      "\t0.5917\t = Validation score   (accuracy)\n",
      "\t64.29s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 196.80s of the 196.78s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.5392\t = Validation score   (accuracy)\n",
      "\t1.28s\t = Training   runtime\n",
      "\t0.33s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 194.72s of the 194.69s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.5408\t = Validation score   (accuracy)\n",
      "\t1.28s\t = Training   runtime\n",
      "\t0.34s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 192.64s of the 192.62s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.5737\t = Validation score   (accuracy)\n",
      "\t106.33s\t = Training   runtime\n",
      "\t0.38s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 83.73s of the 83.71s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.5729\t = Validation score   (accuracy)\n",
      "\t42.69s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 37.31s of the 37.29s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\tTime limit exceeded... Skipping NeuralNetTorch_BAG_L1.\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 7.09s of the 7.06s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.01%)\n",
      "\t0.5158\t = Validation score   (accuracy)\n",
      "\t33.35s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 359.37s of the -29.25s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1': 1.0}\n",
      "\t0.5917\t = Validation score   (accuracy)\n",
      "\t0.24s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 389.56s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 3512.9 rows/s (300 batch size)\n",
      "Disabling decision threshold calibration for metric `accuracy` due to having fewer than 10000 rows of validation data for calibration, to avoid overfitting (2400 rows).\n",
      "\t`accuracy` is generally not improved through threshold calibration. Force calibration via specifying `calibrate_decision_threshold=True`.\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250522_150637\")\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250522_151306\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #53~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Jan 15 19:18:46 UTC 2\n",
      "CPU Count:          64\n",
      "Memory Avail:       444.42 GB / 503.54 GB (88.3%)\n",
      "Disk Space Avail:   33781.02 GB / 51214.59 GB (66.0%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=0, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ... Time limit = 360s\n",
      "AutoGluon will save models to \"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250522_151306\"\n",
      "Train Data Rows:    2400\n",
      "Train Data Columns: 18\n",
      "Label Column:       Task Assigned\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = Regularly Assigned, class 0 = Not Regularly Assigned\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (Regularly Assigned) vs negative (Not Regularly Assigned) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    455062.39 MB\n",
      "\tTrain Data (Original)  Memory Usage: 3.48 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['Abstract Text', 'Event Description', 'Event Keywords']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 1609\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['Construction End Use']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('object', []) : 1 | ['Construction End Use']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])        :  1 | ['Event Date']\n",
      "\t\t('int', [])          :  2 | ['build_stor', 'fat_cause']\n",
      "\t\t('object', [])       : 11 | ['con_end', 'Building Stories', 'Project Cost', 'Project Type', 'Degree of Injury', ...]\n",
      "\t\t('object', ['text']) :  3 | ['Abstract Text', 'Event Description', 'Event Keywords']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    :   10 | ['con_end', 'Building Stories', 'Project Cost', 'Project Type', 'Nature of Injury', ...]\n",
      "\t\t('category', ['text_as_category'])  :    3 | ['Abstract Text', 'Event Description', 'Event Keywords']\n",
      "\t\t('float', [])                       :    1 | ['Event Date']\n",
      "\t\t('int', [])                         :    2 | ['build_stor', 'fat_cause']\n",
      "\t\t('int', ['binned', 'text_special']) :   38 | ['Abstract Text.char_count', 'Abstract Text.word_count', 'Abstract Text.capital_ratio', 'Abstract Text.lower_ratio', 'Abstract Text.digit_ratio', ...]\n",
      "\t\t('int', ['bool'])                   :    1 | ['Degree of Injury']\n",
      "\t\t('int', ['text_ngram'])             : 1586 | ['__nlp__.00', '__nlp__.00 on', '__nlp__.00 on april', '__nlp__.00 on august', '__nlp__.00 on december', ...]\n",
      "\t34.1s = Fit runtime\n",
      "\t17 features in original data used to generate 1641 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 7.44 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 34.27s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 110 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 325.73s of the 325.71s of remaining time.\n",
      "\t0.5038\t = Validation score   (accuracy)\n",
      "\t0.35s\t = Training   runtime\n",
      "\t0.51s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 324.22s of the 324.19s of remaining time.\n",
      "\t0.4971\t = Validation score   (accuracy)\n",
      "\t0.35s\t = Training   runtime\n",
      "\t0.35s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 322.87s of the 322.85s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.08%)\n",
      "\t0.5729\t = Validation score   (accuracy)\n",
      "\t80.03s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 237.98s of the 237.96s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.08%)\n",
      "\t0.5833\t = Validation score   (accuracy)\n",
      "\t68.1s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 165.40s of the 165.38s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.5375\t = Validation score   (accuracy)\n",
      "\t2.62s\t = Training   runtime\n",
      "\t1.56s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 160.43s of the 160.41s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.5587\t = Validation score   (accuracy)\n",
      "\t2.73s\t = Training   runtime\n",
      "\t1.53s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 155.45s of the 155.43s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.42%)\n",
      "\t0.5904\t = Validation score   (accuracy)\n",
      "\t78.39s\t = Training   runtime\n",
      "\t1.74s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 72.17s of the 72.15s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.5521\t = Validation score   (accuracy)\n",
      "\t2.45s\t = Training   runtime\n",
      "\t1.48s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 67.41s of the 67.39s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.5546\t = Validation score   (accuracy)\n",
      "\t2.81s\t = Training   runtime\n",
      "\t1.54s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 62.37s of the 62.35s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.02%)\n",
      "\t0.5842\t = Validation score   (accuracy)\n",
      "\t106.19s\t = Training   runtime\n",
      "\t0.35s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 325.73s of the -48.79s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1': 1.0}\n",
      "\t0.5904\t = Validation score   (accuracy)\n",
      "\t0.22s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 409.17s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 172.2 rows/s (300 batch size)\n",
      "Disabling decision threshold calibration for metric `accuracy` due to having fewer than 10000 rows of validation data for calibration, to avoid overfitting (2400 rows).\n",
      "\t`accuracy` is generally not improved through threshold calibration. Force calibration via specifying `calibrate_decision_threshold=True`.\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250522_151306\")\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250522_151957\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #53~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Jan 15 19:18:46 UTC 2\n",
      "CPU Count:          64\n",
      "Memory Avail:       445.77 GB / 503.54 GB (88.5%)\n",
      "Disk Space Avail:   33780.64 GB / 51214.59 GB (66.0%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=0, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ... Time limit = 360s\n",
      "AutoGluon will save models to \"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250522_151957\"\n",
      "Train Data Rows:    2400\n",
      "Train Data Columns: 15\n",
      "Label Column:       Task Assigned\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = Regularly Assigned, class 0 = Not Regularly Assigned\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (Regularly Assigned) vs negative (Not Regularly Assigned) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    456472.68 MB\n",
      "\tTrain Data (Original)  Memory Usage: 1.86 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['Construction End Use']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('object', []) : 1 | ['Construction End Use']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  :  1 | ['Event Date']\n",
      "\t\t('int', [])    :  2 | ['build_stor', 'fat_cause']\n",
      "\t\t('object', []) : 11 | ['con_end', 'Building Stories', 'Project Cost', 'Project Type', 'Degree of Injury', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 10 | ['con_end', 'Building Stories', 'Project Cost', 'Project Type', 'Nature of Injury', ...]\n",
      "\t\t('float', [])     :  1 | ['Event Date']\n",
      "\t\t('int', [])       :  2 | ['build_stor', 'fat_cause']\n",
      "\t\t('int', ['bool']) :  1 | ['Degree of Injury']\n",
      "\t0.7s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.09 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.76s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 110 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 359.24s of the 359.22s of remaining time.\n",
      "\t0.5283\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 359.16s of the 359.14s of remaining time.\n",
      "\t0.52\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 359.08s of the 359.06s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.5962\t = Validation score   (accuracy)\n",
      "\t41.85s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 313.56s of the 313.53s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.5917\t = Validation score   (accuracy)\n",
      "\t49.65s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 260.23s of the 260.21s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.5521\t = Validation score   (accuracy)\n",
      "\t1.25s\t = Training   runtime\n",
      "\t0.32s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 258.38s of the 258.36s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.5454\t = Validation score   (accuracy)\n",
      "\t1.16s\t = Training   runtime\n",
      "\t0.32s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 256.60s of the 256.58s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.09%)\n",
      "\t0.5837\t = Validation score   (accuracy)\n",
      "\t68.7s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 184.14s of the 184.12s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.5433\t = Validation score   (accuracy)\n",
      "\t1.23s\t = Training   runtime\n",
      "\t0.36s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 182.22s of the 182.20s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.5421\t = Validation score   (accuracy)\n",
      "\t1.18s\t = Training   runtime\n",
      "\t0.34s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 180.34s of the 180.32s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.5771\t = Validation score   (accuracy)\n",
      "\t105.92s\t = Training   runtime\n",
      "\t0.4s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 70.68s of the 70.66s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.5896\t = Validation score   (accuracy)\n",
      "\t40.61s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 26.63s of the 26.61s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\tTime limit exceeded... Skipping NeuralNetTorch_BAG_L1.\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 16.31s of the 16.29s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.01%)\n",
      "\t0.5708\t = Validation score   (accuracy)\n",
      "\t40.49s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 359.24s of the -27.15s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\n",
      "\t0.5962\t = Validation score   (accuracy)\n",
      "\t0.23s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 387.46s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 3277.5 rows/s (300 batch size)\n",
      "Disabling decision threshold calibration for metric `accuracy` due to having fewer than 10000 rows of validation data for calibration, to avoid overfitting (2400 rows).\n",
      "\t`accuracy` is generally not improved through threshold calibration. Force calibration via specifying `calibrate_decision_threshold=True`.\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250522_151957\")\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250522_152625\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #53~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Jan 15 19:18:46 UTC 2\n",
      "CPU Count:          64\n",
      "Memory Avail:       445.99 GB / 503.54 GB (88.6%)\n",
      "Disk Space Avail:   33779.92 GB / 51214.59 GB (66.0%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=0, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ... Time limit = 360s\n",
      "AutoGluon will save models to \"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250522_152625\"\n",
      "Train Data Rows:    2400\n",
      "Train Data Columns: 18\n",
      "Label Column:       Task Assigned\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = Regularly Assigned, class 0 = Not Regularly Assigned\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (Regularly Assigned) vs negative (Not Regularly Assigned) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    456690.24 MB\n",
      "\tTrain Data (Original)  Memory Usage: 3.46 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['Abstract Text', 'Event Description', 'Event Keywords']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 1625\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['Construction End Use']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('object', []) : 1 | ['Construction End Use']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])        :  1 | ['Event Date']\n",
      "\t\t('int', [])          :  2 | ['build_stor', 'fat_cause']\n",
      "\t\t('object', [])       : 11 | ['con_end', 'Building Stories', 'Project Cost', 'Project Type', 'Degree of Injury', ...]\n",
      "\t\t('object', ['text']) :  3 | ['Abstract Text', 'Event Description', 'Event Keywords']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    :   10 | ['con_end', 'Building Stories', 'Project Cost', 'Project Type', 'Nature of Injury', ...]\n",
      "\t\t('category', ['text_as_category'])  :    3 | ['Abstract Text', 'Event Description', 'Event Keywords']\n",
      "\t\t('float', [])                       :    1 | ['Event Date']\n",
      "\t\t('int', [])                         :    2 | ['build_stor', 'fat_cause']\n",
      "\t\t('int', ['binned', 'text_special']) :   40 | ['Abstract Text.char_count', 'Abstract Text.word_count', 'Abstract Text.capital_ratio', 'Abstract Text.lower_ratio', 'Abstract Text.digit_ratio', ...]\n",
      "\t\t('int', ['bool'])                   :    1 | ['Degree of Injury']\n",
      "\t\t('int', ['text_ngram'])             : 1600 | ['__nlp__.00', '__nlp__.00 on', '__nlp__.00 on april', '__nlp__.00 on august', '__nlp__.00 on december', ...]\n",
      "\t35.9s = Fit runtime\n",
      "\t17 features in original data used to generate 1657 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 7.51 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 36.12s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 110 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 323.88s of the 323.85s of remaining time.\n",
      "\t0.51\t = Validation score   (accuracy)\n",
      "\t0.37s\t = Training   runtime\n",
      "\t0.36s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 322.49s of the 322.47s of remaining time.\n",
      "\t0.5033\t = Validation score   (accuracy)\n",
      "\t0.36s\t = Training   runtime\n",
      "\t0.35s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 321.14s of the 321.12s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.08%)\n",
      "\t0.6025\t = Validation score   (accuracy)\n",
      "\t62.8s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 253.33s of the 253.31s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.08%)\n",
      "\t0.5975\t = Validation score   (accuracy)\n",
      "\t65.37s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 183.21s of the 183.19s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.5629\t = Validation score   (accuracy)\n",
      "\t2.39s\t = Training   runtime\n",
      "\t1.54s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 178.55s of the 178.53s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.5613\t = Validation score   (accuracy)\n",
      "\t2.65s\t = Training   runtime\n",
      "\t1.57s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 173.64s of the 173.62s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.42%)\n",
      "\t0.5979\t = Validation score   (accuracy)\n",
      "\t79.69s\t = Training   runtime\n",
      "\t1.71s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 89.01s of the 88.99s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.5646\t = Validation score   (accuracy)\n",
      "\t2.48s\t = Training   runtime\n",
      "\t1.5s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 84.12s of the 84.10s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.5646\t = Validation score   (accuracy)\n",
      "\t2.54s\t = Training   runtime\n",
      "\t1.55s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 79.32s of the 79.30s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.02%)\n",
      "\t0.5837\t = Validation score   (accuracy)\n",
      "\t109.62s\t = Training   runtime\n",
      "\t0.43s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 323.88s of the -34.72s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\n",
      "\t0.6025\t = Validation score   (accuracy)\n",
      "\t0.21s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 395.09s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1590.1 rows/s (300 batch size)\n",
      "Disabling decision threshold calibration for metric `accuracy` due to having fewer than 10000 rows of validation data for calibration, to avoid overfitting (2400 rows).\n",
      "\t`accuracy` is generally not improved through threshold calibration. Force calibration via specifying `calibrate_decision_threshold=True`.\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250522_152625\")\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250522_153301\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #53~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Jan 15 19:18:46 UTC 2\n",
      "CPU Count:          64\n",
      "Memory Avail:       445.50 GB / 503.54 GB (88.5%)\n",
      "Disk Space Avail:   33779.35 GB / 51214.59 GB (66.0%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=0, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ... Time limit = 360s\n",
      "AutoGluon will save models to \"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250522_153301\"\n",
      "Train Data Rows:    2400\n",
      "Train Data Columns: 15\n",
      "Label Column:       Task Assigned\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = Regularly Assigned, class 0 = Not Regularly Assigned\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (Regularly Assigned) vs negative (Not Regularly Assigned) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    456197.50 MB\n",
      "\tTrain Data (Original)  Memory Usage: 1.87 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['Construction End Use']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('object', []) : 1 | ['Construction End Use']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  :  1 | ['Event Date']\n",
      "\t\t('int', [])    :  2 | ['build_stor', 'fat_cause']\n",
      "\t\t('object', []) : 11 | ['con_end', 'Building Stories', 'Project Cost', 'Project Type', 'Degree of Injury', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 10 | ['con_end', 'Building Stories', 'Project Cost', 'Project Type', 'Nature of Injury', ...]\n",
      "\t\t('float', [])     :  1 | ['Event Date']\n",
      "\t\t('int', [])       :  2 | ['build_stor', 'fat_cause']\n",
      "\t\t('int', ['bool']) :  1 | ['Degree of Injury']\n",
      "\t0.5s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.09 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.58s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 110 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 359.42s of the 359.40s of remaining time.\n",
      "\t0.54\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 359.34s of the 359.32s of remaining time.\n",
      "\t0.5275\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 359.26s of the 359.24s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.6021\t = Validation score   (accuracy)\n",
      "\t43.61s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 312.11s of the 312.09s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.5971\t = Validation score   (accuracy)\n",
      "\t51.17s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 257.45s of the 257.43s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.5371\t = Validation score   (accuracy)\n",
      "\t1.19s\t = Training   runtime\n",
      "\t0.32s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 255.53s of the 255.51s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.5354\t = Validation score   (accuracy)\n",
      "\t1.19s\t = Training   runtime\n",
      "\t0.32s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 253.70s of the 253.68s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.09%)\n",
      "\t0.5908\t = Validation score   (accuracy)\n",
      "\t73.41s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 176.82s of the 176.80s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.5537\t = Validation score   (accuracy)\n",
      "\t1.21s\t = Training   runtime\n",
      "\t0.34s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 174.90s of the 174.88s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.5387\t = Validation score   (accuracy)\n",
      "\t1.22s\t = Training   runtime\n",
      "\t0.33s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 173.02s of the 173.00s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.585\t = Validation score   (accuracy)\n",
      "\t107.16s\t = Training   runtime\n",
      "\t0.37s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 62.09s of the 62.07s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.5833\t = Validation score   (accuracy)\n",
      "\t42.02s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 16.57s of the 16.55s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\tTime limit exceeded... Skipping NeuralNetTorch_BAG_L1.\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 6.18s of the 6.16s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.01%)\n",
      "\t0.5158\t = Validation score   (accuracy)\n",
      "\t33.17s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 359.42s of the -30.00s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\n",
      "\t0.6021\t = Validation score   (accuracy)\n",
      "\t0.23s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 390.31s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 3845.9 rows/s (300 batch size)\n",
      "Disabling decision threshold calibration for metric `accuracy` due to having fewer than 10000 rows of validation data for calibration, to avoid overfitting (2400 rows).\n",
      "\t`accuracy` is generally not improved through threshold calibration. Force calibration via specifying `calibrate_decision_threshold=True`.\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250522_153301\")\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250522_153932\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #53~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Jan 15 19:18:46 UTC 2\n",
      "CPU Count:          64\n",
      "Memory Avail:       445.24 GB / 503.54 GB (88.4%)\n",
      "Disk Space Avail:   33779.04 GB / 51214.59 GB (66.0%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=0, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ... Time limit = 360s\n",
      "AutoGluon will save models to \"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250522_153932\"\n",
      "Train Data Rows:    2400\n",
      "Train Data Columns: 18\n",
      "Label Column:       Task Assigned\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = Regularly Assigned, class 0 = Not Regularly Assigned\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (Regularly Assigned) vs negative (Not Regularly Assigned) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    455935.58 MB\n",
      "\tTrain Data (Original)  Memory Usage: 3.44 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['Abstract Text', 'Event Description', 'Event Keywords']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 1596\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['Construction End Use']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('object', []) : 1 | ['Construction End Use']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])        :  1 | ['Event Date']\n",
      "\t\t('int', [])          :  2 | ['build_stor', 'fat_cause']\n",
      "\t\t('object', [])       : 11 | ['con_end', 'Building Stories', 'Project Cost', 'Project Type', 'Degree of Injury', ...]\n",
      "\t\t('object', ['text']) :  3 | ['Abstract Text', 'Event Description', 'Event Keywords']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    :   10 | ['con_end', 'Building Stories', 'Project Cost', 'Project Type', 'Nature of Injury', ...]\n",
      "\t\t('category', ['text_as_category'])  :    3 | ['Abstract Text', 'Event Description', 'Event Keywords']\n",
      "\t\t('float', [])                       :    1 | ['Event Date']\n",
      "\t\t('int', [])                         :    2 | ['build_stor', 'fat_cause']\n",
      "\t\t('int', ['binned', 'text_special']) :   40 | ['Abstract Text.char_count', 'Abstract Text.word_count', 'Abstract Text.capital_ratio', 'Abstract Text.lower_ratio', 'Abstract Text.digit_ratio', ...]\n",
      "\t\t('int', ['bool'])                   :    1 | ['Degree of Injury']\n",
      "\t\t('int', ['text_ngram'])             : 1575 | ['__nlp__.00', '__nlp__.00 on', '__nlp__.00 on april', '__nlp__.00 on august', '__nlp__.00 on december', ...]\n",
      "\t35.2s = Fit runtime\n",
      "\t17 features in original data used to generate 1632 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 7.40 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 35.57s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 110 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 324.43s of the 324.40s of remaining time.\n",
      "\t0.5096\t = Validation score   (accuracy)\n",
      "\t0.35s\t = Training   runtime\n",
      "\t0.4s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 323.03s of the 323.01s of remaining time.\n",
      "\t0.5058\t = Validation score   (accuracy)\n",
      "\t0.35s\t = Training   runtime\n",
      "\t0.37s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 321.69s of the 321.66s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.08%)\n",
      "\t0.5925\t = Validation score   (accuracy)\n",
      "\t65.83s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 251.33s of the 251.31s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.08%)\n",
      "\t0.5917\t = Validation score   (accuracy)\n",
      "\t67.7s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 179.25s of the 179.23s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.5467\t = Validation score   (accuracy)\n",
      "\t2.5s\t = Training   runtime\n",
      "\t1.48s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 174.58s of the 174.56s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.5492\t = Validation score   (accuracy)\n",
      "\t2.61s\t = Training   runtime\n",
      "\t1.47s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 169.81s of the 169.79s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.41%)\n",
      "\t0.5908\t = Validation score   (accuracy)\n",
      "\t76.96s\t = Training   runtime\n",
      "\t1.74s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 88.30s of the 88.28s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.5425\t = Validation score   (accuracy)\n",
      "\t2.56s\t = Training   runtime\n",
      "\t1.47s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 83.57s of the 83.55s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.5513\t = Validation score   (accuracy)\n",
      "\t2.53s\t = Training   runtime\n",
      "\t1.47s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 78.88s of the 78.86s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.02%)\n",
      "\t0.5704\t = Validation score   (accuracy)\n",
      "\t108.22s\t = Training   runtime\n",
      "\t0.41s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 324.43s of the -33.88s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\n",
      "\t0.5925\t = Validation score   (accuracy)\n",
      "\t0.22s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 394.24s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 1728.6 rows/s (300 batch size)\n",
      "Disabling decision threshold calibration for metric `accuracy` due to having fewer than 10000 rows of validation data for calibration, to avoid overfitting (2400 rows).\n",
      "\t`accuracy` is generally not improved through threshold calibration. Force calibration via specifying `calibrate_decision_threshold=True`.\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250522_153932\")\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250522_154608\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #53~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Jan 15 19:18:46 UTC 2\n",
      "CPU Count:          64\n",
      "Memory Avail:       445.43 GB / 503.54 GB (88.5%)\n",
      "Disk Space Avail:   33778.75 GB / 51214.59 GB (66.0%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=0, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ... Time limit = 360s\n",
      "AutoGluon will save models to \"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250522_154608\"\n",
      "Train Data Rows:    2400\n",
      "Train Data Columns: 15\n",
      "Label Column:       Task Assigned\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = Regularly Assigned, class 0 = Not Regularly Assigned\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (Regularly Assigned) vs negative (Not Regularly Assigned) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    456114.03 MB\n",
      "\tTrain Data (Original)  Memory Usage: 1.86 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['Construction End Use']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('object', []) : 1 | ['Construction End Use']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  :  1 | ['Event Date']\n",
      "\t\t('int', [])    :  2 | ['build_stor', 'fat_cause']\n",
      "\t\t('object', []) : 11 | ['con_end', 'Building Stories', 'Project Cost', 'Project Type', 'Degree of Injury', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 10 | ['con_end', 'Building Stories', 'Project Cost', 'Project Type', 'Nature of Injury', ...]\n",
      "\t\t('float', [])     :  1 | ['Event Date']\n",
      "\t\t('int', [])       :  2 | ['build_stor', 'fat_cause']\n",
      "\t\t('int', ['bool']) :  1 | ['Degree of Injury']\n",
      "\t0.7s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.09 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.77s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 110 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 359.23s of the 359.21s of remaining time.\n",
      "\t0.5308\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 359.15s of the 359.13s of remaining time.\n",
      "\t0.5175\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 359.07s of the 359.05s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.575\t = Validation score   (accuracy)\n",
      "\t43.3s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 312.03s of the 312.01s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.5654\t = Validation score   (accuracy)\n",
      "\t52.52s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 256.05s of the 256.02s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.5454\t = Validation score   (accuracy)\n",
      "\t1.24s\t = Training   runtime\n",
      "\t0.32s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 254.20s of the 254.18s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.5425\t = Validation score   (accuracy)\n",
      "\t1.19s\t = Training   runtime\n",
      "\t0.32s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 252.38s of the 252.36s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.09%)\n",
      "\t0.5571\t = Validation score   (accuracy)\n",
      "\t67.9s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 180.99s of the 180.97s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.5425\t = Validation score   (accuracy)\n",
      "\t1.27s\t = Training   runtime\n",
      "\t0.33s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 179.02s of the 179.00s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.5417\t = Validation score   (accuracy)\n",
      "\t1.17s\t = Training   runtime\n",
      "\t0.34s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 177.05s of the 177.03s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.5687\t = Validation score   (accuracy)\n",
      "\t107.0s\t = Training   runtime\n",
      "\t0.35s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 66.33s of the 66.31s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.5742\t = Validation score   (accuracy)\n",
      "\t39.36s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 23.18s of the 23.16s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\tTime limit exceeded... Skipping NeuralNetTorch_BAG_L1.\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 12.68s of the 12.65s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.01%)\n",
      "\t0.5371\t = Validation score   (accuracy)\n",
      "\t37.44s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 359.23s of the -27.59s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\n",
      "\t0.575\t = Validation score   (accuracy)\n",
      "\t0.24s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 387.89s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 3526.8 rows/s (300 batch size)\n",
      "Disabling decision threshold calibration for metric `accuracy` due to having fewer than 10000 rows of validation data for calibration, to avoid overfitting (2400 rows).\n",
      "\t`accuracy` is generally not improved through threshold calibration. Force calibration via specifying `calibrate_decision_threshold=True`.\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250522_154608\")\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250522_155236\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #53~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Jan 15 19:18:46 UTC 2\n",
      "CPU Count:          64\n",
      "Memory Avail:       444.83 GB / 503.54 GB (88.3%)\n",
      "Disk Space Avail:   33782.25 GB / 51214.59 GB (66.0%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=0, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ... Time limit = 360s\n",
      "AutoGluon will save models to \"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250522_155236\"\n",
      "Train Data Rows:    2400\n",
      "Train Data Columns: 18\n",
      "Label Column:       Task Assigned\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = Regularly Assigned, class 0 = Not Regularly Assigned\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (Regularly Assigned) vs negative (Not Regularly Assigned) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    455507.14 MB\n",
      "\tTrain Data (Original)  Memory Usage: 3.46 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['Abstract Text', 'Event Description', 'Event Keywords']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 1590\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['Construction End Use']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('object', []) : 1 | ['Construction End Use']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])        :  1 | ['Event Date']\n",
      "\t\t('int', [])          :  2 | ['build_stor', 'fat_cause']\n",
      "\t\t('object', [])       : 11 | ['con_end', 'Building Stories', 'Project Cost', 'Project Type', 'Degree of Injury', ...]\n",
      "\t\t('object', ['text']) :  3 | ['Abstract Text', 'Event Description', 'Event Keywords']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    :   10 | ['con_end', 'Building Stories', 'Project Cost', 'Project Type', 'Nature of Injury', ...]\n",
      "\t\t('category', ['text_as_category'])  :    3 | ['Abstract Text', 'Event Description', 'Event Keywords']\n",
      "\t\t('float', [])                       :    1 | ['Event Date']\n",
      "\t\t('int', [])                         :    2 | ['build_stor', 'fat_cause']\n",
      "\t\t('int', ['binned', 'text_special']) :   40 | ['Abstract Text.char_count', 'Abstract Text.word_count', 'Abstract Text.capital_ratio', 'Abstract Text.lower_ratio', 'Abstract Text.digit_ratio', ...]\n",
      "\t\t('int', ['bool'])                   :    1 | ['Degree of Injury']\n",
      "\t\t('int', ['text_ngram'])             : 1570 | ['__nlp__.00', '__nlp__.00 on', '__nlp__.00 on april', '__nlp__.00 on august', '__nlp__.00 on december', ...]\n",
      "\t35.8s = Fit runtime\n",
      "\t17 features in original data used to generate 1627 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 7.37 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 36.05s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 110 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 323.95s of the 323.93s of remaining time.\n",
      "\t0.5017\t = Validation score   (accuracy)\n",
      "\t0.35s\t = Training   runtime\n",
      "\t0.36s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 322.60s of the 322.58s of remaining time.\n",
      "\t0.5008\t = Validation score   (accuracy)\n",
      "\t0.34s\t = Training   runtime\n",
      "\t0.34s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 321.29s of the 321.27s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.08%)\n",
      "\t0.5875\t = Validation score   (accuracy)\n",
      "\t68.63s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 247.71s of the 247.69s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.08%)\n",
      "\t0.5913\t = Validation score   (accuracy)\n",
      "\t68.08s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 175.25s of the 175.23s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.5671\t = Validation score   (accuracy)\n",
      "\t2.43s\t = Training   runtime\n",
      "\t1.46s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 170.65s of the 170.63s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.5558\t = Validation score   (accuracy)\n",
      "\t2.66s\t = Training   runtime\n",
      "\t1.41s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 165.90s of the 165.88s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.41%)\n",
      "\t0.59\t = Validation score   (accuracy)\n",
      "\t75.97s\t = Training   runtime\n",
      "\t1.7s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 85.45s of the 85.43s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.5537\t = Validation score   (accuracy)\n",
      "\t2.47s\t = Training   runtime\n",
      "\t1.46s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 80.79s of the 80.77s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.5525\t = Validation score   (accuracy)\n",
      "\t2.72s\t = Training   runtime\n",
      "\t1.45s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 75.92s of the 75.90s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.02%)\n",
      "\t0.5958\t = Validation score   (accuracy)\n",
      "\t109.21s\t = Training   runtime\n",
      "\t0.37s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 323.95s of the -37.84s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_BAG_L1': 0.667, 'NeuralNetFastAI_BAG_L1': 0.25, 'LightGBM_BAG_L1': 0.083}\n",
      "\t0.6075\t = Validation score   (accuracy)\n",
      "\t0.21s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 398.26s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 133.2 rows/s (300 batch size)\n",
      "Disabling decision threshold calibration for metric `accuracy` due to having fewer than 10000 rows of validation data for calibration, to avoid overfitting (2400 rows).\n",
      "\t`accuracy` is generally not improved through threshold calibration. Force calibration via specifying `calibrate_decision_threshold=True`.\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250522_155236\")\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n",
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250522_155922\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.3.0\n",
      "Python Version:     3.10.12\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #53~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Wed Jan 15 19:18:46 UTC 2\n",
      "CPU Count:          64\n",
      "Memory Avail:       444.86 GB / 503.54 GB (88.3%)\n",
      "Disk Space Avail:   33781.86 GB / 51214.59 GB (66.0%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Stack configuration (auto_stack=True): num_stack_levels=0, num_bag_folds=8, num_bag_sets=1\n",
      "Beginning AutoGluon training ... Time limit = 360s\n",
      "AutoGluon will save models to \"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250522_155922\"\n",
      "Train Data Rows:    2400\n",
      "Train Data Columns: 15\n",
      "Label Column:       Task Assigned\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = Regularly Assigned, class 0 = Not Regularly Assigned\n",
      "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (Regularly Assigned) vs negative (Not Regularly Assigned) class.\n",
      "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    455551.60 MB\n",
      "\tTrain Data (Original)  Memory Usage: 1.87 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 1 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['Construction End Use']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('object', []) : 1 | ['Construction End Use']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  :  1 | ['Event Date']\n",
      "\t\t('int', [])    :  2 | ['build_stor', 'fat_cause']\n",
      "\t\t('object', []) : 11 | ['con_end', 'Building Stories', 'Project Cost', 'Project Type', 'Degree of Injury', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 10 | ['con_end', 'Building Stories', 'Project Cost', 'Project Type', 'Nature of Injury', ...]\n",
      "\t\t('float', [])     :  1 | ['Event Date']\n",
      "\t\t('int', [])       :  2 | ['build_stor', 'fat_cause']\n",
      "\t\t('int', ['bool']) :  1 | ['Degree of Injury']\n",
      "\t0.5s = Fit runtime\n",
      "\t14 features in original data used to generate 14 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.09 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.58s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 110 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 359.42s of the 359.40s of remaining time.\n",
      "\t0.5138\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 359.36s of the 359.34s of remaining time.\n",
      "\t0.5192\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 359.31s of the 359.29s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.5771\t = Validation score   (accuracy)\n",
      "\t43.94s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 311.69s of the 311.67s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.5708\t = Validation score   (accuracy)\n",
      "\t53.01s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 255.22s of the 255.20s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.5408\t = Validation score   (accuracy)\n",
      "\t1.2s\t = Training   runtime\n",
      "\t0.35s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 253.36s of the 253.34s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.5317\t = Validation score   (accuracy)\n",
      "\t1.21s\t = Training   runtime\n",
      "\t0.33s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 251.60s of the 251.57s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.09%)\n",
      "\t0.5754\t = Validation score   (accuracy)\n",
      "\t62.85s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 185.00s of the 184.97s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.5442\t = Validation score   (accuracy)\n",
      "\t1.24s\t = Training   runtime\n",
      "\t0.33s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 183.07s of the 183.04s of remaining time.\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "\t0.5275\t = Validation score   (accuracy)\n",
      "\t1.16s\t = Training   runtime\n",
      "\t0.35s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 181.18s of the 181.16s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.5746\t = Validation score   (accuracy)\n",
      "\t106.39s\t = Training   runtime\n",
      "\t0.43s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 71.17s of the 71.15s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\t0.5725\t = Validation score   (accuracy)\n",
      "\t41.2s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 26.36s of the 26.34s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.00%)\n",
      "\tTime limit exceeded... Skipping NeuralNetTorch_BAG_L1.\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 15.74s of the 15.72s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=8, gpus=1, memory=0.01%)\n",
      "\t0.5621\t = Validation score   (accuracy)\n",
      "\t40.07s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 359.42s of the -27.21s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\n",
      "\t0.5771\t = Validation score   (accuracy)\n",
      "\t0.23s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 387.49s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 3362.7 rows/s (300 batch size)\n",
      "Disabling decision threshold calibration for metric `accuracy` due to having fewer than 10000 rows of validation data for calibration, to avoid overfitting (2400 rows).\n",
      "\t`accuracy` is generally not improved through threshold calibration. Force calibration via specifying `calibrate_decision_threshold=True`.\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/guptaa/anshul/FreeText_TaBench/datasets_notebooks/classification/AutogluonModels/ag-20250522_155922\")\n",
      "/work/dlclarge2/guptaa-dataset/anshul_env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:3001: UserWarning: The y_pred values do not sum to one. Make sure to pass probabilities.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from baseline_eval import evaluate_baseline, plot_model_performance_summary\n",
    "results = evaluate_baseline(\n",
    "    df=loaded_df,\n",
    "    model='AGTabular',\n",
    "    df_name=dataset_config['dataset_name'],\n",
    "    label_col= dataset_config['target'],\n",
    "    task_type=dataset_config['task'],\n",
    "    textual_cols=textual_cols,\n",
    "    k_folds=5,\n",
    "    seed=0,\n",
    "    max_samples=3000,\n",
    "    output_path=f\"../../baseline_results/{dataset_config['task']}/{dataset_config['dataset_name']}.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "743cf7ee-d31d-4200-80ec-a4218bb462b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving plot to ../../baseline_results/plots/clf/score\n",
      "Saving plot to ../../baseline_results/plots/clf/loss\n",
      "Saving plot to ../../baseline_results/plots/clf/roc_auc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score':                                     mean       std\n",
       " model                                             \n",
       " AutoGluon_Tabular_without_text  0.544000  0.018089\n",
       " AutoGluon_Tabular_with_text     0.559333  0.018768,\n",
       " 'loss':                                     mean       std\n",
       " model                                             \n",
       " AutoGluon_Tabular_with_text     0.681664  0.002682\n",
       " AutoGluon_Tabular_without_text  0.686779  0.004388,\n",
       " 'roc_auc':                                     mean       std\n",
       " model                                             \n",
       " AutoGluon_Tabular_without_text  0.564818  0.020198\n",
       " AutoGluon_Tabular_with_text     0.583241  0.008084}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs = pd.read_csv(f\"../../baseline_results/{dataset_config['task']}/{dataset_config['dataset_name']}.csv\")\n",
    "plot_model_performance_summary(name=dataset_config['dataset_name'],task=dataset_config['task'], df=rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f39e3f-5458-47f7-b6eb-6ad75290b7e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
